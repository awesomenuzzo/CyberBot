Efficient Bootstrapping for Approximate
Homomorphic Encryption with Non-Sparse Keys
Jean-Philippe Bossuat, Christian Mouchet, Juan Troncoso-Pastoriza, and
Jean-Pierre Hubaux
École polytechnique fédérale de Lausanne
first.last@epfl.ch

Abstract. We present a bootstrapping procedure for the full-RNS variant of the approximate homomorphic-encryption scheme of Cheon et al.,
CKKS (Asiacrypt 17, SAC 18). Compared to the previously proposed
procedures (Eurocrypt 18 & 19, CT-RSA 20), our bootstrapping procedure is more precise, more efficient (in terms of CPU cost and number
of consumed levels), and is more reliable and 128-bit-secure. Unlike the
previous approaches, it does not require the use of sparse secret-keys.
Therefore, to the best of our knowledge, this is the first procedure that
enables a highly efficient and precise bootstrapping with a low probability of failure for parameters that are 128-bit-secure under the most
recent attacks on sparse R-LWE secrets.
We achieve this efficiency and precision by introducing three novel contributions: (i) We propose a generic algorithm for homomorphic polynomialevaluation that takes into account the approximate rescaling and is optimal in level consumption. (ii) We optimize the key-switch procedure and
propose a new technique for linear transformations (double hoisting). (iii)
We propose a systematic approach to parameterize the bootstrapping,
including a precise way to assess its failure probability.
We implemented our improvements and bootstrapping procedure in the
open-source Lattigo library. For example, bootstrapping a plaintext in
C32768 takes 18 seconds, has an output coefficient modulus of 505 bits, a
mean precision of 19.1 bits, and a failure probability of 2−15.58 . Hence,
we achieve 14.1× improvement in bootstrapped throughput (plaintextbit per second), with respect to the previous best results, and we have a
failure probability 468× smaller and ensure 128-bit security.
Keywords: Fully Homomorphic Encryption · Bootstrapping · Implementation

1

Introduction

Homomorphic encryption (HE) enables computing over encrypted data without
decrypting them first; thus, it is becoming increasingly popular as a solution
for processing confidential data in untrustworthy environments. Since Gentry’s
introduction of the first fully homomorphic-encryption (FHE) scheme over ideal
lattices [13], continuous efficiency improvements have brought these techniques
©IACR 2021. This manuscript is the extended version of the article published at Eurocrypt 2021.

2

J.P. Bossuat et al.

closer to practical application domains. As a result, lattice-based FHE schemes
are increasingly used in experimental systems [25, 22, 26], and some of them are
now proposed as an industry standard [1].
Cheon et al. [10] introduced a leveled encryption scheme for approximate
arithmetic (CKKS); the scheme is capable of homomorphically evaluating arbitrary polynomial functions over encrypted complex-number vectors. Although
the family of leveled cryptosystems enables only a finite multiplicative depth,
with each multiplication consuming one level, the CKKS scheme enables the homomorphic re-encryption of an exhausted ciphertext into an almost fresh one.
This capability, commonly called bootstrapping, theoretically enables the evaluation of arbitrary-depth circuits. In practice, however, the bootstrapping procedure for CKKS is approximate, and its precision and performance determine the
actual maximum depth of a circuit.
Since the initial CKKS bootstrapping procedure by Cheon et al. [8] and until
the most recent work by Han and Ki [19] that operates on the full-RNS (residue
number systems) version of CKKS, the bootstrapping efficiency has improved
by several orders of magnitude. However, this operation remains a bottleneck
for its potential applications, and its performance is crucial for the adoption
of the scheme. Bootstrapping performance can be improved by following two
approaches: (i) adapting the bootstrapping circuit representation by using HEfriendly numerical methods. (ii) optimizing the scheme operations themselves,
which also improves the overall scheme performance.
All current CKKS bootstrapping approaches [8, 5, 19] rely, so far, on sparse
secret-keys to reduce the depth of their circuit representation, and none of them
has proposed parameters with an equivalent security of at least 128 bits under the recent attacks on sparse R-LWE secrets [9, 28]. The lack of stability
in the security of sparse R-LWE secrets has lead the standardization initiatives
to exclude sparse keys, hence also the bootstrapping operation, from the currently proposed standards [1]. This raises the question about the practicality of
a bootstrapping procedure that would not require the use of sparse secret-keys.
1.1

Our Results

We propose an efficient bootstrapping procedure for the full-RNS CKKS scheme;
it does not necessarily require the use of sparse secret-keys and provides a greater
throughput than the current state of the art (Definition 1 in Section 7.1). To
achieve this, we make the following contributions:
Homomorphic Polynomial Evaluation (Section 3). The full-RNS variant
of the CKKS scheme restricts the re-scale operation only to the division by
the factors qi of the ciphertext modulus Q. As the choice of these factors is
constrained to those enabling a number theoretic transform (NTT), the rescale
cannot be done by a power of two (as in the original CKKS scheme) and it
introduces a small scale deviation in the process. For complex circuits, such as
polynomial evaluations, additions between ciphertexts of slightly different scales
will eventually occur and will introduce errors.

Efficient Bootstrapping with Non-Sparse Keys

3

We observe that this problem is trivially solved for linear circuits, by scaling
the plaintext constants by the modulus qi by which the ciphertext will be divided
during the next rescale. By doing so, the rescale is exact and the ciphertext scale
is unchanged after the operation. As a polynomial can be computed by recursive
evaluations of a linear function, the linear case can be generalized. In this work,
we propose a generic algorithm that consumes an optimal number of dlog(d + 1)e
levels to homomorphically evaluate degree-d polynomial functions. Starting from
a user-defined output scale, the intermediate scales can be back-propagated in
the recursion, thus ensuring that each and every homomorphic addition occurs
between ciphertexts of the same scale (hence is errorless). Our algorithm is,
to the best of our knowledge, the first general solution for the problem of the
approximate rescale arising from the full-RNS variant of the CKKS scheme.
Faster Matrix × Ciphertext Products (Section 4). The most expensive
CKKS homomorphic operation is the key-switch. This operation is an integral
building block of the homomorphic multiplication, slot rotations, and conjugation. The CKKS bootstrapping requires two linear transformations that involve
a large number of rotations (key-switch operations), so minimizing the number
of key-switch and/or their complexity has a significant effect on its performance.
Given an n × n plaintext matrix M and an encrypted vector v, all previous
works on the CKKS bootstrapping [8, 5, 19] use a baby-step giant-step (BSGS)
algorithm,√proposed by Halevi and Shoup [17], to compute the encrypted product
M v in O( n) rotations. These works treat the key-switch procedure as a blackbox and try to reduce the number of times it is executed. Therefore, they do not
exploit the hoisting proposed by Halevi and Shoup [18].
We improve this BSGS algorithm by proposing a new format for rotation
keys and a modified key-switch procedure that extends the hoisting technique to
a second layer. This strategy is generic and it reduces the theoretical minimum
complexity (in terms of modular products) of any linear transformation over
ciphertexts. In our bootstrapping it reduces the cost of the linear transformations
by roughly a factor of two compared to the previous hoisting approach.
Improved Bootstrapping Procedure (Section 5). We integrate our proposed improvements in the bootstrapping circuit proposed by Cheon et al. [8],
Chen et al. [5], Cheon et al. [6] and Han and Ki [19]. We propose a new highprecision and faster bootstrapping circuit with updated parameters that are
128-bit secure, even if considering the most recent attacks on sparse keys [9, 28].
Parameterization and Evaluation (Section 6). We discuss the parametrization of the CKKS scheme and its bootstrapping circuit, and we propose a procedure to choose and fine-tune the parameters for a given use-case.
We implemented our contributions, as well as our bootstrapping, in the open
source library Lattigo: https://github.com/ldsec/lattigo. To the best of
our knowledge, this is the first public and open-source implementation of the
bootstrapping for the full-RNS variant of the CKKS scheme.

4

2

J.P. Bossuat et al.

Background and Related Work

We now recall the full-RNS variant of the CKKS encryption scheme and review
its previously proposed bootstrapping procedures.
2.1

The Full-RNS CKKS Scheme

We consider the CKKS encryption scheme [10] in its full-RNS variant [7]: the
polynomial coefficients are always represented in the RNS and NTT domains.
Notation For
QLa fixed power-of-two N and L + 1 distinct primes q0 , . . . , qL , we
define QL = i=0 qi and RQL = ZQL [X]/(X N + 1), the cyclotomic polynomial
ring over the integers modulo QL . Unless otherwise stated, we consider elements
of RQL as their unique representative in the RNS domain: Rq0 ×Rq1 ×...×RqL ∼
=
RQL : a polynomial in RQL is represented by a (L + 1) × N matrix of coefficients.
We denote single elements (polynomials or numbers) in italics, e.g., a, and vectors
of such elements in bold, e.g., a, with a||b the concatenation of two vectors. We
denote a(i) the element at position i of the vector a or the degree-i coefficient
of the polynomial a. We denote ||a|| the infinity norm of the polynomial (or
vector) a in the power basis and hw(a) the Hamming weight of the polynomial
(or vector) a. We denote ha, bi the inner product between the vectors a and b.
Given two vectors a and b, each of n values, we denote log(−1 ) the negative log
Pn−1
of the L1 norm of their difference:  = n1 i=0 |a(i) −b(i) |. [x]Q denotes reduction
of x modulo Q and bxc, dxe, bxe the rounding of x to the previous, the next, and
the closest integer, respectively (if x is a polynomial, the operation is applied
coefficient-wise). Unless otherwise stated, logarithms are in base 2.
Plaintext and Ciphertext Space A plaintext is a polynomial pt = m(Y ) ∈
R[Y ]/(Y 2n + 1) with Y = X N/2n and n a power-of-two smaller than N . We
define the following plaintext encodings: (i) The coefficient encoding for which
the message m ∈ R2n is directly encoded as the coefficients of a polynomial
in Y . (ii) The slots encoding for which the message m ∈ Cn is subjected to
the canonical embedding Cn → Y 2n for which the negacyclic convolution in
R[Y ]/(Y 2n + 1) results in a Hadamard product in Cn .
We represent plaintexts and ciphertexts, respectively, by the tuples {pt, Q` , ∆}
and {ct, Q` , ∆}, where, for a secret s ∈ RQL , pt is a degree-zero polynomial in
2
s, i.e. of RQ` , and ct is a degree-one polynomial in s, i.e. of RQ
. We define
`
Q`
Q` = i=0 qi as the modulus at level ` and ∆ as a scaling factor. We denote
L as the maximum level and use 0 ≤ ` ≤ L to represent a level between the
smallest level 0 and the highest level L. We refer to the depth of a circuit as the
number of levels required for the evaluation of the circuit.

Efficient Bootstrapping with Non-Sparse Keys

5

Scheme RNS-CKKS – Basic Operations
• Setup(N, h, b, σ): For a power-of-two ring degree N , a secret-distribution
Hamming weight h, a standard deviation σ, and a modulus bit-size b: Select the moduli chains {q0 , . . . , qL } and {p0 , . . . , pα−1 } composed of pairwise
different NTT-friendly primes (i.e. qi ≡ 1 mod 2N ) close to powers of two
QL
Qα−1
QL
Qα−1
such that log( i=0 qi × j=0 pj ) ≤ b. Set QL = i=0 qi , P = j=0 pj .
Define the following distributions over R: χkey with coefficients uniformly distributed over {−1, 0, 1} and exactly h non-zero coefficients. χpkenc with coefficients distributed over {−1, 0, 1} with respective probabilities {1/4, 1/2, 1/4}.
χerr with coefficients distributed according to a discrete Gaussian distribution with standard deviation σ and truncated to [−b6σc, b6σc].
• Encode (m, ∆, n, `) (coefficients→slots): For a message m ∈ Cn with 1 ≤
n < N , where n divides N , apply the canonical map Cn → R[Y ]/(Y 2n +1) →
0
0
2n
RQ` with Y = X N/2n . Compute m0 = FFT−1
n (m) and set m0 ||m1 ∈ R ,
−i
1
0
0
0
0
with m0 = 2 (m + m0 ) and m1 = 2 (m − m0 ), as a polynomial in Y .
Finally, scale the coefficients by ∆ and round them to the nearest integer,
apply the change of variable Y → X and return {pt, Q` , ∆}.
• Decode({pt, Q` , ∆}, n) (slots→coefficients): For 1 ≤ n < N , where n divides
N , apply the inverse of the canonical map RQ` → R[Y ]/(Y 2n + 1) → Cn ,
with Y = X N/2n . Map pt to the vector m00 ||m01 ∈ R2n and return m =
FFTn (∆−1 · (m00 + i · m01 )).
• SecKeyGen(·): Sample s ← χkey and return the secret key s.
• SwitchKeyGen(s, s0 , w): For w an integer decomposition basis of β elements,
sample ai ∈ RP QL and ei ← χerr and return the key-switch key: swk(s→s0 ) =
(0)

(β−1)

(i)

(swk(s→s0 ) , . . . , swk(s→s0 ) ), where swk(s→s0 ) = (−ai s0 + sw(i) P + ei , ai ).
• PubKeyGen(s): Set the public encryption key pk ← SwitchKeyGen(0, s, (1)),
the relinearization key rlk ← SwitchKeyGen(s2 , s, w), the rotation keys rotk ←
k
SwitchKeyGen(s5 , s, w) (a different key has to be generated for each different k), and the conjugation key conj ← SwitchKeyGen(s−1 , s, w) and return:
(pk, rlk, {rotk }k , conj).
• Enc({pt, Q` , ∆}, s): Sample a ∈u RQ` and e ← χerr , set ct = (−as + e, a) +
(pt, 0) and return {ct, Q` , ∆}.
• PubEnc({pt, Q` , ∆}, pk): Sample u ← χpkenc and e0 , e1 ← χerr , set:
ct = SwitchKey(u, pk) + (pt + e0 , e1 ) and return {ct, Q` , ∆}.
• SwitchKey(d, swks→s0 ): For d ∈ RQ` a polynomial1 , decompose d base w
such that d = hd, wi and return (d0 , d1 ) = bP −1 · hd, swks→s0 ie mod Q` for
P −1 ∈ R.
• Dec({ct, Q` , ∆}, s): For ct = (c0 , c1 ), return {pt = c0 + c1 s, Q` , ∆}.
The homomorphic operations of CKKS are detailed in Supplementary material A.
1
SwitchKey does not act directly in a ciphertext; instead, we define it as a generalized
intermediate function used as a building block that takes a polynomial as input.

6

2.2

J.P. Bossuat et al.

CKKS Bootstrapping

Let ct = (c0 , c1 ) be a ciphertext at level ` = 0, and s a secret key of Hamming weight h, such that Decrypt(ct, s) = [c0 + c1 s]Q0 = pt. The goal of the
bootstrapping operation is to compute a ciphertext ct0 at level L − k > 0
(where k is the depth of the bootstrapping circuit) such that QL−k  Q0 and
[c00 + c01 s]QL−k ≈ pt. Since [c0 + c1 s]QL = pt + Q0 · I, where I is an integer
polynomial [8], bootstrapping is equivalent to an extension of the CRT basis,
followed by a homomorphic reduction modulo Q0 .
Cheon et al. proposed the first procedure [8] to compute this modular reduction, by (i) homomorphically applying the encoding algorithm, to enable the
parallel (slot-wise) evaluation, (ii) computing a modular reduction approximated
by a scaled sine function on each slot, and (iii) applying the decoding algorithm
to retrieve a close approximation of pt without the polynomial I:


2πpt0
Q0
sin
= pt00 ⇒ Decode(pt00 ) ≈ pt .
Encode(pt + Q0 · I) = pt0 ⇒
{z
}
|
{z
}
|
2π
Q0
{z
}
|
(i) SlotsToCoeffs(pt+Q0 ·I)
(iii) CoeffsToSlots(pt00 )
(ii) EvalSine(pt0 )

The complexity of the resulting bootstrapping circuit is influenced by two parameters: The first one is the secret-key Hamming weight h, which directly impacts the √
depth of the bootstrapping circuit. Indeed, Cheon et al. show that
||I|| ≤ O( h) with very high probability. A denser key will therefore require
evaluating a larger-degree polynomial, with a larger depth. The second parameter is the number of plaintext slots n that has a direct impact on the complexity
of the circuit (but not on its depth). By scaling down the values to compress
them closer to the origin, Cheon et al. are able to evaluate the sine function
by using a low-degree Taylor series of the complex exponential and then use
repeated squaring (the double angle formula) to obtain the correct result. In
their approach, the sine evaluation dominates the circuit’s depth, whereas the
homomorphic evaluation of the encoding and decoding algorithms, which they
express as an n × n matrix-vector product, dominates its width.
In a subsequent work, Chen et al. [5] propose to compute the encoding by
homomorphically evaluating the Cooley-Tukey algorithm. This approach needs
log(n) depth (the number of iterations of the algorithm); to reduce this depth,
Chen et al. merge several iterations together, at the cost of an increased complexity. In a concurrent work, Cheon et al. [6] explored techniques to efficiently
evaluate DFTs on ciphertexts. They show how to factorize the encoding matrices into a series of logr (n) sparse matrices, where r is a power-of-two radix. The
contributions in [5, 6] enabled the acceleration of the homomorphic evaluation of
the encoding functions by two orders of magnitude. Chen et al. [5] also improved
the approximation of the scaled sine function by using a Chebyshev interpolant.
More recently, Han and Ki port the bootstrapping procedure to the fullRNS variant of CKKS, with several improvements to the bootstrapping circuit
and to the CKKS scheme [19]. They propose a generalization of its key-switch
procedure by using an intermediate RNS decomposition that enables a trade-off

Efficient Bootstrapping with Non-Sparse Keys

7

between the complexity of the key-switch and the homomorphic capacity of a
fresh ciphertext. They also give an alternative way to approximate the scaled
sine function, which accounts for the magnitude of the underlying plaintext and
uses the cosine function and the double angle formula. Combined, these changes
yield an acceleration factor of 2.5 to 3, compared to the work of Chen et al. [5].
Both works [6, 5] were implemented with HEAAN [20], yet the implementation of only the former was published. The work of [19] was implemented using
SEAL [27], but the implementation has still not been published.
2.3

Security of Sparse Keys

One commonality between all the aforementioned works is the use of sparse
secret-keys with a Hamming weight h = 64. A key with a small Hamming weight
enables a low-depth bootstrapping circuit, essential for its practicality. However,
recent advances in the cryptanalysis of the R-LWE problem prove that hybrid
attacks specifically targeting such sparse keys can severely affect its security [9,
28]. In light of the most recent attacks, Curtis and Player [11] estimate that, for
a sparse key with h = 64 and a ring degree N = 216 , the modulus needs to be
at most 990 bits to achieve a security of 128 bits. In their initial bootstrapping
proposal, Cheon et al. [8] use the parameters {N = 216 , log(Q) = 2480, h = 64,
σ = 3.2} and estimate the security of these parameters to 80 bits. In their work,
Han and Ki [19] propose new parameter sets, one of which they claim has 128-bit
of security: {N = 216 , log(Q) = 1450, h = 64, σ = 3.2}. However, these estimates
are based on results obtained using Albrecht’s estimator [2] that, at the time,
did not take into account the most recent attacks on sparse keys. The security
of the parameter set {N = 216 , log(Q) = 1250, h = 64, σ = 3.2} is estimated
at 113 bits in the more recent work by Son and Cheon [28]. This sets a loose
upper bound to security of the parameters (which have a 1450-bit modulus)
proposed by Han and Ki [19]. Therefore, the bootstrapping parameters must be
updated to comply with the most recent security recommendations, as none of
the parameters proposed in the current works achieve a security of 128 bits.

3

Homomorphic Polynomial Evaluation

The main disadvantage of the full-RNS variant of CKKS stems from its rescale
operation that does not divide the scale by a power-of-two, as in the original
scheme, but by one of the moduli. Those moduli are chosen, for efficiency purposes, as distinct NTT-friendly primes [7]; under this constraint, the power-oftwo rescale of the original CKKS scheme can only be approximated. As a result,
ciphertexts at the same level can have slightly different scales (depending on the
previous homomorphic operations) and additions between such ciphertexts will
introduce an error proportional to the difference between their scale. Addressing
this issue in a generic and practical way is crucial for the adoption of CKKS.
For a significant step toward this goal, we introduce a homomorphic polynomialevaluation algorithm that is depth-optimal and ensures that additions are always
made between ciphertexts with the exact same scale.

8

J.P. Bossuat et al.

Algorithm 1: BSGS alg. for polynomials in Chebyshev basis
P
Input: p(t) = di=0 ci Ti (t).
Output: The evaluation of p(t).
1 m ← dlog(d + 1)e
2 l ← bm/2c
3 T0 (t) = 1, T1 (t) = t
4 Evaluate T2 (t), T3 (t), . . . , T2l −1 (t) and T2l (t), T2l+1 (t), . . . , T2m−1 (t) using
Ti=a+b (t) ← 2Ta (t)Tb (t) − T|a−b| (t).
5 Find q(t) and r(t) such that p(t) = q(t) · T2m−1 (t) + r(t).
6 Recurse on step 5 by replacing p(t) by q(t) and r(t) and m by m − 1, until the
degree of q(t) and r(t) is smaller than 2l .
l
7 Evaluate q(t) and r(t) using Tj (t) for 0 ≤ j ≤ 2 − 1.
8 Evaluate p(t) using q(t), r(t) and T2m−1 (t).
9 return p(t)

3.1

The Baby-Step Giant-Step (BSGS) Algorithm

In order to minimize the number of ciphertext-ciphertext multiplications in their
bootstrapping circuit, Han and Ki [19] adapt a generic baby-step giant-step
(BSGS) polynomial-evaluation algorithm for polynomials expressed in a Chebyshev basis. Algorithm 1 gives a high-level description of the procedure.
For a polynomial p(t) of degree d, with m = dlog(d + 1)e and l = bm/2c,
Pbd/lc
the algorithm first decomposes p(t) into i=0 ui,2l (t) · T2i·l (t), with ui,2l (t) =
P2l −1
j=0 ci,j · Tj (t), ci,j ∈ C and T0≤j<2l a pre-computed power basis. We denote
ubd/lc,2l (t) as umax . The BSGS algorithm then recursively combines the monomials ui,2j+1 (t) = ui+1,2j (t)·T2j (t)+ui,2j (t) in a tree-like manner by using a second
pre-computed power basis T2l≤i<m (t) to minimize the number of non-scalar multiplications. The algorithm requires 2m−l + 2l + m − l − 3 + d(d + 1)/2l e non-scalar
products and has, in the best case, depth m.
3.2

Errorless Polynomial Evaluation

We address the errors introduced by the approximate rescale for the evaluation
of a polynomial p(t). We scale each of the leaf monomials ui,2l (t) by some scale
∆ such that all evaluations of the subsequent monomials ui,2j+1 (t) = ui+1,2j (t) ·
T2j (t) + ui,2j (t) are done with additions between ciphertexts of the same scale.
More formally, let ∆ui,2j+1 (t) be the scale of ui,2j+1 (t) (the result of the monomial
evaluation), ∆T2j (t) the scale of the power-basis element T2j (t), and qT2j (t) the
modulus by which the product ui+1,2j (t) · T2j (t) is rescaled. We set ∆ui+1,2j (t) =
∆ui,2j+1 (t) · qT2j (t) /∆T2j (t) and ∆ui,2j (t) = ∆ui,2j+1 (t) . Starting from a target
scale ∆p(t) and p(t) = u0,2m (t) = u1,2m−1 (t) · T2m−1 (t) + u0,2m−1 (t), we recursively
compute and propagate down the tree the scale each ui,2j (t) should have. The
recursion ends when reaching ui,2l , knowing the scale that they must have. Since
P2l −1
ui,2l (t) = j=0 ci,j Tj (t), we can use the same technique to derive by what value

Efficient Bootstrapping with Non-Sparse Keys

9

Algorithm 2: EvalRecurse
Input: A target scale ∆, an
P upper-bound m, a stop factor l, a degree-d
polynomial p(t) = di=0 ci Ti (t), and the power basis {T0 , T1 , . . . , T2l−1 }
and {T2l , T2l+1 , . . . , T2m−1 }, pre-computed for a ciphertext ct.
Output: A ciphertext encrypting the evaluation of p(ct).
l
1 if d < 2 then
2
if p(t) = umax (t) and l > 2m - 2l−1 and l > 1 then
3
return EvalRecurse(∆, m = dlog(d + 1)e, l = bdlog(d + 1)e/2c, p(t), T )
4
else
5
ct ← bc0 · ∆ · qTd e
6
for i = d; i > 0; i = i − 1 do
7
ct ← Add(ct, MultConst(Ti , b(ci · ∆ · qTd )/∆Ti e))
8
end
9
return Rescale(ct)
10
end
11 end
12 Express p(t) as q(t) · T2m−1 + r(t)
13 ct0 ← EvalRecurse((∆ · qT m−2 )/∆T m−1 , m − 1, l, q(t), T )
2
2
14 ct1 ← EvalRecurse(∆, m − 1, l, r(t), T )
15 ct0 ← Mul(ct0 , T2m−1 )
16 if level(ct0 ) > level(ct1 ) then
17
ct0 ← Add(Rescale(ct0 ), ct1 )
18 else
19
ct0 ← Rescale(Add(ct0 , ct1 ))
20 end
21 return ct0

each of the coefficients ci,j must be scaled, so that the evaluation of ui,2l (t) is
also done with exact additions and ends up with the desired scale.
Algorithm 2 is our proposed solution: it integrates our scale-propagation
technique to the recursive decomposition of p(t) into q(t) and r(t). We compare
Algorithms 1 and 2 in Table 1 by evaluating a Chebyshev interpolant of the
homomorphic modular reduction done during the bootstrapping circuit. This
function plays a central role in the bootstrapping hence is an ideal candidate for
evaluating the effect of the proposed approaches (see Section 5.4). To verify that
our algorithm correctly avoids additions between ciphertexts of different scales,
Table 1: Comparison of the homomorphic evaluation of a Chebyshev interpolant
of degree d of cos(2π(x − 0.25)/2r ) in the interval (−K/2r , K/2r ) followed by
r evaluations of cos(2x) = 2 cos2 (x) − 1. The scheme parameters are N = 216 ,
n = 215 , h = 196 and qi ≈ 255 . ∆ = |∆in − ∆out | · ∆−1
in .
log(1/) for (K, d, r)
(12, 34, 2) (15, 40, 2) (17, 44, 2) (21, 52, 2) (257, 250, 3)
Algorithm 1 ([19]) 2−31.44
30.36
30.05
29.73
29.19
25.00
Algorithm 2 (ours)
0
37.37
37.16
37.15
37.04
29.46
∆

10

J.P. Bossuat et al.

we forced both algorithms to always rescale a ciphertext before an addition (in
practice, it is better to check the levels of the ciphertexts before an addition,
and dynamically assess if a level difference can be used to scale one ciphertext to
the scale of the other). We observe that our algorithm yields two advantages: It
enables (i) a scale-preserving polynomial evaluation (the output-scale is identical
to the input scale), and (ii) a much better precision by successfully avoiding
errors due to additions between ciphertexts of different scales.
3.3

Depth-Optimal Polynomial Evaluation

In practice, Algorithm 1 will consume more than the optimal m levels for a
specific class of d due to the way the rescale and level management work in the
full-RNS variant of the CKKS scheme. This discrepancy arises from the following
interactions (recall that Algorithm 1 evaluates each ui (t) as a linear combination
of a pre-computed power-basis {T0 (t), T1 (t), . . . , T2l −1 (t)}):
1. If l > 1, then the depth to evaluate T2l −1 (t) is l and evaluating the ui (t) will
necessarily cost l + 1 levels due to the constant multiplications.
2. If l = 1, then the depth to evaluate T1 (t) is zero, hence the depth to evaluate
the ui (t) is and remains l.
3. If d > 8, then Algorithm 1 sets l > 1.
4. If 2m −2l−1 ≤ d < 2m , then all the elements of the power basis {T2l , T2l+1 , . . . , T2m−1 }
need to be used during the recombination step of Algorithm 1.
Hence, if l > 1 and d > 2m − 2l−1 , the total depth to execute Algorithm 1 is
necessarily m + 1. This could be avoided by always setting l = 1 regardless of
d, but it would lead to a very costly evaluation, as the number of non-scalar
multiplications would grow proportionally to d. To mitigate this additional cost,
we only enforce l = 1 on the coefficient of p(t) whose degree is ≥ 2m − 2l−1 .
Hence, Algorithm 2 first splits p(t) into p(t) = a(t) + b(t) · T2m −2l−1 (t). It then
evaluates a(t) with the optimal l and recurses on b(t) until l = 1. The number of
additional recursions is bounded by log(m), because each recursion sets the new
degree to half of the square root of the previous one. In practice, these additional
recursions add only dlog(d+1−(2m −2l−1 ))e non-scalar multiplications but enable
the systematic evaluation of any polynomial by using exactly m levels.
3.4

Conclusions

For an extra cost of dlog(d + 1 − (2m − 2l−1 ))e ciphertext-ciphertext products,
our proposed algorithm guarantees an optimal depth hence an optimal-level consumption. This extra cost is negligible, compared to the base cost of Algorithm
1, i.e., 2m−l + 2l + m − l − 3 + d(d + 1)/2l e. It also guarantees exact additions
throughout the entire polynomial evaluation, hence preventing the precision loss
related to additions between ciphertexts of different scales and making the procedure easier to use. It also enables the possibility to choose the output scale
that can be set to the same as the input scale, making the polynomial evaluation

Efficient Bootstrapping with Non-Sparse Keys

11

scale-preserving. As linear transformations and constant multiplications can already be made to be scale-preserving, our polynomial evaluation is the remaining
building block for enabling scale-preserving circuits of arbitrary depth.

4

Key-switch and Improved Matrix-Vector Product

The key-switch procedure is the generic public-key operation of the CKKS
scheme. By generating specific public key-switch keys derived from secret keys
s0 and s, it is possible to enable the public re-encryption of ciphertexts from key
s0 to s. Beyond the public encryption procedure (switching from s0 = 0 to s), a
key-switch is required by most homomorphic operations to cancel the effect of
encrypted arithmetic on the decryption circuit, thus ensuring the compactness of
the scheme. In particular, homomorphic multiplications require the re-encryption
from key s2 back to s, whereas slot-rotations require the re-encryption from the
equivalent rotation of s back to s. The cost of the key-switch dominates the
cost of these operations by one to two orders of magnitude because it requires
many NTTs and CRT reconstructions. Hence, optimizations of the key-switch
algorithm have a strong effect on the overall efficiency of the scheme.
We propose an optimized key-switch key format and key-switch algorithm
(Section 4.1). We then apply them to rotation-keys and further improve the
hoisted-rotation technique (Section 4.2) introduced by Halevi et al. [18]. Finally,
we propose a modified procedure for matrix-vector multiplications over packed
ciphertexts (Section 4.3) which features a novel double-hoisting optimization.
4.1

Improved Key-switch Keys

QL
Given a ciphertext modulus QL = j=0 qj , we use a basis w composed of
products among the qj , as described by Han and Ki [19]. We also include the
entire basis w in the keys, as done by Bajard et al. and Halevi et al. [3, 15]; this
saves one constant multiplication during the key-switch and enables a simpler
key-switch keys generation. A more detailed overview of these works can be
found in Supplementary material B.
We propose a simpler and more efficient hybrid approach. Specifically, we use
Qmin(α(i+1)−1,L)
qj for 0 ≤ i < β,
the basis w(i) = qQαL [( qQαL )−1 ]qαi with qαi = j=αi
i
i
β = d(L + 1)/αe and α a positive integer. In other words, Q is factorized into β
equally-sized composite-numbers qαi , each composed of up to α different primes.
Thus, our key-switch keys have the following format:


 
swk0qα , swk1qα = [−ai s + s0 · P · qQαL · [( qQαL )−1 ]qαi + ei ]P QL , [ai ]P QL .
i

i

Qα−1

i

i

We set P = j=0 pj , and the bit-size of P such that qαi ≤ P, ∀αi . As shown
by Gentry et al. [14], this leads to a negligible error introduced by the keyswitch operation. Algorithm 3 describes the associated key-switch procedure
that corresponds to the standard one adapted to our keys.

12

J.P. Bossuat et al.

Algorithm 3: Key-switch
Input: c ∈ RQ` , the key-switch key swks→s0 .
2
Output:
(a, b) ∈

 RQ` .
1 d ← [c]qα
0≤i<β P Q
`

(a, b) ← (hd, swk0 i, hd, swk1 i)
−1
3 (a, b) ← (bP
· ae, bP −1 · be)
4 return (a, b)

2

4.2

Improved Hoisted-Rotations

The slot-rotation operation in CKKS is defined by the automorphism φk : X →
k
X 5 (mod X N + 1). It rotates the message slots by k positions to the left. After
a rotation, the secret under which the ciphertext is encrypted is changed from s
to φk (s), and a key-switch φk (s) → s is applied to return to the original key.
Halevi et al. [18] show that as φk is an automorphism, it distributes over
addition and multiplication, and commutes with the power-of-two base decomposition. As φk acts individually on the coefficients by permuting them without
changing their norm (the modular reduction by X N + 1 at most induces a sign
change), it also commutes with the special RNS decomposition (see Supplementary material B): [φk (a)]qαi = φk ([a]qαi ).
Hence, when several rotations have to be applied on the sameP
ciphertext,
[a]qαi can be pre-computed and re-used for each subsequent rotation: φk ([a]qαi )·
rotk,qαi . This technique proposed by Halevi et al., called hoisting, significantly
reduces the number of NTTs and CRT reconstructions, at the negligible cost of
having to compute the automorphism for each of the [a]qαi .
We further exploit the properties of the automorphism to reduce its execution
cost, by observing that φ−1
k can be directly pre-applied on the rotation keys:
 
 0

1
QL
QL −1
f k,qα = [−ai φ−1
f k,qα , rot
]qαi + ei ]P QL , [ai ]P QL
rot
k (s) + s · P · qα · [( qα )
i

i

i

i

Compared to a rotk,qαi , a traditional rotation-key as defined in Section 2.1,
this reduces the number of automorphisms per-rotation to only one:

f ki .
hφk (a), rotk i = φk ha, rot
Our improved algorithm for hoisted rotations is detailed in Algorithm 4.
4.3

Faster Matrix-Vector Operations

We now discuss the application of homomorphic slot-rotations to the computation of matrix-vector products on packed ciphertexts. The ability to efficiently
apply generic linear transformations to encrypted vectors is pivotal for a wide
variety of applications of homomorphic encryption. In particular, the homomorphic evaluation of the CKKS encoding and decoding procedures, which are linear
transformations, dominates the cost in the original bootstrapping procedure.

Efficient Bootstrapping with Non-Sparse Keys

13

Algorithm 4: Optimized Hoisting-Rotations
2
f rk .
Input: ct = (c0 , c1 ) ∈ RQ
and a set of r rotation keys rot
`
Output:
v
a
list
containing
each
r
rotation
of
ct.
k


1 d ← [c1 ]qα
// (Decompose )
0≤i<β P Q
`

foreach rk do
f 0rk i, hd, rot
f 1rk i) // (MultSum )
3
(a, b) ← (hd, rot
−1
−1
4
(a, b) ← (bP · ae, bP · be) // (ModDown )
5
vrk ← (φrk (c0 + a), φrk (b)) // (Permute )
6 end
7 return v

2

Halevi and Shoup propose to express an n × n matrix M in diagonal form
and to use a baby-step giant-step
(BSGS) algorithm (Algorithm 5) to evaluate
√
the matrix product in O( n) rotations [16, 17]. At the time of this writing, all
the existing bootstrapping procedures for the CKKS scheme are based on this
approach and are not reported to use hoisting, unlike done for BGV [17, 18]. We
now break down the cost of this BSGS algorithm, analyze its components and,
using our observations, we present our improvements to this approach.
Algorithm 5: BSGS Algorithm of [18] For Matrix × Vector Multiplication
Input: ct a ciphertext encrypting m ∈ Cn , Mdiag the diagonal rows of M a
n × n matrix with n = n1 n2 .
Output: The evaluation ct0 = M × ct.
1 for i = 0; i < n1 ; i = i + 1 do
2
cti ← Rotatei (ct)
3 end
0
4 ct ← (0, 0)
5 for j = 0; j < n2 ; j = j + 1 do
6
r ← (0, 0)
7
for i = 0; i < n1 ; i = i + 1 do
(n1 ·j+i)
8
r ← Add(r, Mul(cti , Rotate−n1 ·j (Mdiag
)))
9
end
10
ct0 ← Add(ct0 , Rotaten1 ·j (r))
11 end
0
0
12 ct ← Rescale(ct )
0
13 return ct

Dominant Complexity of Rotations The dominant cost factor of Algorithm
5 is the number of rotations, as each rotation requires key-switch operations.
These rotations comprise four steps (see Algorithm 4):
1. Decompose: Decompose a polynomial of RQ` in base w and return the result
in RP Q` . This operation requires NTTs and CRT basis extensions.
2. MultSum: Compute a sum of products of polynomials in RP Q` . This operation only requires coefficient-wise additions and multiplications.
3. ModDown: Divide a polynomial of RP Q` by P and return the result in RQ` .
This operation requires NTTs and CRT basis extensions.

#MulZp op./#MulZp tot.

14

J.P. Bossuat et al.
Decompose

MultSum

ModDown

Permute

1

0.5

0
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
`

Fig. 1: Normalized complexity of each step (op.) of a rotation. The complexity
for each operation was computed with N = 216 , 0 ≤ ` ≤ 23 and α = 4. The
complexity derivation can be found in Supplementary material C.2.
4. Permute: Apply the automorphism φk on a polynomial of RQ` . It represents
a permutation of the coefficients and has in theory no impact on complexity.
Let n be the number of non-zero diagonals of M , and n1 , n2 be two integers
such that n = n1 n2 ; the complexity of the original BSGS algorithm (Algorithm
5) is n1 + n2 rotations and it is minimized when n1 ≈ n2 :
(n2 + n1 ) · (Decompose + MultSum + ModDown + Permute),
to which 2n2 n1 multiplications in RQ` should also be added (line 8 of Algorithm 5). We denote inner-loop and outer-loop the lines that depend, respectively, on n1 and n2 . Figure 1 shows the weight of each of the four steps in the
total complexity. The complexity of the steps MultSum and Permute is negligible compared to the complexity of Decompose and ModDown, as products and
additions are very inexpensive compared to NTTs and CRT basis extensions.
We base our optimization on this observation.
Improved BSGS Algorithm We propose a new optimization that we refer to
as double-hoisting. This optimization improves the hoisting technique proposed
by Halevi et al. [18] and further reduces the complexity related to the inner-loop
rotations by adding a second layer of hoisting.
The first level, proposed by Halevi et al. [18], applies to the inner-loop rotations (line 8 of Algorithm 5). This renders the computation devoted to Decompose
independent of the value n1 , so the complexity is reduced to
(n2 + n1 ) · (MultSum + ModDown + Permute) + (n2 + 1) · Decompose.
The second level, which we propose, introduces an additional hoisting for
the inner-loop rotations, as the ModDown step is a coefficient-wise operation.
Similarly to the Decompose step, this operation commutes with the Permute step
and the ciphertext-plaintext multiplications (line 8 of Algorithm 5). Therefore,
we need to apply it only once after the entire inner-loop of n1 rotations. Applying

Efficient Bootstrapping with Non-Sparse Keys

15

Algorithm 6: Double-hoisting BSGS matrix×vector algorithm
2
Input: ct = (c0 , c1 ) ∈ RQ
, Mdiag ∈ RP Q` the pre-rotated diagonals of Mn×n ,
`
2
n1 n2 = n, roti ∈ RP
Q` the set of necessary rotations keys.
0
Output:
ct
=
M
×
ct.


1 d ← [c1 ]qα
// Decompose Q` → P Q`
0≤i<β P Q
`

(a0 , b0 ) ← (P · c0 , P · c1 )
3 for i = 1; i < n1 ; i = i + 1 do
f 0i i) // MultSum & Permute ∈ P Q`
4
ai ← φi (a0 + hd, rot
f 1i i) // MultSum & Permute ∈ P Q`
5
bi ← φi (hd, rot
6 end
0
0
7 (c0 , c1 ) ← (0, 0)
8 for j = 0; j < n2 ; j = j + 1 do
9
(u0 , u1 ) ← (0, 0)
10
for i = 0; i < n1 ; i = i + 1 do
(n1 ·j+i)
11
(u0 , u1 ) ← (u0 , u1 ) + (ai , bi ) · Mdiag
// ct × pt ∈ P Q`
12
end
13
u1 ←bP −1 · u1 e //
 ModDown P Q` → Q`
14
d ← [u1 ]qα0≤i<β P Q // Decompose Q` → P Q`
2

`

f 0n1 ·j i) // MultSum & Permute ∈ P Q`
c00 ← c00 + φn1 ·j (u0 + hd, rot
f 1n1 ·j i) // MultSum & Permute ∈ P Q`
16
c01 ← c01 + φn1 ·j (hd, rot
17 end
0
−1
18 ct ← (bP
· c00 e, bP −1 · c01 e) // ModDown P Q` → Q`
0
19 return Rescale(ct )
15

the same reasoning for the ModDown step of the outer-loop rotations we can
reduce the number of key-switch operations from n1 + n2 to n2 + 1:
(n2 + n1 ) · (MultSum + ModDown) + (n2 + 1) · (Decompose + ModDown).
Algorithm 6 describes our double-hoisting BSGS for matrix-vector products.
Discussion In addition to benefiting from our improved key-switch (Section
4.1) and rotation (Section 4.2) procedures, Algorithm 6 introduces a trade-off:
The ModDown step in the inner-loop now depends on the value n2 , and the
ModDown step of the outer-loop is performed only once. However, the 2n1 n2
multiplications and additions are performed in RP Q` instead of RQ` . Hence,
the complexity dependency on n1 is significantly reduced at the cost of slightly
increasing the dependency on n1 n2 . Applying the ModDown step at the end of
each loop has the additional benefit of introducing the rounding error only once.
Table 2 compares the complexity of a non-hoisted, single-hoisted (Algorithm
5) and double-hoisted (Algorithm 6) BSGS, each with its optimal ratio n1 /n2 .
Our approach minimizes the complexity when 23 ≤ n1 /n2 ≤ 24 . This shows
that the strategy of the previously proposed bootstrapping procedures [8, 5,
19], which minimize the number of rotations by setting n1 ≈ n2 , is not optimal
anymore. The maximum gain occurs when n (the number of non zero diagonals)

16

J.P. Bossuat et al.

Table 2: Complexity of Algorithm 5 [16], 1-hoisted Algorithm 5 [18] and our
2-hoisted Algorithm 6. M is a 215 ×215 matrix with n = n1 n2 non zero diagonals.
The used parameters are N = 216 , n = 215 , ` = 18, α = 4. The speed-up factor
is the ratio between the #MulZp , taking as baseline the 1-hoisted approach.

No hoisting [16]
1-hoisted [18]
2-hoisted (proposed)
n
n1 /n2 log(#MulZp ) Speed-up n1 /n2 log(#MulZp ) n1 /n2 log(#MulZp ) Speed-up
32768
2
37.276
0.777×
2
36.913
8
36.789
1.089×
16384
1
36.500
0.765×
4
36.114
16
35.880
1.176×
8192
2
35.865
0.706×
2
35.364
8
35.014
1.275×
4096
1
35.152
0.705×
4
34.648
16
34.167
1.396×
2048
2
34.597
0.652×
2
33.981
8
33.381
1.515×
1024
1
33.927
0.664×
4
33.337
16
32.613
1.651×
512
2
33.422
0.619×
2
32.732
8
31.920
1.756×
256
1
32.769
0.645×
4
32.137
16
31.234
1.869×
128
2
32.282
0.609×
2
31.568
8
30.626
1.920×
64
1
31.614
0.649×
4
30.992
16
30.011
1.974×
32
2
31.112
0.623×
2
30.430
8
29.471
1.943×
16
1
30.375
0.682×
4
29.842
16
29.100
1.672×
8
2
29.792
0.685×
2
29.248
8
28.872
1.297×

is around 128. This can be exploited by factorizing the linear transforms, used
during the bootstrapping, into several sparse matrices (see Section 5.3).
Increasing the ratio from n2 /n1 ≈ 1 to n2 /n1 ≈ 16 in our bootstrapping
parameters (Section 6) increases the number of keys by a factor around 1.6 and
reduces the computation time by 20%. Hence, Algorithm 6 reduces the overall
complexity of matrix-vector products, by introducing a time-memory trade-off.
We also observe that these improvements are not restricted to plaintext matrices or to the CKKS scheme and can be applied to other R-LWE scheme, such
as BGV [4] or BFV [12], as long as the scheme (or its implementation) allows for
the factorization of an expensive operation. For example, in the BFV scheme,
the quantization (division by Q/t) (as well as the re-linearization if the matrix
is in ciphertext) can be delayed to the outer-loop.

5

Bootstrapping for the Full-RNS CKKS Scheme

We present our improved bootstrapping procedure for the full-RNS variant of
the CKKS scheme. We follow the high-level procedure of Cheon et al. [8] and
adapt each step by relying on the techniques proposed in Sections 3 and 4.
The purpose of the CKKS bootstrapping [8] is, in contrast with BFV’s [12],
not to reduce the error. Instead, and similarly to BGV [4] bootstrapping, it
is meant to reset the ciphertext modulus to a higher level in order to enable
further homomorphic multiplications. The approximate nature of CKKS, due
to the plaintext and ciphertext error being mixed together, implies that each
homomorphic operation decreases the output precision. As a result, all the currently proposed bootstrapping circuits only approximate the ideal bootstrapping
operation, and their output precision also determines their practical utility.

Efficient Bootstrapping with Non-Sparse Keys

5.1

17

Circuit Overview

Let {ct = (c0 , c1 ), Q0 , ∆} be a ciphertext that encrypts an n-slot message under
a secret-key s with Hamming weight h, such that Decrypt(ct, s) = c0 + sc1 =
b∆·m(Y )e+e ∈ Z[Y ]/(Y 2n +1), where Y = X N/2n . The bootstrapping operation
outputs a ciphertext {ct0 = (c00 , c01 ), QL−k , ∆} such that c00 + sc01 = b∆ · m(Y )e +
e0 ∈ Z[Y ]/(Y 2n + 1), where k < L is the number of levels consumed by the
bootstrapping and ||e0 || ≥ ||e|| is the error that results from the combination of
the initial error e and the error induced by the bootstrapping circuit.
The bootstrapping circuit is divided into the five steps detailed below. We
provide a schematic view of this circuit (for our implementation) in Supplementary material F. For the sake of conciseness, we describe the plaintext circuit
and omit the error terms.
1. ModRaise: ct is raised to the modulus QL by applying the CRT map Rq0 →
Rq0 × Rq1 × · · · × RqL . This yields a ciphertext {ct, QL , ∆} for which
[c0 + sc1 ]QL = Q0 · I(X) + b∆ · m(Y )e = m0 ,


where Q0 · I(X) = − [sc1 ]Q0 + sc1 Q is an integer polynomial for which
L
√
||I(X)|| is O( h) [8]. The next four steps remove this unwanted Q0 · I(X)
polynomial by homomorphically evaluating an approximate modular reduction by Q0 .
2. SubSum: If 2n 6= N , then Y 6= X and I(X) is not a polynomial in Y . SubSum
˜ )+b∆·m(Y )e), a polynomial
maps Q0 ·I(X)+b∆·m(Y )e to (N/2n)·(Q0 · I(Y
in Y [8].
˜ ) + b∆ · m(Y )e is in the coeffi3. CoeffsToSlots: The message m0 = Q0 · I(Y
cient domain, which prevents slot-wise evaluation of the modular reduction.
This step homomorphically evaluates the inverse discrete-Fourier-transform
(DFT) and produces a ciphertext encrypting Encode(m0 ) that enables the
slot-wise evaluation of the approximated modular reduction.
Remark : This step returns two ciphertexts, each encrypting 2n real values.
If 4n ≤ N , these ciphertexts can be repacked into one. Otherwise, the next
step is applied separately on both ciphertexts.
4. EvalSine: The modular reduction f (x) = x mod 1 is homomorphically evaluated on the ciphertext(s)
encrypting
Encode(m0 ). This function is approxi

Q0
2π∆x
mated by
· sin
, which is tight when Q0 /∆  ||m(Y )||. As the
2π∆
Q0
˜ )||, the approximation needs to account for
range of x is determined by ||I(Y
the secret-key density.
5. SlotsToCoeffs: This step homomorphically evaluates the DFT on the ciphertext encrypting f (Encode(m0 )). It returns a ciphertext at level L − k that
encrypts Decode(f (Encode(m0 ))) ≈ f (m0 ) ≈ b∆ · m(Y )e, which is a close
approximation of the original message.
We now detail our approach for each step.

18

5.2

J.P. Bossuat et al.

ModRaise and SubSum

We base the ModRaise and SubSum operations directly on the initial bootstrapping of Cheon et al. [8]. The SubSum step multiplies the encrypted message by a
factor N/2n that needs to be subsequently cancelled. We take advantage of the
following CoeffsToSlot step, a linear transformation, to scale the corresponding
matrices by 2n/N . As we also use this trick for grouping other constants, we
elaborate more on the matrices scaling in Section 5.5.
5.3

CoeffsToSlots and SlotsToCoeffs

Let n be a power-of-two integer such that 1 ≤ n < N ; the following holds for any
two vectors m, m0 ∈ Cn due to the convolution property of the complex DFT
Decoden (Encoden (m) ⊗ Encoden (m0 )) ≈ m

m0 ,

where ⊗ and
respectively denote the nega-cyclic convolution and Hadamard
multiplication. I.e., the encoding and decoding algorithms define an isomorphism
between R[Y ]/(Y 2n + 1) and Cn [10]. The goal of the CoeffsToSlots and SlotsToCoeffs steps is to homomorphically evaluate this isomorphism on a ciphertext.
Let ψ = eiπ/n be a 2n-th primitive root of unity. As 5 and −1 mod 2n
k
span Z2n , {ψ 5 , ψ 5k , 0 ≤ k < n} is the set of all 2n-th primitive roots of unity.
Given a polynomial m(Y ) ∈ R[Y ]/(Y 2n + 1) with Y = X N/2n , the decoding
algorithm is defined as the evaluation of this polynomial at each root of unity
2n−1
Decoden (m(Y )) = (m(ψ), m(ψ 5 ), . . . , m(ψ 5
)). The decoding isomorphism is
k
fully defined by the n×n special Fourier transform matrix SFn,(j,k) = ψ j5 , with
T

1
inverse (the encoding matrix) SF−1
n = n SFn [6]. Its homomorphic evaluation can
be expressed in terms of plaintext matrix-vector products:

−1
−1
1
1. CoeffsToSlots(m) : t0 = 12 SF−1
n × m + SFn × m , t1 = − 2 i(SFn × m −

−1
SFn × m
2. SlotsToCoeffs(t0 , t1 ) : m = SFn × (t0 + i · t1 ).

DFT Evaluation In their initial bootstrapping proposal, Cheon et al. [8]√homomorphically compute the DFT as a single matrix-vector product in O( n)
rotations and depth 1, by using the baby-step giant-step (BSGS) approach of
Halevi and Shoup [17] (Algorithm 5 in Section 4.3). To further reduce the complexity, two recent works from Cheon et al. [6] and Chen et al. [5] exploit the
structure of the equivalent FFT
√ algorithm by recursively merging its iterations,
reducing the complexity to O( r logr (n)) rotations at the cost of increasing the
depth to O(logr (n)), for r a power-of-two radix between 2 and n.
We base our approach on the work of [6] and [5], and we use our double
hoisting BSGS to evaluate the matrix-vector products (see Section 4.3 and Algorithm 6). This step is parameterized by ρ = dlogr (n)e, the depth of the linear
transformation (i.e., the number of matrices that we need to evaluate).

log(#MulZp )

Efficient Bootstrapping with Non-Sparse Keys
37

37

37

36

36

36

35

35

35

34

34

34

33

33

33

32

32

32

31

−8−6−4−2 0 2 4 6 8
log(n1 /n2 )

(a)SF−1
n = M256× M256

31

−6 −4 −2 0 2 4 6
log(n1 /n2 )

31

19

Original
1-Hoisted
2-Hoisted

−6 −4 −2 0

2

4

log(n1 /n2 )

−1
(b)SF−1
n = M32 ×M64 ×M64 (c)SFn = M16×M32×M32×M16

Fig. 2: Theoretical complexity of CoeffToSlots for different ρSF−1
using Algon
rithm 5 with no hoisting, single hoisting, and double hoisting (Algorithm 6).
Figure 2 shows the effect of our algorithm on the CoeffsToSlots step, com= {2, 3, 4}. The complexity is
pared with the original BSGS algorithm for ρSF−1
n
computed as the number of products in Zp , with parameters N = 216 , a target
` = 17 (the level after CoeffsToSlots) and n = 215 slots.
Each level of hoisting reduces the total complexity by a noticeable amount.
Regular hoisting, as proposed by Halevi and Shoup [18], achieves its minimum
complexity when n1 ≈ 22 n2 instead of n1 ≈ n2 . Using our double hoisting, the
minimum complexity is further shifted to n1 ≈ 24 n2 . On average, our method
reduces the complexity of the linear transformations in the bootstrapping by a
factor of 2× compared to the single hoisting technique of Halevi and Shoup.

Efficient Repacking of Sparse Plaintexts. The first part of CoeffsToSlots
is a DFT that outputs a vector of Cn values; the second part of CoeffsToSlots
applies the map Cn → R2n to this vector. During the decoding, the inverse
mapping R2n → Cn is used. This map can be computed with simple operations,
e.g., conjugation, multiplication by −i, and additions. If the original ciphertext
is not fully packed (0 < n < N/2 slots), the two resulting ciphertexts can be
merged into one, requiring one evaluation of EvalSine instead of two.
We observe that decoding a plaintext m ∈ Cn by using the decoding algok
rithm for a plaintext of C2 n slots (assuming that 2k n < N ) outputs a vector
comprising 2k concatenated replicas of m. Therefore, a ciphertext that encrypts
m ∈ Cn can also be seen as a ciphertext encrypting m0 ∈ C2n for m0 = m||m.
This property can be used to save two levels when repacking and unpacking
ciphertexts before and after the EvalSine:
• Repacking before the EvalSine (Cn → R2n ): Repacking into one ciphertext is done by extending the domain of the plaintext vectors of the last
matrix of the CoeffsToSlots step from Cn to Cn ||0n . Thus, the last n slots
are set to zero and can be used to store the imaginary part of the first n slots.

20

J.P. Bossuat et al.

This repacking involves one additional rotation and it does not consume any
additional levels.
• Unpacking after the EvalSine (R2n → Cn ): For this operation, we evaluate the following 2n × 2n matrix on the ciphertext before the DFT


In i · In
,
In i · In
where In is the n × n identity matrix. Its effect is to homomorphically apply
the map R2n → Cn ||Cn , which is a valid encoding of Cn , due to the properties of the encoding algorithm. This additional matrix (transformation) is
combined with the first group of the SlotsToCoeffs matrices, thus slightly
increasing its density.
5.4

EvalSine

EvalSine implements the homomorphic modular reduction of the message m0 =
˜ ) + ∆ · m(Y ) modulo Q0 . The modular reduction is approximated by
Q0 · I(Y




∆
∆
Q0
Q0 1
sin 2πx
·
x mod 1 ,
≈
f (x) =
∆ 2π
Q0
∆
Q0
˜ ) + (∆/Q0 ) · m(Y ), removes the I(Y
˜ )
which scales the message m0 down to I(Y
polynomial by reducing the message modulo 1, and scales the message back to
˜ ) determines the range and degree of the approximation, the
∆ · m(Y ). As I(Y
EvalSine step has to account for the secret-key density h. In particular, the range
˜ )|| > K] ≤ κ for a
of the approximation (−K, K) is chosen such that Pr[||I(Y
user-defined κ. We elaborate more on how we parameterize K, in Section 6.2.
1
Previous Work Chen et al. [5] directly approximate the function 2π
· sin(2πx)
by using a standard Chebyshev interpolant of degree d = 119 in an interval
of (−K, K) for K = 12 (using a sparse key with h = 64). Han and Ki [19]
approximate cos(2π 21r (x − 0.25)) followed by r iterations of the double angle
formula cos(2x) = 2 cos(x)2 − 1 to obtain sin(2πx). The factor 1/2r reduces the
range of the approximation to (−K/2r , K/2r ), enabling the use of a smallerdegree interpolant. They combine it with a specialized Chebyshev interpolation
that places the node around the expected intervals of the input. This reduces
the degree of the approximation and the cost of its evaluation. In their work,
they use an interpolant of degree 30 with a scaling factor r = 2 (they also use a
sparse key with h = 64).
In a recent work, Lee et al. [24] propose to compose the sine/cosine function
with a low degree arcsine. This additional step corrects the error introduced by
the sine, especially if Q0 /∆ is small (when the values are not close to the origin).
This improves the overall precision of the bootstrapping and enables bootstrapping messages with larger values. However, this comes at the cost of increasing
the depth of the EvalSine step, as a second polynomial must be evaluated.

Efficient Bootstrapping with Non-Sparse Keys

21

Our Work Both the methods of Chen et al. and Han and Ki have d = O(K),
therefore doubling K requires at most doubling d, and the evaluation will require
at most one additional level, as the Chebyshev interpolant can be evaluated in
O(log(K)) levels. Hence, precision put aside, the level consumption should not be
a fundamental problem when evaluating the large degree interpolant (as required
by dense keys). However, the effects of the approximate rescale procedure, if not
properly managed, can significantly reduce the output precision. Our EvalSine
makes use of our novel polynomial evaluation technique (Section 3).
We propose a more compact expression of the modular reduction function
1
sin(2πx), which is approximated by gr (x), a modified scaled cosine
f (x) = 2π
followed by r iterations of the double-angle formula:

1
cos 2π 21r (x − 0.25) and gi+1 = 2gi2 −
g0 (x) = 2√
r
2π

1
√
2r
2π

!2i
.

We include the 1/2π factor directly in the function we approximate, even
when using the double angle formula, without consuming an additional level,
impacting the precision, or fundamentally changing its evaluation. We observed
that even though the approximation technique of Han and Ki is well suited for
small K, the standard Chebyshev interpolation technique, as used by Chen et
al., remains more efficient when K is large. The reason is that Han and Ki’s
interpolant has a minimum degree of 2K − 1, so it grows in degree with respect
to K much faster than the standard Chebyshev interpolation. Hence, we use the
approximation method of Han and Ki when K is small (for sparse keys) and the
standard Chebyshev approximation, as done by Chen et al., for dense keys.
As suggested by Lee et al. [24], we can further improve this step by compos1
ing it with arcsin(x), i.e., 2π
arcsin(sin(2πx)), which corrects the error egr (x) =
|gr (x) − x mod 1|. Unlike Lee et al., we do not interpolate the arcsine, rather
we choose to use a low degree Taylor polynomial and show in our results (see
Section 7.2) that it is sufficient to achieve similar results.
Algorithm 7 details our implementation of the EvalSine procedure. The ciphertext must be multiplied by several constants, before and after the polynomial
evaluation. For efficiency, we merge these constants with the linear transformations. See Section 5.5 for further details.
5.5

Matrix Scaling

Several steps of the bootstrapping circuit require the ciphertexts to be multiplied
by constant plaintext values. This is most efficiently done by merging them and
pre-multiplying the resulting constants to the SF−1
n and SFn matrices.
Before EvalSine, the ciphertext has to be multiplied (i) by 1/N to cancel the
N/2n and 2n factors introduced by the SubSum and CoeffsToSlots steps, (ii)
by 1/(2r K) for the scaling by 1/2r and change of variable for the polynomial
evaluation in Chebyshev basis, and (iii) by Q0 /2dlog(Q0 )e to compensate for the
error introduced by the approximate division by bQ0 /∆e. Therefore, the matrices

22

J.P. Bossuat et al.

Algorithm 7: EvalSine
Input: {ct, Q` , ∆} a ciphertext, p(t) a Chebyshev interpolant of degree d of
f (x) = x mod 1, K the range of interpolation, r a scaling factor.
Output: The evaluation ct0 = bQ0 /∆e · p(bQ0 /∆e−1 · ct).
1 ∆ ← ∆ · bQ0 /∆e // Division by bQ0 /∆e
2 T0 ← 1
r+1
3 T1 ← AddConst(ct, −0.5/(2
K))
4 m ← dlog(d + 1)e
5 l ← bm/2c
6 T ← {T0 , T1 , . . . , T2l ; T2l+1 , . . . , T2m−1 } // Compute the power basis
7 for i = 0; i < r; i = i + 1 do
p
8
∆ ← ∆ · qL−CtS depth−EvalSine depth−r+i // Pre-compute target ∆
9 end
0
10 ct ← EvalRecurse(∆, m, l, p(t), T ) (Algorithm 2) // Outputs ct’ with target
∆ scale
11 for i = 0; i < r; i = i + 1 do
r−i
12
ct0 ← AddConst(2 · Mul(ct0 , ct0 ), −(1/2π)1/2 )
0
0
2
13
ct ← Rescale(ct ) // ∆ ← ∆ /qL−CtS depth−EvalSine depth−i
14 end
−1
15 ∆ ← ∆ · bQ0 /∆e
// Multiplication by bQ0 /∆e
0
16 return ct

resulting from the factorization of SF−1
n are scaled by
! 1
ρSF−1
1
Q0
n
µCtS =
,
· blog(Q )e
r
0
2 KN 2
where ρSF−1
is the degree of factorization of SF−1
n . Evenly spreading the scaling
n
factors across all matrices ensures that they are scaled by a value as close as
possible to 1.
After EvalSine, the ciphertext has to be multiplied (i) by 2dlog(q0 )e /Q0 to compensate for the error introduced by the approximate multiplication by bQ0 /∆e,
and (ii) by ∆/δ, where ∆ is the scale of the ciphertext after the EvalSine step
and δ is the desired ciphertext output scale. Therefore, the matrices resulting
from the factorization of SFn are scaled by
! 1
blog(Q0 )e
ρSFn
∆ 2
µStC =
·
,
δ
Q0
where ρSFn is the degree of factorization of SFn .

6

Parameter Selection

A proper parameterization is paramount to the security and correctness of the
bootstrapping procedure. Whereas security is based on traditional hardness assumptions, setting the correctness-related parameters is accomplished mostly

Efficient Bootstrapping with Non-Sparse Keys

23

Table 3: Modulus size log(QP ) for different secret-key densities h (λ ≥ 128).
log(QP )
log(QP, N ), λ ≥ 128 N = 215 N = 216
64 0.015121N − 8.248756 496
982
96 0.018896N − 3.671642 619
1234
128 0.021370N − 3.601990 699
1396
192 0.023448N − 3.611940 767
1533
N/2
[11]
881
1782
h

through experimental processes for finding appropriate trade-offs between the
performance and the probability of decryption errors. In this Section, we discuss
various constraints and inter-dependencies in the parameter selection. Then, we
propose a generic procedure for finding appropriate parameter sets.
6.1

Security

For each parameter set, we select a modulus size with an estimated security of
128 bits. These values are shown in Table 3 for several choices of the secret-key
Hamming weight h, and are based on the work of Curtis and Player [11]. According to the authors, these parameters result from conservative estimations,
and account for hypothetical future improvements to the most recent attacks of
Cheon et al. [9] and Son et al. [28]. Therefore, their actual security is underestimated.
6.2

Choosing K for EvalSine

˜ ) ∈ R[Y ]/(Y 2n + 1) is the result of the
Each coefficient of the polynomial I(Y
sum of h + 1 uniformly distributed variables in ZQ0 [8], hence it follows an Ir˜ ),
win–Hall distribution [24]. By centering and normalizing the coefficients of I(Y
we get instead the sum of h + 1 uniformly distributed variables in (−0.5, 0.5).
˜ )|| > K] can be computed by adapting the cumulative
The probability Pr[||I(Y
probability function of the Irwin-Hall distribution:


2n


bK+0.5(h+1)c
X
2
h+1
1 − 
(−1)i
(K + 0.5(h + 1) − i)h+1  − 1 .
i
(h + 1)!
i=0
(1)
The previous works [8, 5, 6, 19] use a sparse key with h = 64 and K = 12,
which regardless of the security, gives a failure probability of 2−14.7 and 2−6.7
for n = 27 and n = 215 respectively, according to Equation (1). Clearly, these
parameters were not chosen for large n and are most likely an artifact of the first
proposal for a bootstrapping for CKKS [8], for which only a small number of
slots was practical. In our work, we increase h to ensure an appropriate security
and use a much larger number of slots (e.g., n = 215 ), hence we need to adapt
K. Table 4 shows that if we target a failure probability
≤ 2−15.0 for n = 215
√
slots and take h as a parameter, then K ≈ 1.81 h.

24

J.P. Bossuat et al.

˜ )|| > K] ≈ 2−16 for n = 215 and variable h.
Table 4: Pr[||I(Y
log2 (h)
6
7
8
9
10 11 12 13 14 15
K
14 20 29 41 58 82 116 163 232 328
˜ )|| > K]) -14.6 -14.6 -15.7 -15.6 -15.5 -15.4 -15.4 -15.4 -15.4 -15.4
log2 (Pr[||I(Y
√
K/ h
1.75 1.76 1.81 1.81 1.81 1.81 1.81 1.81 1.81 1.81

Table 5: The sets of parameters of the full-RNS CKKS used to evaluate the
performance of our bootstrapping code. + means concatenation in the chain and
a · b denotes the consecutive concatenation of a different moduli of size b. Moduli
with fractional a are only partially used by the step they are allocated to.
Parameters
Set

h

I
192
240
II 192 16 245
2
III 192
230
IV 32768
245
15 25
V 192 2 2

6.3

log(qi )
log(pj )
q0≤i≤(L−k)
StC
Sine CtS
24 60 + 9 · 40 3 · 39 8 · 60 4 · 56 5 · 61
23 60 + 5 · 45 3 · 42 11 · 60 4 · 58 4 · 61
21 55 + 7.5 · 60 1.5 · 60 8 · 55 4 · 53 5 · 61
27 50 + 9 · 40 56 + 28 12 · 60 4 · 53 6 · 61
13 33 + 50 + 25 60
8 · 50 2 · 49 2 · 50

N ∆ log(QP ) L
1546
1547
1553
1792
768

Finding Parameters

We describe a general heuristic procedure for selecting and fine-tuning bootstrapping parameters. Each operation of the bootstrapping requires a different
scaling and a different precision, therefore different moduli. Choosing each modulus optimally for each operation not only leads to a better performance and a
better final precision but also optimizes the bit consumption of each operation
and increases the remaining homomorphic capacity after the bootstrapping.
We describe our procedure to find suitable parameters for the bootstrapping
in Algorithm 8 and propose five reference parameter sets that result from this
algorithm. The parameter sets were selected for their performance and similarity
with those in previous works, thus enabling a comparison. For each set, Table 5
shows the parameters related to CKKS and to the bootstrapping circuit.

7

Evaluation

We implemented the improved algorithm of Sections 3 and 4, along with the
bootstrapping procedure of Section 5 in the Lattigo library [23]. We evaluated it by using the parameters of Section 6.3. Lattigo is an open-source library that implements the RNS variants of the BFV [12, 3, 15] and CKKS [7]
schemes in Golang [29]. All experiments were conducted single-threaded on an
i5-6600k at 3.5 GHz with 32 GB of RAM running Windows 10 (Go version
1.15.6, GOARCH=amd64, GOOS=windows).

Efficient Bootstrapping with Non-Sparse Keys

25

Algorithm 8: Heuristic Parameter Selection
Input: λ a security parameter.
, ρSFn ).
Output: The parameters (N, n, h, QL , P, κ, α, dsin , r, darcsin , ρSF−1
n
1 Select n, N and h and derive log(P QL ) according to λ.
2 Given ∆ (the scale of the message), compute the ratio Q0 /∆ and select the
bootstrapping output precision δ.
3 Given a target failure probability κ, estimate K using Equation (1).
4 Given the bootstrapping output precision δ, find dsin (the degree of the sine
polynomial), r (the number of double angle) and darcsin (the degree of the
arcsine polynomial) such that the polynomial approximation of x mod 1 of
the EvalSine step in the interval (−K/2r , K/2r ) gives a precision greater than
log(Q0 /∆) + δ bits.
5 Select ρSF−1 and ρSFn (the depth of the CoeffsToSlots and SlotsToCoeffs steps).
n
6 Allocate the qj of the CoeffsToSlots, EvalSine and SlotsToCoeffs steps, with the
maximum possible bit-sizeQfor all qj .
α−1
7 Select α and allocate P =
j=0 pj , ensuring that P ≈ β||qαi ||.
8 Run the bootstrapping and find the minimum values for dsin , r and darcsin
such that the output has δ bits of precision.
9 Run the bootstrapping and find the minimum bit-size for the qj of the EvalSine
such that the output reaches the desired precision or until it plateaus.
10 Run the bootstrapping and find the minimum bit-size for the qj of the
CoeffsToSlots such that the output precision is not affected.
11 Run the bootstrapping and find the minimum bit-size for the qj of the
SlotsToCoeffs such that the output precision is not affected.
12 Allocate the rest of the moduli of QL such that log(P QL ) ensures a security of
at least λ and check again step 7.
13 If additional residual homomorphic capacity is needed or the security λ cannot
be achieved
1. Reduce α, ρSF−1
and/or ρSFn and check again line 6.
n
2. Increase h to increase log(P QL ) and restart at line 1.
3. Increase N to increase log(P QL ) and restart at line 1.
return (N, n, h, QL , P, κ, α, dsin , r, darcsin , ρSF−1
, ρSFn )
n

7.1

The Bootstrapping Metrics

Although CPU costs are an important aspect when evaluating a bootstrapping
procedure, these factors have to be considered together with other performancerelated metrics such as the size of the output plaintext space, the failure probability, the precision, and the remaining multiplicative depth. To compare our
bootstrapping procedure with the existing ones, we use the same concept of a
bootstrapping utility metric, as introduced by Han and Ki [5].
Definition 1 (Bootstrapping Throughput). For n a number of plaintext
slots, log(−1 ) the output precision, log(QL−k ) the output coefficient-modulus
size after the bootstrapping (remaining homomorphic capacity) and complexity
a measure of the computational cost (in CPU time), the bootstrapping throughput

J.P. Bossuat et al.
Throughput
n × log(−1 ) × log(QL−k )/(CPU time)

26

Best of [5]
Best of [19]
Best of [24]
Set III (Our best sparse)
Set IV (Our best dense)

223

215
215

214
214

221
214

219

2

14

214
212

210

217
2−7

2−9

2−11
2−13
2−15
Pr[||I(X)|| > K]
Failure probability

2−17

Fig. 3: Bootstrapping throughput comparison. We plot the results for our best
performing parameter set against the state of the art. Nodes are labeled with n,
the number of plaintext slots.
is defined as:
throughput =

n × log(−1 ) × log(QL−k )
.
complexity

Note that we express the remaining homomorphic capacity in terms of the modulus size, instead of the number of levels, because QL−k can be re-allocated
differently at each bootstrapping call, e.g., a small number of moduli with a
large plaintext scale or a large number of moduli with a small plaintext scale.
As κ, the bootstrapping failure probability, is a probability and not a metric,
we chose to not include it directly in Definition 1. However, we still believe it
should be taken into account as an opportunity-cost variable. Indeed, the event of
a bootstrapping failure will likely result in the need to re-run the entire circuit.
Hence, the probability of failure should be weighed vs. the cost of having to
re-run a circuit to determine if κ is in an acceptable range.
7.2

Results

We run our benchmarks and report the bootstrapping performance for each
parameter set of Table 5, and we compare them with the previous works of
Chen et al. [5], Han and Ki [19], and the recent and concurent work of Lee et al.
[24]. Unfortunately, the implementations of these works have not been publicly
released and we were not able to reproduce their results on our own hardware for
a fair comparison. The parameters and results are summarized in Table 6 and 7,

Efficient Bootstrapping with Non-Sparse Keys

27

Table 6: Parameter comparison of [5, 19, 24] and our work. “-” means that
value was not reported. Lee et al.’s [24] parameters are based on our Set III.
Set N log(QP )
[24]

1553

[5]
[19] 16
2
I
II
III
IV

2480
1452
1546
1547
1553
1792

[5]
[19] 215
V

1240
910
768

Bootstrapping Parameters
h
λ ρSF−1
ρSFn Q0 /∆ K dsin(x) r darcsin(x)
n
256
66
0
192 ≈ 128 2
2
25
2
8
68
5
64 < 80
4
4 1024 12 119 0
0
64 < 100 - 1024 12 31 2
0
192 ≈ 128 4
3
256 25 63 2
0
192 ≈ 128 4
3
256 25 63 2
0
192 ≈ 128 4
3
4
25 63 2
7
32768 ≈ 128 4
3
256 325 255 4
0
64 < 80
64 < 90
192 ≈ 128

2
2

2
2

1024 12
1024 12
256 25

119 0
31 2
63 2

0
0
0

respectively. Reports on experiments that demonstrate the numerical stability
of our bootstrapping can be found in Supplementary material E.
Focusing only on the overall performance, our most performing set (Set III)
achieves throughput 14.1× and 28.4× larger than the best result reported by
Han and Ki [19] and Lee et al. [24] respectively. Our Set IV uses dense keys and
achieves a throughput 4.6× and 9× larger than the work of Han and Ki and
Lee et al. respectively. Both these works use SEAL [27] and are evaluated on
similar hardware. Our sets III and IV achieve a throughput 54.2× and 17.4×
larger than the best result reported by Chen et al. [5], implemented using the
HEAAN library [20]. HEAAN does not implement the full-RNS variant of CKKS,
hence the latter comparison shows the significant performance gains that can be
achieved by combining optimized algorithms with a full-RNS implementation.
The implementation of Lee et al. makes use of the recent work of Kim et al.
[21] which proposes new techniques to minimize the error during computation,
notably a delayed rescaling that consists in rescaling the ciphertext before a
multiplication and not after, so that the error is as small as possible when doing
the multiplication. This enables Lee et al. to achieve a slightly higher precision
than ours (our implementation does not use the work of Kim et al.). Lee et
al. results are also the ones with the most residual homomorphic capacity. The
primary reason is the implementation of the CKKS scheme in SEAL, which can
only use one special prime (α = 1, see Section 4) during the key-switching. This
increases the ciphertext homomorphic capacity, but at the cost of an increased
key-switch complexity. The second reason is that they allocate less levels to the
linear transformations (in total, three less than our parameters). This enables
them to reduce the depth of the bootstrapping, at the cost of increasing its
complexity, which shows in their timings.
We observe that there is a correlation between the value Q0 /∆ and the precision. A better precision is achieved when using a smaller ratio, even when
the arcsin is not composed with the scaled sine. Previous works usually assume

28

J.P. Bossuat et al.

Table 7: Comparison of the bootstrapping performances of [5, 19, 24] and our
proposed bootstrapping for the full-RNS variant of CKKS with parameter sets
I, II, III, IV and V. MU, SS, CtS, StC designate ModUp, SubSum, SlotstoCoeffs,
CoeffstoSlots.“-” indicates that the prior work did not report the value. All timings are single threaded. The plaintext real and imaginary part are uniformly
distributed in the interval −1 and 1.
Bootstrapping Performances
Timing(s)
Set n
log (QL−k ) log (−1 ) log (bits/s) log (κ)
MU SS CtS StC Sine Total
[24] 214 - - 461.5
653
27.2
19.26
-16.58
[24] 214 - - 451.5
533
32.6
19.26
-16.58
[5] 214
119.8
38.5 158.3
172
18.6
18.33
-7.70
[5] 212
127.5
40.4 167.9
301
20.9
17.22
-9.70
[19] 214 - - 52.8
370
10.8
20.24
-7.70
[19] 210 - - 37.6
370
15.3
17.23
-11.70
I 215 0.06 0 6.5 3.7 12.8 23.0
420
25.7
23.87
-15.58
I 214 0.06 0.3 6.3 3.8 6.3 16.9
420
26.0
23.33
-16.58
II 215 0.06 0 6.8 2.2 14.2 23.4
240
31.5
23.33
-15.58
II 214 0.06 0.3 6.0 2.4 7.1 16.0
240
31.6
22.88
-16.58
III 215 0.06 0 5.4 2.4 10.1 18.1
505
19.1
24.06
-15.58
III 214 0.06 0.3 5.0 2.6 5.0 13.1
505
18.9
23.50
-16.58
IV 215 0.07 0 7.9 28.2 3.0 39.2
410
16.8
22.45
-14.90
IV 214 0.07 0.4 7.1 14.1 3.2 24.9
410
17.3
22.15
-15.90
[5] 210
28.8
9.5 38.3
[5] 28
16.9
9.2 26.0
[19] 22
- 7.5
[19] 21
- 7.0
V 214 0.02 0 3.7 0.7 2.9 7.5
V 213 0.02 0.4 1.6 0.4 1.5 3.9

150
75
185
185
110
110

6.9
10.03
15.0
16.8
15.5
15.4

14.75
12.85
10.53
9.79
21.82
21.76

-11.70
-13.70
-19.70
-20.70
-16.58
-17.58

that ||m|| ≈ ||FFT−1 (m)|| to set Q0 /∆ and derive the expected precision of the
scaled sine. In practice, since each coefficient of FFT−1 (m) is a dot product between the vector m and a complex vector of roots of unity (zero-mean and small
variance), if the mean of m is close to zero, then ||FFT−1 (m)||  ||m|| with
overwhelming probability. For example, given m uniform in (−1, 1) and n = 215
slots, then ||m||/||FFT−1 (m)|| ≈ 100. Hence the message is much closer to the
origin than expected, which reduces the inherent error of the scaled sine and
amplifies the effectiveness of the arcsine. We note that even if the distribution
of m is not known, it is possible to enforce this behavior with a single plaintext
multiplication by homomorphically negating half of its coefficients before the
bootstrapping. One could even homomorphically split m in half and create two
symmetric vectors to enforce a zero mean. A more detailed analysis of this behavior and how to efficiently exploit it or integrate it into the linear transforms
of the bootstrapping could be a interesting future research line.
All our sets have a failure probability that is two to three orders magnitude
smaller than previous works, except for the results of Lee et al. which use our

Efficient Bootstrapping with Non-Sparse Keys

29

suggested parameters. For example, following Equation (1), if successive bootstrappings are carried out with n = 215 slots, then [5] and [19] would reach a 1/2
failure probability after 52 bootstrappings, whereas ours would reach the same
probability after 24,656 bootstrappings.
Figure 3 plots the best performing instances of Table 7.

8

Conclusion

In this work, we have introduced a secure, reliable, precise and efficient bootstrapping procedure for the full-RNS CKKS scheme that does not require the
use of sparse secret-keys. To the best of our knowledge, this is the first reported
instance of a practical bootstrapping parameterized for at least 128-bit security.
To achieve this, we have proposed a generic algorithm for the homomorphic
evaluation of polynomials with reduced error and optimal in level consumption.
In addition to the increase in precision and efficiency, our algorithm also improves
the usability of the full-RNS variant of CKKS (for which managing a changing
scale in large circuits is known to be a difficult task).
We have also proposed an improved key-switch format that we apply to the
homomorphic matrix-vector multiplication. Our novel double hoisting algorithm
reduces the complexity of the CoeffsToSlots and SlotsToCoeffs by roughly a factor of 2 compared to previous works. The performance gain for these procedures
enables their use outside of the bootstrapping, for applications where the conversion between coefficient- and slot-domains would enable much more efficient
homomorphic circuits (e.g., in the training of convolutional neural networks or
R-LWE to LWE ciphertext conversion).
We have also proposed a systematic approach to parameterize the bootstrapping, including a way to precisely assess its failure probability. We have evaluated
our bootstrapping procedure and have shown that its throughput with “dense”
secret-keys (h = N/2) is up to 4.6× larger than the best state-of-the-art results
with sparse keys (h = 64). When the sparse-keys-adjusted parameters of Curtis
and Player [11] for h = 192 and 128-bits of security are considered, our procedure has a 14.1× larger throughput than the previous work that uses a sparse
key with h = 64 with insecure parameters. Additionally, all our parameters lead
to a more reliable instance than the previous works, with a failure probability
orders of magnitude lower.
We have implemented our contributions in the Lattigo library [23]. This is,
to the best of our knowledge, the first open-source implementation of a bootstrapping procedure for the full-RNS variant of the CKKS scheme.

Acknowledgments
We would like to thank Anamaria Costache, Mariya Georgieva and the anonymous Eurocrypt’21 reviewers for their valuable feedback. We also thank Lee et
al. (authors of [24]) for the insightful discussions. This work was supported in
part by the grant #2017-201 of the ETH Domain PHRT Strategic Focal Area.

30

J.P. Bossuat et al.

References
[1]

[2]

[3]

[4]

[5]

[6]

[7]

[8]

[9]

[10]

[11]

[12]

Martin Albrecht, Melissa Chase, Hao Chen, Jintai Ding, Shafi Goldwasser,
Sergey Gorbunov, Shai Halevi, Jeffrey Hoffstein, Kim Laine, Kristin Lauter,
Satya Lokam, Daniele Micciancio, Dustin Moody, Travis Morrison, Amit
Sahai, and Vinod Vaikuntanathan. Homomorphic Encryption Security Standard. Tech. rep. Toronto, Canada: HomomorphicEncryption.org, Nov. 2018.
Martin R Albrecht, Rachel Player, and Sam Scott. “On the concrete hardness of learning with errors”. In: Journal of Mathematical Cryptology 9.3
(2015), pp. 169–203.
Jean-Claude Bajard, Julien Eynard, M Anwar Hasan, and Vincent Zucca.
“A full RNS variant of FV like somewhat homomorphic encryption schemes”.
In: International Conference on Selected Areas in Cryptography. Springer.
2016, pp. 423–442.
Zvika Brakerski, Craig Gentry, and Vinod Vaikuntanathan. “(Leveled)
fully homomorphic encryption without bootstrapping”. In: ACM Transactions on Computation Theory (TOCT) 6.3 (2014), pp. 1–36.
Hao Chen, Ilaria Chillotti, and Yongsoo Song. “Improved bootstrapping for
approximate homomorphic encryption”. In: Annual International Conference on the Theory and Applications of Cryptographic Techniques. Springer.
2019, pp. 34–54.
Jung Hee Cheon, Kyoohyung Han, and Minki Hhan. “Faster Homomorphic
Discrete Fourier Transforms and Improved FHE Bootstrapping”. In: IACR
Cryptol. ePrint Arch. 2018 (2018), p. 1073.
Jung Hee Cheon, Kyoohyung Han, Andrey Kim, Miran Kim, and Yongsoo Song. “A full RNS variant of approximate homomorphic encryption”.
In: International Conference on Selected Areas in Cryptography. Springer.
2018, pp. 347–368.
Jung Hee Cheon, Kyoohyung Han, Andrey Kim, Miran Kim, and Yongsoo Song. “Bootstrapping for approximate homomorphic encryption”. In:
Annual International Conference on the Theory and Applications of Cryptographic Techniques. Springer. 2018, pp. 360–384.
Jung Hee Cheon, Minki Hhan, Seungwan Hong, and Yongha Son. “A hybrid of dual and meet-in-the-middle attack on sparse and ternary secret
LWE”. In: IEEE Access 7 (2019), pp. 89497–89506.
Jung Hee Cheon, Andrey Kim, Miran Kim, and Yongsoo Song. “Homomorphic encryption for arithmetic of approximate numbers”. In: International
Conference on the Theory and Application of Cryptology and Information
Security. Springer. 2017, pp. 409–437.
Benjamin R. Curtis and Rachel Player. “On the Feasibility and Impact of
Standardising Sparse-secret LWE Parameter Sets for Homomorphic Encryption”. In: Proceedings of the 7th Workshop on Encrypted Computing
and Applied Homomorphic Cryptography (2019).
Junfeng Fan and Frederik Vercauteren. “Somewhat Practical Fully Homomorphic Encryption.” In: IACR Cryptol. ePrint Arch. 2012 (2012), p. 144.

Efficient Bootstrapping with Non-Sparse Keys

[13]

[14]

[15]

[16]
[17]

[18]

[19]

[20]
[21]

[22]

[23]
[24]

[25]

31

C. Gentry. “Fully homomorphic encryption using ideal lattices”. In: Proceedings of the forty-first annual ACM symposium on Theory of computing.
2009, pp. 169–178.
Craig Gentry, Shai Halevi, and Nigel P. Smart. “Homomorphic Evaluation
of the AES Circuit”. In: Advances in Cryptology – CRYPTO 2012. Ed.
by Reihaneh Safavi-Naini and Ran Canetti. Berlin, Heidelberg: Springer
Berlin Heidelberg, 2012, pp. 850–867. isbn: 978-3-642-32009-5.
Shai Halevi, Yuriy Polyakov, and Victor Shoup. “An improved RNS variant
of the BFV homomorphic encryption scheme”. In: Cryptographers’ Track
at the RSA Conference. Springer. 2019, pp. 83–105.
Shai Halevi and Victor Shoup. “Algorithms in HELib”. In: Annual Cryptology Conference. Springer. 2014, pp. 554–571.
Shai Halevi and Victor Shoup. “Bootstrapping for HELib”. In: Annual
International conference on the theory and applications of cryptographic
techniques. Springer. 2015, pp. 641–670.
Shai Halevi and Victor Shoup. “Faster homomorphic linear transformations in HElib”. In: Annual International Cryptology Conference. Springer.
2018, pp. 93–120.
Kyoohyung Han and Dohyeong Ki. “Better bootstrapping for approximate
homomorphic encryption”. In: Cryptographers’ Track at the RSA Conference. Springer. 2020, pp. 364–390.
HEAAN. Online:https://github.com/snucrypto/HEAAN.
Andrey Kim, Antonis Papadimitriou, and Yuriy Polyakov. Approximate
Homomorphic Encryption with Reduced Approximation Error. Cryptology
ePrint Archive, Report 2020/1118. https://eprint.iacr.org/2020/
1118. 2020.
Miran Kim, Arif Harmanci, Jean-Philippe Bossuat, Sergiu Carpov, Jung
Hee Cheon, Ilaria Chillotti, Wonhee Cho, David Froelicher, Nicolas Gama,
Mariya Georgieva, et al. “Ultra-Fast Homomorphic Encryption Models
enable Secure Outsourcing of Genotype Imputation”. In: bioRxiv (2020).
doi: 10.1101/2020.07.02.183459.
Lattigo 2.0.0. Online: https://github.com/ldsec/lattigo. EPFL-LDS.
Sept. 2020.
Joon-Woo Lee, Eunsang Lee, Yongwoo Lee, Young-Sik Kim, and JongSeon No. “High-Precision Bootstrapping of RNS-CKKS Homomorphic Encryption Using Optimal Minimax Polynomial Approximation and Inverse
Sine Function”. In: Advances in Cryptology – EUROCRYPT 2021. Ed. by
Anne Canteaut and François-Xavier Standaert. Cham: Springer International Publishing, 2021, pp. 618–647. isbn: 978-3-030-77870-5.
Oliver Masters, Hamish Hunt, Enrico Steffinlongo, Jack Crawford, Flavio
Bergamaschi, Maria Eugenia Dela Rosa, Caio Cesar Quini, Camila T
Alves, Fernanda de Souza, and Deise Goncalves Ferreira. “Towards a Homomorphic Machine Learning Big Data Pipeline for the Financial Services
Sector”. In: IACR Cryptol. ePrint Arch. 2019 (2019), p. 1113.

32

[26]

J.P. Bossuat et al.

Sinem Sav, Apostolos Pyrgelis, Juan R Troncoso-Pastoriza, David Froelicher,
Jean-Philippe Bossuat, Joao Sa Sousa, and Jean-Pierre Hubaux. “POSEIDON: Privacy-Preserving Federated Neural Network Learning”. In: arXiv
preprint arXiv:2009.00349 (2020).
[27] Microsoft SEAL (release 3.6). Online: https://github.com/Microsoft/
SEAL. Microsoft Research, Redmond, WA. Nov. 2020.
[28] Yongha Son and Jung Hee Cheon. “Revisiting the Hybrid Attack on Sparse
Secret LWE and Application to HE Parameters”. In: Proceedings of the
7th ACM Workshop on Encrypted Computing & Applied Homomorphic
Cryptography (2019).
[29] The Go Programming Language. Online: https : / / golang . org/. Sept.
2020.

Supplementary Material

33

35

A

CKKS Homomorphic Operations

This section introduces the available homomorphic operation of the CKKS scheme.
Whenever homomorphic operations involve ciphertexts and/or plaintexts whose
respective modulus Q` differ, the operations are carried out with the moduli
shared between both operands (i.e., the smallest modulus) and the other moduli
are discarded.
• Add({ct, Q` , ∆}, {ct0 , Q`0 , ∆0 }) : Scale ct and ct’ to max(∆, ∆0 ) and return
{ct + ct0 , min(Q` , Q`0 ), max(∆, ∆0 )}.
• AddPlain({ct, Q` , ∆}, {pt, Q`0 , ∆0 }) : Scale ct and pt to max(∆, ∆0 ) and return {ct + (pt, 0), min(Q` , Q`0 ), max(∆, ∆0 )}.
• AddConst({ct, Q` , ∆}, a+bi ∈ C): Return {ct+(b∆·(a+b·X N/2 )e, 0), Q` , ∆}.
• Multi({ct, Q` , ∆}): Return {ct · X N/2 , Q` , ∆}, the homomorphic product by
the imaginary unit.
• MultConst({ct, Q` , ∆}, a+bi ∈ C, ∆0 ): Return {b∆0 ae·ct+b∆0 be·ct·X N/2 , Q` , ∆∆0 }.
• Mul({ct, Q` , ∆}, {ct0 , Q`0 , ∆0 }): For ct = (c0 , c1 ) and ct’ = (c00 , c01 ), compute (d0 , d1 , d2 ) = (c0 c00 , c0 c01 + c1 c00 , c1 c01 ), and return {ctmul = (d0 , d1 ) +
SwitchKey(d2 , rlk), min(Q` , Q`0 ), ∆∆0 }.
• MulPlain({ct, Q` , ∆}, {pt, Q`0 , ∆0 }): For ct = (c0 , c1 ), return {(c0 · pt, c1 · pt),
min(Q` , Q`0 ), ∆∆0 }.
• Rescale({ct, Q` , ∆}): Return {bq`−1 · cte, Q`−1 , ∆/q` }, for q`−1 ∈ R.
• DropLevel({ct, Q` , ∆}, k): Return {ct, Q`−k , ∆}.
k

k

• Rotate({ct, Q` , ∆}, k): For ct = (c0 , c1 ), return {ctrotk = (c50 , 0)+SwitchKey(c51 , rotk ), Q` , ∆}.
−1
• Conjugate({ct, Q` , ∆}): For ct = (c0 , c1 ), return {ctconj = (c−1
0 , 0)+SwitchKey(c1 , conj), Q` , ∆}.

B

Key-switch: Current Approaches

In this section we review the current approaches taken by the state of the art
for the key-switch. Given a ciphertext (c0 , c1 ) = (−as0 + m + e, a) that decrypts
under s0 , the most efficient approach to switch it to s would be to generate public
key-switch keys of the form swk = (−bs + s0 + e0 , b), and perform a re-encryption
from s0 to s as
(c0 , 0) + c1 · swk = (−abs + ae0 + m + e, ab).

36

However, the term ae0 would introduce too much error for the ciphertext to be
correctly decrypted. Fan and Vercauteren [12] propose two key-switch keys types
to control this error term:
• Type I : Use swk(i) = (−bi s + w(i) s0 + e0i , bi ) for a base w with the reconP (i) (i)
struction formula x =
xw w , decompose c1 under base w and compute
P (i)
P (i)
(i)
(c0 , 0) + cw,1 swk = (−a0 s + aw e0i + m + e, a0 ). This solution is highly
P (i) 0
inefficient if the target is to make
aw ei small because it will increase
the number of keys, and therefore the number of operations, by an amount
proportional to Q/||w||.
• Type II : Use swk = (−bs + P · s0 + e0 , b), for P a large integer, and compute
(c0 , 0) + bP −1 · c1 · swke = (−a0 s + bP −1 · ae0 e + m + e, a0 ). If P ≈ ||ae0 || then
the added error is negligible. This solution is more efficient than the Type I,
but the modulus of the keys is multiplied by P , so the size of the ring degree
must be increased or the ciphertext modulus reduced to compensate for the
security loss. This also affects the overall performance or the homomorphic
capacity.
Han and Ki [19] propose a hybrid version that combines both approaches and
uses keys of the form swk(i) = (−bi s+w(i) ·P ·s0 +e0i , bi ). Similarly to the Type II,
if ||w|| ≈ P , it results in a negligible added error. Moreover, it enables the user
to balance the trade-off between the complexity of the first approach and the
modulus increase of the second approach. This hybrid solution is well-suited for
large parameters, as it can greatly reduce the size of the key-switch keys and the
complexity of the key-switch operation without much affecting the homomorphic
capacity.
Although the above high-level description of the key-switch is agnostic of
the representation of the coefficients, the base w must be chosen to be compatible with the latter: when dealing with integers represented in the positional
i
domain, a decomposition with a power-of-two basis w(i) = 2b (i.e., a bit-wise
decomposition basis where elements of the decomposed basis are of size at most
b bits) is straightforward and efficient to implement using bit-wise arithmetic.
However, due to its non-linearity, such a decomposition cannot be used directly
when dealing with coefficients in the RNS representation. Instead, an alternate
base w, derived from the RNS reconstruction, can be used. Similarly to the reP (i)
construction from a power basis, a = aw w(i) , the RNS reconstruction is also
a linear operation over a vector, i.e., a sum of products:
 −1 i
X
Qh Q
a≡
[a]qi
qi
qi
qi

mod Q.

(2)

Therefore, it can also be used as a decomposition basis and is especially wellsuited for dealing with integers represented in the RNS domain, as shown in [3,
15]. It is also possible to apply an additional power-basis decomposition for each
of the elements [a]qi , to further reduce the size of the noise terms, if needed.

37

C

Complexity Analysis

This section contains the complexity derivations of the algorithms used in our
work for the key-switch (Algorithm 3 in Section 4.1) and hoisted rotation (Algorithm 4 in Section 4.2).
C.1

Key-Switch

We analyse the the complexity of a homomorphic multiplication with a keyswitch (Algorithm 3 in Section 4.1) in term of the required number of modular
multiplication in Zp , and we compare it with the results reported in [19].
We assume that the inputs and outputs of the procedure are both in the NTT
domain. We set α = #pj and β = d(` + 1)/αe, ct = (c0 , c1 ) and ct0 = (c00 , c01 )
mod Q` .
Step 1 : Tensoring. We compute the tensor product of the ciphertexts (of degree
1): (ĉ0 , ĉ1 , ĉ2 ) ← (c0 c00 , c0 c01 + c1 c00 , c1 c01 ) mod Q` . Intuitively, the optimal way
would be to use a Karatsuba approach to trade multiplications with additions.
However, we observed that, due to our Montgomery arithmetic, it was more efficient in our implementation to do 4 multiplications and 1 addition rather than
3 multiplications and 4 additions. The total complexity is therefore 4 · N · (` + 1).
Step 2 : NTT. We switch ĉ2 = d ∈ RQ` out of the NTT domain. The complexity
is N · log(N ) · (` + 1).
Step 3 : MultSum. We decompose d0 base qαi , multiply it with evk and sum. So
for 0 < i < β,
1. We are given an input vector of ` + 1 elements that we take modulo qαi , thus
reducing its size to α elements. This first operation is free as qαi |Q` . We
then extend this vector to a vector of size (` + 1) + α, for which we already
know α elements, hence the complexity is α · (` + 1 + α − α) = α · (` + 1).
We also have to run α pre-computations on the fly. As we have to run this
for N values, the total complexity is N · (α + α · (` + 1)).
2. We switch d0qα ∈ RQ` P back to the NTT domain: we need to compute
i
(` + 1) + α NTT, but we already have α of those NTT vectors available
from d ∈ RQ` , hence the total number of NTT is reduced to ` + 1, and the
complexity is N · log(N ) · (` + 1).
3. We multiply dqαi ∈ RQ` P with evkjqα for j ∈ 0, 1. The complexity is 2 · N ·
i
(` + 1 + α).
The total complexity of Step 2 is β · N · ((` + 1) · (α + log(N ) + 2) + 3 · α).
Step 4 : ModDown. For i ∈ 0, 1:
1. We switch the P basis of di ∈ RQ` P out of the NTT domain. The complexity
is N · log(N ) · α.

38

2. We change the basis of di ∈ RP from P to Q` : we are given a vector of size
α and want to extend it to a vector of size ` + 1, but which do not share any
moduli with the initial vector. Therefore, the complexity is N ·(α+α·(`+1)).
3. We switch di ∈ RQ` back to the NTT domain: N · log(N ) · (` + 1).
4. The last step is a subtraction and a multiplication by P −1 : N · (` + 1).
The total complexity of Step 4 is 2·N ·((`+1)·(α+log(N )+1)+α·(log(N )+1)).
Step 5. We add the polynomials di ∈ RQ` for i ∈ 0, 1 to the ciphertext; there is
no multiplication: ctmul = (d0 + ĉ0 , d1 + ĉ1 ) mod Q` .
Hence, the total complexity of our homomorphic multiplication in terms of modular multiplications is



N · (` + 1) · log(N ) · (3 + β) + β · (α + 2) + 2α + 6 + α · (2 · log(N ) + 2 + 3β) .
Remark 1. The complexity of the key-switch itself can be obtained by subtracting 4 · N (` + 1) to the homomorphic-multiplication complexity.
The complexity reported in [19] is


N · (` + 1)2 + (` + 1) · (α + 2β + 6) + 3 + log(N ) · (` + 1) · (α + β + 5) + 3 .
Table 8 compares both expressions by using the same parameters as the
original table of [19] with ` = 23 and a variable #pj = α. The size of the moduli
of Q and P is 45 bits, and q0 is 55 bits. Our algorithm has the same asymptotic
complexity, but it introduces a change in the constants, which is enough to
induce a non-negligible difference. The number of NTT operations, which is the
dominant term, is (` + 1) · (α + β + 5) + 3 in [19], whereas it is (` + 1) · (β + 3) + 2α
in our work. The number of NTTs in our algorithm decreases much faster for
larger α than those of Han and Ki, e.g., for α = 6 it already shows a factor-of-two
difference. As the number of NTTs is the dominant term of the key-switch, this
translates into a non-negligible difference in the final complexity.
C.2

(Hoisted) Rotations

In this section, we analyse the complexity of hoisted rotations (Algorithm 4 in
Section 4.2) in term of their number of modular multiplications in Zp . Let r
be the number of rotations, N the ring degree, ` the current level and β =
d(` + 1)/αe, with α a positive integer, then
Step 1: NTT. We switch c1 out of the NTT domain : N · log(N ) · (` + 1).
Step 2: Decompose + NTT. We decompose c01 mod each qαi , extend the RNS
basis from Q` to Q` P and switch back the result in the NTT domain: β · N ·
(α + (` + 1) · (log(N ) + α)).

39

Table 8: Comparison of the homomorphic multiplication complexity in log.
log(#Mul in Zp )
α log(QP ) Work in [19] Our work
1 1136
29.70
29.59
2 1181
29.08
28.83
3 1227
28.84
28.46
4 1272
28.75
28.25
6 1363
28.74
28.02
8 1454
28.82
27.92
12 1635
29.04
27.88
24 2180
29.65
28.08

Step 3: MultSum. For each rotation rk we compute the dot product between d
and rotk,qαi : 2kβ · N · (` + 1 + α).
Step 4: ModDown. For each rotation rk we rescale a and b by P and reduce the
RNS basis from P Q` back to Q` : 2k·N ·((`+1)·(α+log(N )+1)+α·(log(N )+1)).
Step 5: Permute. For each rotation rk we apply the automorphism φk on c0 + a
and b: there is no multiplication.
Hence, the total complexity for r hoisted rotations is







N · log(N )· (`+1)·(β+1+2r)+2rα +(`+1)· βα+2r·(α+β+1) +α· β+2r·(β+1) .
Figure 4 compares the complexity of regular and hoisted rotations for a
varying number of rotations r and ciphertext level `. It shows that using hoisted
rotations scales significantly better for any r > 1 and any level `. This is especially the case when ` is large, which is relevant for the bootstrapping, as the
first step of this procedure is a linear transformation computed at the maximum
ciphertext level.

D

Performance of Basic Operations

Table 9 reports the single-thread performance in ms of Lattigo v2.1.1 for the
basic operations for N = 216 and different values of lvls = #qi and α = #pj
with lvls + α = 30 (so that λ is not changed when α varies). The timings for
the ct × ct multiplication are reported without the relinearization (key-switch).
The benchmarks were conducted single threaded on an i5-6600k at 3.5 GHz
with 32Gb of RAM running Windows 10 and Go 1.15.6, GOARCH=amd64,
GOOS=windows.

40
·109
1

Hoisted
Normal

8

·1010
Hoisted
Normal

0.8

#MulZp

#MulZp

6

4

0.6
0.4

2

0.2

0

0

0

5

10

15
r

20

25

30

0

5

10

15
`

20

25

30

(a) Varying number of rotations r. Param- (b) Varying input level for r=20 rotations.
Parameters: {N=216 , α=4, β=d(`+1)/αe}.
eters: {N=216 , `=21, α=4, β=d(`+1)/αe}.

Fig. 4: Complexity of hoisted rotations vs. non-hoisted rotations in terms of the
number of multiplications in Zp .
Table 9: Performance of basic operations in Lattigo. Timings are in [ms]
lvls α Encpk Encsk Dec Add Mulpt Mulct φ KeySwitch Rescale
29 1 205 124 9 4
8
19 7
1121
72
28 2 208 124 8 4
8
18 6
692
58
27 3 208 118 8 4
8
17 6
496
55
25 5 215 113 7 3
7
16 6
349
50
24 6 214 106 7 3
7
16 5
311
49
20 10 210 92
6 3
6
12 4
233
41
15 15 204 72
4 2
4
10 3
181
30

E

Bootstrapping Stability Experiments

This section reports on the following checks: the mean precision across all the
slots against the number of slots (Supplementary material E.1), the probability
of each slot to fall under some given precision (Supplementary material E.2), and
the mean precision across all the slots after each bootstrapping for 50 successive
bootstrapping operations (Supplementary material E.3).
E.1

Precision vs. Slots

We plot in Figure 5 the mean precision for different values n (slots) for the
parameter sets I, II, III, IV and V of Table 5 in Section 6.3. The plaintext values
are of the form a + bi, for a, b random reals between −1 and 1. The comparison
is made against a non-encoded plaintext vector, hence these results also include
the error of the encoding algorithms. The parameter sets are optimized to give

41

the best performance for n = 215 slots, hence a smaller amount of slots will not
necessarily imply a better precision. To get a better precision with a smaller n,
the moduli of the linear transforms and the ratio Q0 /||m|| should be increased.
I

II

44

44
Real
Imag

40

36
log(1/)

log(1/)

36

40

32
28
24
20

32
28
24
Real
Imag

20

16

16
4

6

8

10 12
log(n)

14

16

4

6

Set III

log(1/)

log(1/)

24
20
16
Real
Imag
4

6

8

10 12
log(n)

10 12
log(n)

14

16

14

16

Set IV

28

12

8

14

16

14

16

28
26
24
22
20
18
16
14
12
10

Real
Imag
4

6

8

10 12
log(n)

Set V
28

log(1/)

24
20
16
12

Real
Imag

8
4

6

8

10 12
log(n)

Fig. 5: Precision vs. number of slots for the parameter sets I, II, III, IV and V
of Table 5 in Section 6.3.

42

E.2

Precision Distribution

In this section, we plot in Figures 6 and 7 the CDF of the precision for the
parameter sets I, II, III, IV and V of Section 6.3. The goal is to show that
though we have a good mean precision, the overall distribution also behaves well
and is not scattered. The plaintext values are of the form a + bi, for a, b random
reals between −1 and 1. The comparison is made against a non-encoded plaintext
vector, hence these results also include the error of the encoding algorithms. The
shapes of all the plots show that the distribution is smooth across all the different
parameter sets of Table 5 and that 99% of the values are within ± 2 bits of the
mean.
Set I - n = 214

Set I - n = 215

0.8

1
Real
Imag
Pr[log(1/i ) < x]

Pr[log(1/i ) < x]

1

0.6
0.4
0.2
0

0.8

Real
Imag

0.6
0.4
0.2

20

30
log(1/)

0

40

20

30
log(1/)

Set II - n = 214

Set II - n = 215
1

Real
Imag
Pr[log(1/i ) < x]

Pr[log(1/i ) < x]

1
0.8
0.6
0.4
0.2
0
25

40

0.8

Real
Imag

0.6
0.4
0.2

30

35
40
log(1/)

45

0
25

30

35
40
log(1/)

45

Fig. 6: CDF of the precision for the parameters sets I and II of Table 5 in Section
6.3.

43
Set III - n = 214

Set III - n = 215

0.8

1
Real
Imag
Pr[log(1/i ) < x]

Pr[log(1/i ) < x]

1

0.6
0.4
0.2
0

0.8

Real
Imag

0.6
0.4
0.2

10

20
log(1/)

0

30

10

Set IV - n = 214

Pr[log(1/i ) < x]

Pr[log(1/i ) < x]

1
Real
Imag

0.6
0.4
0.2
0

0.8

Real
Imag

0.6
0.4
0.2

10

20
log(1/)

0

30

10

Set V - n = 213

Pr[log(1/i ) < x]

Pr[log(1/i ) < x]

30

1
Real
Imag

0.6
0.4
0.2
0

20
log(1/)
Set V - n = 214

1
0.8

30

Set IV - n = 215

1
0.8

20
log(1/)

0.8

Real
Imag

0.6
0.4
0.2

10

20
log(1/)

30

0

10

20
log(1/)

30

Fig. 7: CDF of the precision for the parameters sets III, IV and V of Table 5 in
Section 6.3.

44

E.3

Successive Bootstrapping Operations

In this section, we plot in Figures 8 and 9 the plaintext precision values after
each bootstrapping with 50 iterations for the parameter sets I, II, III, IV and V
of Section 6.3. The plaintext values are of the form a + bi, for a, b random reals
between −1 and 1. The plots show the mean precision, along with the absolute
upper and lower precision bound (no value had a larger or smaller precision).
Note that the comparison is made against a non-encoded plaintext vector, hence
these results also include the inherent error of the encoding algorithms. We
observe a logarithmic decrease in the precision loss, that is consistent with an
additive error.

log(1/)

Set I - n = 215
44
42
40
38
36
34
32
30
28
26
24
22
20
18
16
14

Real
Imag

0

5

10

15

20

25
30
Iteration

35

40

45

50

35

40

45

50

log(1/)

Set II - n = 215
50
48
46
44
42
40
38
36
34
32
30
28
26
24
22
20

Real
Imag

0

5

10

15

20

25
30
Iteration

Fig. 8: Mean precision after successive bootstrapping operations for the parameter sets I and II of Table 5 in Section 6.3.

45

log(1/)

Set III - n = 215
40
38
36
34
32
30
28
26
24
22
20
18
16
14
12
10
8

Real
Imag

0

5

10

15

20

25
30
Iteration

35

40

45

50

35

40

45

50

35

40

45

50

log(1/)

Set IV - n = 215
40
38
36
34
32
30
28
26
24
22
20
18
16
14
12
10
8
6

Real
Imag

0

5

10

15

20

25
30
Iteration

log(1/)

Set V - n = 21 4
40
38
36
34
32
30
28
26
24
22
20
18
16
14
12
10
8
6

Real
Imag

0

5

10

15

20

25
30
Iteration

Fig. 9: Mean precision after successive bootstrapping operations for the parameter sets III, IV and V of Table 5 in Section 6.3.

46

F

Bootstrapping Diagram

We include here a graphical description (Figure 10) of the implementation of
our bootstrapping circuit in the form of a flow diagram.
ModUp
For 𝑖 = log 𝑛 to
𝑖 = log 𝑁/4

SubSum
⋘2𝑖

⊞

Facorized SF𝑛−1 into 𝜌SF𝑛−1 sparse matrices
1
𝜌 −1
1
𝑞0
SF𝑛
⋅
×
𝐾 ⋅ 𝑁 ⋅ 2𝑟 2⌊log 𝑞0 ⌉

SF𝑛−1

⊗

…

…

…
1
𝜌 −1
1
𝑞0
SF𝑛
⋅
×
𝐾 ⋅ 𝑁 ⋅ 2𝑟 2⌊log 𝑞0 ⌉

⊗

CoeffsToSlots
𝑥ҧ

⊞

⊟
⊙

−𝑖

If 𝑛 = 𝑁/2

If 𝑛 < 𝑁/2

⊞

⋘𝑛/2
Δ
ඍ ඉ
𝑞0

⊙

𝑦 = 2𝑟

1
2𝜋

cos 2𝜋 𝑥 −

2
𝑦𝑖 = 2𝑦𝑖−1
−

Δ
ඍ ඉ
𝑞0

⊙

1
2𝑟

0.25
2𝑟
2𝑖

EvalSine

2𝜋

𝑥 = arcsin(𝑦𝑖 )

𝑞0
቞ ቝ
Δ

⊙

Factorized SF𝑛 into 𝜌SF𝑛 sparse matrices

⊙

SF𝑛

𝑖

⊞

1

Δ 2⌊log 𝑞0 ⌉ 𝜌SF𝑛
⋅
×
𝛿
𝑞0

𝑞0
቞ ቝ
Δ

⊙

⊗

If 𝑛 < 𝑁/2

…

…

𝑖 ⋅ 𝐼ℓ
×
𝑖 ⋅ 𝐼ℓ

…

𝐼ℓ
𝐼ℓ

SlotsToCoeffs

1

Δ 2⌊log 𝑞0 ⌉ 𝜌SF𝑛
⋅
×
𝛿
𝑞0

⊗

Fig. 10: Bootstrapping circuit diagram.

