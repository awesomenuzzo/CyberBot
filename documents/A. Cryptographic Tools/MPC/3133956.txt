Session C5: Using Blockchains

CCS’17, October 30-November 3, 2017, Dallas, TX, USA

Fairness in an Unfair World:
Fair Multiparty Computation from Public Bulletin Boards
Arka Rai Choudhuri

Matthew Green

Abhishek Jain

achoud@cs.jhu.edu
Johns Hopkins University

mgreen@cs.jhu.edu
Johns Hopkins University

abhishek@cs.jhu.edu
Johns Hopkins University

Gabriel Kaptchuk

Ian Miers

gkaptchuk@cs.jhu.edu
Johns Hopkins University

imiers@cs.jhu.edu
Johns Hopkins University

ABSTRACT

is the first to learn she did not win an auction, she may abort, claim
a network failure, and try again with a new bid that just exceeds
the previous winning bid. More generally when the “value” of the
function output may be enhanced by an information asymmetry,
e.g., if Alice is better off exclusively knowing the true value of a
financial asset than all parties knowing it, fairness is an issue.
In a seminal work, Cleve [25] proved that fair MPC is impossible
to realize for general functions when a majority of the parties are
dishonest. This result even holds when the parties have access to a
trusted setup such as a common reference string.

Secure multiparty computation allows mutually distrusting parties
to compute a function on their private inputs such that nothing but
the function output is revealed. Achieving fairness — that all parties
learn the output or no one does – is a long studied problem with
known impossibility results in the standard model if a majority of
parties are dishonest.
We present a new model for achieving fairness in MPC against
dishonest majority by using public bulletin boards implemented
via existing infrastructure such as blockchains or Google’s certificate transparency logs. We present both theoretical and practical
constructions using either witness encryption or trusted hardware
(such as Intel SGX).
Unlike previous works that either penalize an aborting party or
achieve weaker notions such as ∆-fairness, we achieve complete
fairness using existing infrastructure.

The pursuit of fairness. In light of Cleve’s impossibility result,
a vast amount of research effort has been dedicated towards the
study of mitigations to the fairness problem. In particular, two
prominent lines of research have emerged over the years. The first
research direction considers the problem of achieving fairness in
the standard model for a restricted classes of functions [7–9, 45, 47].
The second research direction studies fairness for general functions by augmenting the computation model and/or by relaxing
the definition of fairness. The prominent examples in this direction range from using a trusted party to restore fairness [20], to
weaker models where the honest parties can recover the output at
computational cost or time at most ∆-times that of the adversary
[13, 31, 34, 42, 59, 60] (where ∆ is a constant), to penalizing aborting
parties monetarily [6, 17, 52, 53]. (See Section 2 for a more elaborate
discussion.)
While these mitigations are helpful, they fall short of solving the
problem in many circumstances. In particular, they either require
appointing trusted parties for very specific tasks (related to the protocol) that can be hard to find, or require that the parties’ possess
precise estimates of the adversary’s resources and incentives. If the
adversary values exclusive knowledge of the output very highly, it
may not be practical to have a large enough computational differential or penalty to deter aborts. Indeed, in many cases it may be
impossible value the MPC output at all.

KEYWORDS
Secure Multiparty Computation, Fairness

1

INTRODUCTION

Secure multiparty computation (MPC) allows a collection of mutually distrusting parties to jointly compute a function on their
private inputs while revealing nothing beyond the function output.
Since its conception three decades ago [41, 62], MPC has found
wide applicability to important tasks such as electronic auctions,
voting, valuation of assets, and privacy-preserving data mining.
Fairness. Over the years, several security definitions for MPC
have been studied. One natural and desirable definition for MPC
stipulates that either all parties receive the protocol output or no
party does. This is referred to as fair MPC.
The notion of fairness is very important (and necessary) in applications such as auctions and contract signing. For example, if Alice
Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CCS’17, Oct. 30–Nov. 3, 2017, Dallas, TX, USA.
© 2017 Copyright held by the owner/author(s). Publication rights licensed to the
Association for Computing Machinery.
ACM ISBN 978-1-4503-4946-8/17/10. . . $15.00
https://doi.org/10.1145/3133956.3134092

Our Model: Public Bulletin Boards. In this work, we take a new
approach to achieving complete fairness in MPC for general functions. We consider a setting where the parties have access to a
public ledger, or a bulletin board that allows anyone to publish arbitrary strings. Upon publishing its data D on the bulletin board,
a party receives a proof (or a signature) to establish that D was
published. The bulletin board is public, in that anyone can see all
of its contents. The main security requirements from the bulletin

719

Session C5: Using Blockchains

CCS’17, October 30-November 3, 2017, Dallas, TX, USA

board are that its contents cannot be erased, nor can a proof of
publish be forged.
Our choice of the bulletin board model as a viable model for fair
MPC is motivated by the fact that implementations of public bulletin
boards already exist in practice. We can realize a bulletin board from
an existing centralized system: Google’s certificate transparency
project which logs issued certificates.1
A decentralized implementation of a bulletin board can be realized from blockchain-based ledgers such as Etherium and Bitcoin
implemented with proofs of stake or proofs of work [16]. Proof of
work based blockchains rely on the assumption that the majority
of the network’s computational power is honest. In contrast, proof
of stake systems assume that some quorum of users are honest.
For each block, proof of stake systems select the quorum users,
typically at random but proportional to the amount of currency or
stake they have in the system, and that quorum must sign the next
block and (randomly) select the next quorum. The signature on a
block by the quorum constitutes an unforgeable proof that data
is on the bulletin board. In contrast to e.g. byzantine agreement
protocols, however, the user group is ad-hoc and tolerant to churn.
Proof of Stake and hybrid Proof of Stake/Proof of Work systems
are an area of active research.

1.1

have access to secure processors. In fact, Cleve’s impossibility result
holds even in the presence of secure processors, and was proved
recently in [58]. For concreteness, we work with Intel SGX as a
secure processor, following the formalization of [59]. For this result, we only need standard cryptographic assumptions such as
secret-key authenticated encryption and signatures. We provide an
implementation of this protocol in Section 8.
Comparison with recent works. Recently, [6, 17] showed how
block-chain based decentralized cryptocurrencies such as Bitcoin
can be used to achieve a notion of fairness with penalties where
aborting parties are forced to pay a pre-agreed financial penalty.
We note that while we also use blockchain based bulletin boards in
our work, our end result is quite different in that we achieve the
standard notion of fairness – either all parties get the output or
none do.
Very recently, [59] studied fairness in the model where each party
has access to a secure hardware equipped with secure clock. They
achieve a notion of ∆-fairness which guarantees that if an aborting
adversary can learn the output in time T , then the honest party can
also learn the output in time ∆ · T for ∆ = 2. A disadvantage of
this model is that T is controlled by the adversary, who can set it
arbitrarily to create large delay (e.g., in the order of several minutes
or hours) between the times when it gets the output and when the
honest party does.
We note that while we also use secure hardware for our second
result, we do not require them to implement secure clocks.2 More
importantly, we achieve the standard notion of fairness.

Our Results

In this work, we construct theoretical and practical fair MPC protocols for general functions in the bulletin board model. We, in fact,
provide general transformations from any (possibly unfair) n-party
MPC protocol that supports t < n corruptions to a fair MPC protocol secure against the same number of corruptions. Crucially, the
assumptions used in our transformations affect fairness only: the
correctness and privacy properties of the underlying MPC scheme
are completely preserved even if the assumptions were not to hold.

1.2

Technical Overview

We now describe the main ideas used in our constructions. For
simplicity of exposition, we restrict this discussion to the twoparty case. It is easy to generalize the ideas presented below to the
multiparty case.

I. Fair MPC from Witness Encryption. Our first contribution
is a fair MPC protocol in the bulletin board model assuming the
existence of witness encryption (WE) [37] and injective one-way
functions. In order to rely on the standard security of WE, we
require the bulletin board’s proof of publish to be implemented via
unique signatures [43, 56]. If the bulletin board is implemented via
standard signatures (e.g., in Google Transparency Certificates) or
proofs of stake (e.g., in Etherium), then we require the stronger
assumption of extractable witness encryption [19].
Candidate constructions of WE for NP [37, 39] are known from
multilinear maps [36]. Since present constructions [26, 27, 36, 38] of
multilinear maps are quite inefficient, we view our first construction
as a feasibility result. We note, however, that our construction
requires WE for a specific NP language for which constructing
efficient schemes from simpler assumptions might be easier. Indeed,
a fascinating open question for future work is whether WE for the
specific language used in our constructions can be implemented
from existing constructions for the related notion of hash proof
systems [28].

Starting Ideas. Our starting idea is to run an unfair MPC protocol
to compute an encryption of the function output as opposed to
computing it in the clear. We then design a special decryption
procedure such that either no party is able to perform the decryption
or both parties can. In other words, we reduce the fairness problem
in MPC to the problem of fair decryption.
At first, it may seem that we haven’t made any progress because
it is unclear why fair decryption would be any easier than achieving
fairness for general functions. Indeed, fair decryption was shown
to be a complete functionality for fair MPC in [46].
Our key insight is that a public bulletin board can be used to
implement a fair decryption protocol for a witness encryption scheme.
We elaborate on this idea below.
Fairness from Witness Encryption. A witness encryption scheme
for a language L can be used to encrypt a message m with a statement x in such a manner that the resulting ciphertext can only be
decrypted using a witness w for x. We now explain how we use
witness encryption to implement our fair MPC protocol.

II. Fair MPC from Secure Processors. Our second contribution
is a fair MPC protocol in the bulletin board where all the parties

2 In the specific case where the bulletin board is implemented using a proof of work

blockchain, we can use secure clocks to achieve stronger security guarantees. This
is unnecessary when the bulletin board uses signatures. We discuss this further in
Section 8.

1 Looking forward, our protocol only needs to post a constant sized token to the

blockchain and this can readily be embedded in a URL or certificate.

720

Session C5: Using Blockchains

CCS’17, October 30-November 3, 2017, Dallas, TX, USA

In order to securely compute a function f with complete fairness,
the parties first run a standard (possibly unfair) MPC protocol to
compute a randomized function that takes the private inputs say
(y1 , y2 ) of the parties and returns a witness encryption ciphertext
CT of the desired output F (y1 , y2 ). The statement x associated with
CT is set to be such that a valid witness for x corresponds to the
proof of posting a “release token” α (to be determined later) on the
bulletin board.
The only way for any party to obtain such a witness is to post
α on the bulletin board and obtain the corresponding proof of
posting σ . However, in doing so, the pair (α, σ ) is made public, and
therefore, anyone can obtain it. Thus, if a malicious adversary learns
the witness for decrypting CT, then so can the honest party since
it can simply read the public bulletin board. This mechanism puts
the honest party and the adversary on equal footing and resolves
the fairness problem.
While the above constitutes the core idea behind our work, we
run into several technical issues in implementing this idea. We
discuss these next, together with the solutions.

that if we set f to be an injective one-way function and implement
the proof of posting on the bulletin board via unique signatures
[43, 56], then we can bound the number of valid witnesses. In this
case, we can rely on the standard definition of WE.
Issue #3: Rewinding. We run into yet another issue while arguing
security of the above construction. Recall that in order to prove
security of a fair MPC protocol, we must construct a simulator who
can “force” the correct output on the real adversary, provided that
the adversary did not abort prematurely. In our protocol, the only
opportunity for the simulator to “program” the output is inside the
ciphertext CT computed during the initial MPC phase. However,
this point in our overall protocol is “too early” for the simulator to
determine with enough confidence whether the real adversary is
going to later abort or not. If the simulator’s decision to program the
output turns out to be wrong, then it would immediately lead to a
distinguisher between the outputs of the real and ideal experiments.
To deal with this issue, we use a rewinding strategy previously
used in [40, 44, 46] to determine the aborting probability of the
adversary with enough accuracy, while still ensuring (expected)
polynomial running time for the simulator. In order to ensure indistinguishability of the adversary’s view in the real and ideal experiments, we allow the simulator to also rewind the bulletin board
to a previous state, as and when necessary. Indeed, without this
capability, the simulator cannot prevent an adversary from “detecting rewinding” by continuously posting on the bulletin board.
A consequence of this is that we must model the bulletin board
as a “local” functionality as opposed to a “global” functionality
[21, 22]. Furthermore, since our simulator performs rewinding, we
only achieve stand-alone security.

Issue #1: Setting the release token. An immediate issue with implementing the above idea is that we cannot set the release token α to
be an a priori fixed value that is known to the adversary. Indeed,
if this is the case, then the adversary can simply abort during the
execution of the unfair MPC protocol so that it learns the ciphertext
CT, but the honest party does not. Now, even if the honest party
can obtain (α, σ ) once the adversary has posted it on the bulletin
board, it cannot learn the output F (y1 , y2 ) since it does not have
CT to decrypt.
To address this issue, we set α to be a pair of random values
(α 1 , α 2 ) where α i is chosen by the i-th party. During the initial
MPC phase, each party uses α i as an additional input such that the
output of the MPC is (β, CT) where βi = f (α i ) for some one-way
function f and β = (β 1 , β 2 ). Now, even given (β, CT), the value α
is not completely known to the adversary. Therefore, if it aborts
prematurely, then the honest party aborts as well, knowing that
the adversary would not be able to recover the output.
On the other hand, if the first phase is successfully completed,
then the parties execute a second phase where each party i simply
sends over α i to the other party. Of course, the adversary may abort
in this phase after learning α. However, in order to decrypt CT, it
will have to post α on the bulletin board which means the honest
party would learn it as well. This restores the balance between the
honest party and the adversary.

Fairness from Secure Hardware. Roughly, the main idea in our
second protocol is to replace the witness encryption in the plain
model with a secure hardware that implements (essentially) the
same functionality as witness encryption. We require that each
party is equipped with such a secure hardware (e.g., Intel SGX).
While much of the details in this protocol are similar to the previous
one, there are some key differences. We explain them below.
Once the parties have “installed” an appropriate program P (discussed below) in their own local secure hardware and attestation of
the same is successfully performed by everyone, they run (as in the
previous protocol) an execution of a standard MPC protocol to compute an encryption CT of the desired output. Unlike the previous
scheme where CT was computed using witness encryption, here we
use a regular secret-key encryption scheme. The secret key K used
for encryption is secret-shared amongst the parties who use their
respective shares as additional inputs to the MPC. The key K is also
loaded in each party’s secure hardware, and is in fact computed by
the secure hardware devices during an initial key-exchange phase.
As in the previous protocol, we require that the ciphertext CT
can only be decrypted if the release token α has been posted on
the bulletin board. The program P loaded in each party’s secure
hardware implements such a conditional decryption mechanism.
Specifically, upon receiving a ciphertext CT, a release token α and
a corresponding proof of posting σ , the program P verifies the
validity of α and σ . If the verification succeeds, then it decrypts CT
and returns the output; otherwise it returns ⊥.

Issue #2: Security of WE. The standard definition of witness encryption only guarantees semantic security for a ciphertext CT if the
statement x associated with it is false. In our case, the statement
is always true. The only way to argue security in this case is to
use a stronger notion of extractable witness encryption [19] which
guarantees that for any statement x, if an adversary can distinguish
between witness encryption of m from an encryption of m ′ , m,
then one can efficiently recover from that adversary a witness w
for x. Now, if the witness w is computationally hard to find, then
we can get a contradiction.
It was shown in [19] that for languages with statements that
have only polynomially many witnesses, the standard definition
of WE implies the stronger definition of extractable WE. We note

721

Session C5: Using Blockchains

CCS’17, October 30-November 3, 2017, Dallas, TX, USA

We remark upon two security issues: first, in order to prevent
malleability attacks, we require that an authenticated encryption
scheme is used in order to compute CT. Further, to prevent an adversary from performing a related key attack (by changing its input
key share in the MPC), we require that the secure hardware also
provide commitments Ci of each key share Ki to all the parties upon
generation of K. A party i is required to input the decommitment
to Ci in the MPC protocol, and the MPC functionality checks that
all the input key shares are valid by verifying the decommitment
information.
Second, for this protocol, we can completely dispense with rewinding and instead construct a black-box, non-rewinding simulator.
This is because the use of secure hardware allows the simulator to
“program” the output at the very end, when the adversary makes
a decryption query to its secure hardware.3 Indeed, in the secure
hardware model, the simulator has the ability to observe (and modify) the queries made by the adversary to its secure hardware. This
means that when the adversary makes a final decryption query, the
simulator can check if it is valid. If this is the case, then it queries
the trusted party to obtain the function output. At this point, the
simulator sends a “fake” decryption query to the secure hardware
that already contains the desired output. Upon receiving this query,
the secure hardware returns the programmed output to the adversary. We note that this programming technique for secure hardware
was recently used in [59].
Because of the above modifications, in this protocol, we can
model the bulletin board as a global functionality. In this manuscript,
however, we do not prove UC security of our protocol and leave it
for future work.

that this is merely an implementation detail. Our bulletin board
could easily be replaced with one of the alternatives above.
Optimizations. We mention a few optimizations to the above
protocols to improve efficiency. First, we can add an optimistic
decryption phase in the above protocols that allows the parties to
learn the output using a simple decryption process, without using
the bulletin board, provided that all the parties are honest. Roughly,
the MPC protocol executed in the first phase now additionally
computes another encryption CT ′ of the function output, where CT ′
is implemented using a regular encryption scheme. The decryption
key K ′ corresponding to CT ′ is secret-shared between the parties.
Now, if the release-token exchange performed in the second phase
is successful, then the parties execute a third phase (that we refer
to as the optimistic decryption phase) where they exchange the key
shares corresponding to K ′ . If all the parties are honest, then they
all learn K ′ and use it to decrypt CT ′ , without using the bulletin
board. However, if one or more parties are adversarial and abort in
this phase, then the honest parties can still post the release token α
(that they learned in the second phase) on the bulletin board and
then use the proof of posting to decrypt CT as before.
We remark that in order to avoid related key attacks by an adversary, we would need a slight modification to the above protocol
where the MPC in the first phase outputs commitments to each
key share Ki′ to both the parties. During the optimistic decryption
phase, each party must reveal the decommitment value together
with Ki′ . A party only accepts the key share as valid if the associated
decommitment information is correct.
Finally, we note that the size of the release token α = (α 1 , α 2 )
used in the above described protocols grows with the number of
parties N . However, it is easy to make it independent of N by setting
α = ⊕i α i and using β = f (α) to verify the correctness of release
token. An advantage of this modification is that the witness length
for the witness encryption used in our construction, as well as the
length of the string that is posted on the bulletin board becomes
independent of the number of parties.

Realizing the Bulletin Board. Our constructions assume a public
bulletin board that is capable of producing an unforgeable proof
that a string has been published to the bulletin board. Such bulletin boards can easily be constructed practice if one is willing to
instantiate the board using a single trusted party. While this seems
a strong assumption, the advantage of this approach is that such
systems already exist and have been widely deployed in practice for
applications such as Certificate Transparency [1]. Re-using them
to achieve fairness in arbitrary MPC protocols requires no specific
to the existing systems.
Alternatively, a bulletin board can be realized using a decentralized systems such as proof of stake blockchains (e.g., [49]). These
systems allow a quorum of honest users – who together possess
a majority ownership “stake” in a cryptocurrency – to securely
authenticate an append-only log using signatures. Finally, a weaker
notion of security can be achieved using a proof of work blockchain.
In the latter case, the “proof” of publication is not a cryptographically unforgeable signature, but rather the solution to a sequence
of one or more computational puzzles which may be, in practice,
prohibitively expensive for an attacker to forge.4 We explore this
approach in our experimental implementation, although we stress

2

RELATED WORK

A large body of research work has addressed the problem of fairness in secure protocols over the years. Below, we provide a nonexhaustive summary of prior works. A more elaborate summary
can be found, e.g., in [17].
Fairness in Standard Model. Assuming an honest majority of
parties, fair MPC can be achieved in both computational [41] and
information-theoretic setting [61]. Cleve [25] proved the impossibility of MPC for general functions n the dishonest majority setting.
Subsequently, an exciting sequence of works [7–9, 45, 47] have
shown that complete fairness can still be achieved for a restricted
class of functions. The works of [5, 14, 48] study the problem of
partial fairness.

3 We also use an MPC in the common random string (CRS) model (e.g., [23]) to imple-

ment the first phase of the protocol. By using the CRS trapdoor, the simulator for this
phase can avoid any rewinding of the adversary.
4 In practice, such proof of work blockchains provide a slightly weaker security that is
related to ∆-fairness. An attacker, given enough time, may be able to forge the proof
of work necessary to prove publication. However, in the trusted hardware setting we
are able to mitigate this concern to some extent by requiring the attacker to provide a
proof in a limited period of time, as judged by the hardware.

Optimistic Models. Starting from the early work of [15], optimistic models for fair exchange have been studied in a long sequence of works [11, 12, 30, 33, 54, 57]. An optimistic model for
fair two-party computation using a semi-trusted third party was
studied in [20, 51].

722

Session C5: Using Blockchains

CCS’17, October 30-November 3, 2017, Dallas, TX, USA

Gradual Release Mechanisms. A different approach to fairness
that avoids trusted third parties was considered in a long sequence
of works [18, 32, 35, 60], following the early works of [13, 31, 42].
The protocols in these works employ a “gradual release” mechanism
where the parties take turns to release their secrets in a bit-by-bit
fashion. The intuitive security guarantee (formalized in [34]) is
that even if an adversary aborts prematurely, the honest party can
recover the output in time comparable to that of the adversary by
investing equal (or more) computational effort.

The overall output of the ideal-world experiment consists of
the outputs of all parties. For any ideal-world adversary Sim with
auxiliary input z ∈ {0, 1}∗ , input vector x,
® and security parameter λ,
we denote the output of the corresponding ideal-world experiment

by IDEALSim, F 1λ , x,
®z .
Real World. The real world execution begins by an adversary A
selecting any arbitrary subset of parties P A ⊂ P to corrupt. The
parties then engage in an execution of a real n-party protocol Π.
Throughout the execution of Π, the adversary A sends all messages
on behalf of the corrupted parties, and may follow an arbitrary
polynomial-time strategy. In contrast, the honest parties follow the
instructions of Π.
At the conclusion of all the update phases, each honest party P i
outputs whatever output it received from the computation. Malicious parties may output an arbitrary PPT function of the view of
A.
For any adversary A with auxiliary input z ∈ {0, 1}∗ , input
® and security parameter λ, we denote the output of the
vector x,

MPC protocol Π by REAL A, Π 1λ , x,
®z .

∆-Fairness. Very recently, [59] considered a notion of ∆-fairness
with the guarantee that if an adversary aborts, then the honest party
can learn the output in time ∆ · T , where T is the time in which the
adversary would learn the output. They propose a fair two-party
computation protocol with (∆ = 2)-fairness assuming that all the
parties have secure hardware equipped with secure clocks.
Fairness with Penalties. Recently, with the popularity of decentralized cryptocurrencies such as Bitcoin, a sequence of works [6,
17, 52, 53] have shown how to implement a fairness-with-penalties
model for MPC where adversarial parties who prematurely abort
are forced to pay financial fines. Prior works in similar spirit considered fairness with reputation systems [10] and legally enforced
fairness [24, 55].

MPC with Complete Fairness. We say that a protocol Π is a
secure protocol if any adversary, who corrupts a subset of parties
and runs the protocol with honest parties, gains no information
about the inputs of the honest parties beyond the protocol output.

3 DEFINITIONS
3.1 Fair Multi Party Computation

Definition 3.1. A protocol Π is a secure n-party protocol computing F with complete fairness if for every PPT adversary A in the
real world, there exists a PPT adversary Sim corrupting the same
parties in the ideal world such that for every initial input vector x,
®
every auxiliary input z, it holds that




IDEALSim, F 1λ , x,
® z ≈c REAL A, Π 1λ , x,
®z .

A secure fair multi-party computation protocol is a protocol executed by n number of parties P1 , · · · , Pn for a n-party functionality
F . We allow for parties to exchange messages simultaneously. In
every round, every party is allowed to broadcast messages to all
parties. We require that at the end of the protocol, all the parties
receive the output F (x 1 , . . . , x n ), where x i is the i t h party’s input.5
We formalize the security notion below.
Ideal World. We start by describing the ideal world experiment
where n parties P1 , · · · , P n interact with an ideal functionality for
computing a function F . An adversary may corrupt any subset
P A ⊂ P of the parties. We denote the honest parties by H .
Inputs: Each party P i obtains an initial input x i . The adversary
Sim is given auxiliary input z. Sim selects a subset of the
parties P A ⊂ P to corrupt, and is given the inputs x k of
each party Pk ∈ P A .
Sending inputs to trusted party: Each honest party Pi sends its
input x i to the trusted party. For each corrupted party P i ∈
P A , the adversary may select any value x i∗ and send it to
the ideal functionality.
Trusted party computes output: Let x 1∗ , . . . , x n∗ be the inputs that
were sent to the trusted party. If any of the received inputs
were ⊥, then the trusted party sends ⊥ to all the parties. Else,
the trusted party sends F (x 1∗ , . . . , x n∗ ) to all the parties.
Outputs: Honest parties output the function output they obtained
from the ideal functionality. Malicious parties may output
an arbitrary PPT function of the adversary’s view.

Security with Abort. For our constructions, we shall require a
weaker security notion of MPC referred to as security with abort.
This definition differs from the above only in the ideal world, where
the adversary receives the output prior to the honest parties and
then decides if the trusted party should give the output to the honest
parties or not.

5 One can also consider asymmetric functionalities where every party receives a dif-

Definition 3.2. A scheme Σ = (Gen, Tag, Verify) is an authentication scheme with public verification if for any sequence of messages
m 1 , . . . , mq and any PPT adversary A, the following is negligible

3.2

Authentication Scheme with Public
Verification

An authentication scheme with public verification consists of three
polynomial algorithms (Gen, Tag, Verify).
– Gen is PPT algorithm that takes as input λ and generates a
key for signing. sk ← Gen(λ).
– Tag is a deterministic algorithm that computes a tag on a
message x. σ = Tagsk (x).
– Verify is a deterministic algorithm that allows for public
verification of the tag. Verify(x, σ ) returns 1 if the tag σ
verifies.

ferent output. Since there are generic transformations from the symmetric case to
the asymmetric case, we only consider symmetric functionalities for simplicity of
exposition.

723

Session C5: Using Blockchains

CCS’17, October 30-November 3, 2017, Dallas, TX, USA

in the security parameter:
 sk ← Gen(λ);



Verify(m ′, σ ′ ) = 1
 ∀i σi = Tag (mi );

sk 
Pr 
 : Ó m ′ < {m , . . . , m } 

q
1
q 
′
′
 (m , σ ) ← A {mi , σi }i=1




Theorem 3.6. Suppose L is a polynomial witness language. Then,
witness encryption for L implies extractable witness encryption for
L.

3.3

We describe briefly our modeling of the bulletin board. The bulletin
board models a public ledger that lets parties publish arbitrary
strings. On publishing the string on the bulletin board, the party
receives a proof to establish the string was indeed published. In our
setting, we model these proofs via authentication tags that can be
publicly verified and the string subsequently publicly accessible.
For security, we require that the authentication tags follow the
standard notion of unforgeability described earlier (see definition
3.2).
In addition, the bulletin board implements a counter. Each time a
string is published on the bulletin board, the counter is incremented
and the authentication tag is produced on the string and counter
pair. While the counter value of the bulletin board is assumed to
be publicly accessible, we shall model it as an explicit query. The
counter also serves as an index to the string on the bulletin board.
Hence, we model the bulletin board BB through the following
queries:

4

Witness Encryption

In this section, we define witness encryption [39] and state its
relation with extractable witness encryption [19] for polynomial
witness languages.
Definition 3.3 (Extractable Witness Encryption). An extractable
witness encryption ExtWE = (Enc, Dec) for a NP language L associated with relation R consists of the following algorithms:
– Encryption, Enc(1λ , x, m): On input instance x and message
m ∈ {0, 1}, it outputs a ciphertext CT.
– Decryption, Dec(CT, w): On input ciphertext CT and witness w, it outputs m ′ .
We require that the above primitive satisfies the following properties:
– Correctness: For every x ∈ L, let w be such that (x, w) ∈ R,
for every m ∈ {0, 1},
Pr[m ← Dec(Enc(x, m), w)] = 1

MODELING THE BULLETIN BOARD

– getCurrentCounter: the bulletin board returns the current
value of the counter.

– Security: Let A be a PPT adversary such that the following
holds: for every x, m 0 , m 1 , every auxiliary information z ∈
{0, 1}poly(λ) :

t ← BB(getCurrentCounter).
– post: on receiving value x, the bulletin board increments the
counter value by 1 to t, computes the authentication tag on
(t ||x) and responds with the tag and t to the posting party.
The value and the corresponding tag can be retrieved by
querying the bulletin board on t.

Pr[1 ← A(1λ , Enc(x, m 0 ))] − Pr[1 ← A(1λ , Enc(x, m 1 ))] ≤ ε
Then there exists a PPT extractor Ext such that:
Pr[w ← Ext A (1λ , x) : (x, w) ∈ R] ≥ ε − negl

(σ , t) ← BB(post, x)

We now define the notion of polynomial witness languages.

such that VerifyBB (σ , (t ||x)) = 1.
– getContent: on receiving input t, it returns the value and the
corresponding tag stored at counter value t. If t is greater
than the current counter value, it returns ⊥. Else,

Definition 3.4 (Witness Languages). Consider an NP language L
and let R be its associated relation. We say that L is a polynomial
witness language if there exists a fixed polynomial p such that for
every x ∈ L it holds that there exists a size p(|x |) set of witnesses
w such that w ∈ {0, 1}poly( |x |) and (x, w) ∈ R.

(σ , x) ← BB(getContent, t)

Definition 3.5 (Witness Encryption). A witness encryption WE =
(Enc, Dec) for a NP language L consists of the following algorithms:

We note that bulletin boards have previously been considered in
works such as [50], but their model differs significantly from ours.

– Encryption, Enc(1λ , x, m): On input instance x, message m
and it outputs a ciphertext CT.
– Decryption, Dec(CT, w): On input ciphertext CT and witness w, it outputs m ′ .
We require that the following properties hold:
– Correctness: For every x ∈ L, let w be such that (x, w) ∈ R,
for every m ∈ {0, 1},

5

FAIR MPC FROM WITNESS ENCRYPTION

Overview. We start by giving an overview of our protocol. Our
protocol builds on an MPC protocol that achieves the weaker notion
of security with abort, where the fairness condition is not required
to hold. The initial phase constitutes of the parties using this unfair
MPC protocol to compute a witness encryption ciphertext of the
function value they wish to compute. To decrypt, a party must
post messages of a specific form (referred to as “release tokens”)
on to the bulletin board which the bulletin board validates with
an authentication tag. The idea then is that any party can use this
posted information and authentication tag to decrypt the witness
encryption ciphertext. The release token must include shares of all
parties that are secret prior to the completion of this initial phase.
These shares must also be easily verifiable. Our construction uses

Pr[m ← Dec(Enc(x, m), w)] = 1
– Message Indistinguishability: For every PPT adversary
A, there is a negligible function ε, such that for every x < L
the following holds:
Pr[1 ← A(1λ , Enc(x, m 0 ))] − Pr[1 ← A(1λ , Enc(x, m 1 ))] ≤ ε.
The following theorem was shown in [19].

724

Session C5: Using Blockchains

CCS’17, October 30-November 3, 2017, Dallas, TX, USA

(3) A witness encryption WE for the language
n



L WE, ∆t = {yi }i ∈[n] ,T ∃ t, σ , {ρ i }i ∈[n] s.t.

injective one-way functions, where the images of these shares are
sent out during the initial phase.
The next phase, on completion of the initial phase, constitutes
of parties sending these secrets to every other party. Once a party
releases its share, it must not abort until it is sure that the other
parties cannot post to the bulletin board, and hence decrypt the
message thereafter. Otherwise, the adversary on receiving the secret
shares will wait for the honest parties to abort before posting to the
bulletin board. This is resolved by parameterizing the protocol by a
cut-off period which once elapsed, effectively ends the protocol. If
there isn’t a valid post to the bulletin board at this time, no party
gets the output.
To argue security, we require each statement in the language
corresponding to the witness encryption to have only a polynomial
size witness set. To do so, we use an injective one-way function
and a unique signature scheme. The witness for the statement are
the pre-images of the values sent during the initial phase, and the
corresponding tag from the bulletin board. This pair is unique for
a given statement. But we need to incorporate the cut-off period
into the witness. This is enforced by the counter in the bulletin
board as described in section 4. In the protocol, this translates to
a window (set) of counter values which qualify as the additional
variable in the witness. To ensure that the number of witnesses
are still polynomial, the window size has to be polynomial. We
parameterize the protocol with the size of this window, and the
parties choose the start point of the window.
As discussed in the introduction, for the proof in this model, it
is essential that the simulator is able to reset the bulletin board to a
prior point (in essence, rewinding).

(∀i ∈ [n], yi = f (ρ i )) AND
t ∈ {T ,T + 1, · · · ,T + ∆t } AND
VerifyBB ((t ||ρ 1 || · · · ||ρ n ), σ ) = 1

o

For a given x ∈ L WE, ∆t , if f is an injective one-way function
and (Gen, Tag, VerifyBB ) is a scheme that generates unique
authentication tags, it is easy to see that there are only ∆t + 1
witnesses for x. If ∆t is set to be polynomial in the size of x,
there are only polynomially many witnesses for any given
statement, and thus L WE, ∆t is a polynomial witness language
(see Definition 3.4). From Theorem 3.6, given L WE, ∆t is a
polynomial witness language, we know that a witness encryption for L WE, ∆t is also an extractable witness encryption
for L WE, ∆t .
(4) An MPC protocol that computes:


′
F∆t
((x 1 , ρ 1 , t 1 ), · · · , (x n , ρ n , tn )) = c, { f (ρ i )}i ∈[n] ,T
where T = max(t 1 , · · · , tn ) and c = WE.Enc(x WE, ∆t , F (x 1 ,
· · · , x n )) for x WE, ∆t = ({ f (ρ i )}i ∈[n] ,T ). We do not require
this protocol to be fair. Importantly, we use the MPC protocol
in the common random string (CRS) model. This allows for
black-box simulation of the adversary without the necessity
of rewinding. For this section, we shall drop the CRS notation,
but it will be implicit.
Remark 1. In the construction described above, the size of the
witness encryption circuit is dependent on the number of parties in
the protocol. This can be remedied by using the XOR of the ρ i values
as the release token, and applying the injective one-way function on
this. The rest of the protocol remains the same.

– rewind: This functionality is reserved for the simulator in
the ideal world. On receiving additional input t, the bulletin
board internally resets its counter to t and clears all data
stored beyond the counter value t. The simulator gets no
output on this query.

5.1

⊥← BB(rewind, t)

Proof of Security

′ -hybrid model.
We prove the security of our construction in the F∆t

We want to stress that this additional capability is only limited
to the construction in this section and the construction in the next
section (using trusted hardware) we will not require this.
We additionally discuss an extension to an optimistic phase
where the parties can share some additional secrets (different from
before) that enable them to decrypt a (different) ciphertext containing the output, without having to post to the bulletin board.
Of course, the adversary can prematurely abort in this phase and
obtain the output for itself. To protect against this, the optimistic
phase is reached only once it has been established that the parties
have enough information that would enable them to use the bulletin
board, to decrypt to the output, in case the adversary aborts in this
phase.

Simulator S. We start by constructing a simulator S. Our simulator uses rewinding strategy similar to the one described in [44]
(which in turn builds on [40]). The simulator has access to an ideal
′ for the real world
functionality for computing F , and simulates F∆t
adversary. In addition, for the proof in this model, the simulator reserves the right to reset the bulletin board to prior point (in essence,
rewinding). (We will not require this property in the protocol based
on secure hardware.) Further, S forwards any queries the adversary makes to the bulletin board, and returns the corresponding
response from the bulletin board.
(1) S receives inputs {(x a , ρ a , ta )}a ∈A sent by the adversary
′ .
that are intended for F∆t
(2) Mark the current value of the counter so that S can rewind
the bulletin board to this point.

Construction. We now proceed to describe our protocol Πfair . It
uses the cryptographic primitives and a bulletin board as described
below. The formal protocol description is given in Figure 1.

t mark ← BB(getCurrentCounter)

(1) A injective one-way functions f .
(2) An authentication scheme with public verification (Gen, Tag,
VerifyBB ) such that the authentication tags are unique for a
given message.

′
(3) S simulates the output of ideal functionality computing F∆t
as follows:
(a) Set T = max{{ta }a ∈A , t mark }.
(b) Randomly pick {ρh }h ∈H for the honest parties.

725

Session C5: Using Blockchains

CCS’17, October 30-November 3, 2017, Dallas, TX, USA

′ -Hybrid model
Protocol Π fair in the F∆t

Inputs: Each party Pi has an input x i .
Common input: The verification key for the bulletin board vkBB .
The protocol:
′ .
(1) Computation of F∆t
$

– Pi samples token ρ i ← {0, 1}poly(λ) .
– Pi queries the bulletin board to get the current counter value, i.e. ti ← BB(getCurrentCounter).


′ and receives c, {y }
– Pi sends (x i , ρ i , ti ) to the ideal functionality F∆t
i i ∈[n] ,T . It aborts if it receives ⊥ from the ideal
functionality.
(2) Exchange of tokens. Pi broadcasts ρ i to all other parties, and receives {b
ρl }l ∈[n]\{i } .
(3) Obtaining the output. We split this into three cases, where either (i) Pi can post on the bulletin board to receive a valid
witness; or (ii) Pi waits for another party to post to the bulletin board; or (iii) no party posts to the bulletin board.
(i) Pi received ρ j from all the other parties, such that ∀j ∈ [n] \ {i} : f (ρ j ) = y j . In this case, Pi waits for the counter to get to T
before posting to the bulletin board. Prior to posting, it check to see if another party has already posted the same. This could
be done either by observing the broadcasts sent (to the bulletin board), or querying the bulletin board at most ∆t times. On
obtaining the appropriate authentication tag, the witness encryption can be decrypted to get the output.
(ii) Pi received a ρ j such that f (ρ j ) , y j , or ρ j =⊥ (i.e. a party didn’t send its token). In this case, Pi checks if the right message is
posted to the bulletin board for counter values between T and T + ∆T . If it finds the right value, it obtains the authentication
tag and decrypts the witness encryption to get the output.
(iii) If there are no posts on the bulletin board satisfying the given requirements, and the counter has progressed beyond T + ∆t,
Pi aborts.
′ -Hybrid model. The protocol relies on the security of witness encryption for a polynomial witness
Figure 1: Π fair in the F∆t
language, injective one-way functions and authentication scheme with public verification and unique tags.
t
. The polynomial defin(c) S estimates q as qe = # of repetitions
ing t is chosen to be large enough that


1 q
Pr
≤ ≤ 2 > 1 − 2λ .
2 qe

(c) ∀i ∈ [n], yi B f (ρ i ).
c ← F (b
(d) Compute out
x 1 , · · · , xbn ) where xbh = 0 for all h ∈
H.


(e) Set x WE B {yi }i ∈[n] ,T and compute


c .
c ← WE.Enc x WE , out

(7) The simulator sends {x a }a ∈A to the ideal functionality for
t times.
F and receives out. S repeats the following at most qe
(a) With fresh randomness each time, S rewinds the adversary to step 3, rewinds the bulletin board BB(rewind,
t mark ) and repeats steps 3 and 4 (other than 3(g)) replacing
c with out.
out
(b) If the adversary does not abort, we output its view and
the simulator terminates.
(8) If S has not terminated yet, output fail and terminate the
simulation.

(f) Send (c, {yi }i ∈[n] ,T ) to the adversarial parties.
(g) If the adversary responds with an abort, S sends abort to
the ideal functionality computing F , and exits. For our
analysis, we denote this by abort1 .
(4) S sends values {ρh }h ∈H to the adversary. If the adversary
sends values {ρ a }a ∈A such that ∀a, ya = f (ρ a ); or sends
a post query to the bulletin board with value (ρ 1 || · · · ||ρ n )
when counter value is betweenT andT +∆t such that ∀i, yi =
f (ρ i ), the adversary has not aborted.
(5) If the adversary aborted in the previous step, S sends abort
to the ideal functionality computing F , and exits. For our
analysis, we denote this by abort2 .
(6) If the adversary didn’t abort prior to this, we need to estimate
the probability of the adversary not aborting. Let q represents
the true of probability of this event, where the randomness is
over random coins used in step 3(b) and 3(e). The estimated
probability will be denoted by qe.
(a) S fixes some number t = poly(λ).
(b) S rewinds the adversary to step 3, rewinds the bulletin
board BB(rewind, t mark ) and repeats steps 3 and 4 (other
than 3(g)) with fresh randomness each time. Repeat till
the adversary has not aborted t times.

Claim 1. If simulator S does not outputs fail, the hybrid world
and the ideal world are indistinguishable.
Proof. We split the analysis into two cases:
– Case 1: The adversary does not abort. Since the simulator
does not output fail, it has successfully got the adversary to
accept the transcript for the right output. In this case, the
main thread of the adversary is statistically indistinguishable
from the real execution. Additionally, since the simulator is
able to rewind the bulletin board, the adversary’s view of
the bulletin board is that of a straight line execution. Thus
the joint distribution consisting of the view of the adversary
and the honest party outputs is indistinguishable.

726

Session C5: Using Blockchains

CCS’17, October 30-November 3, 2017, Dallas, TX, USA

6

– Case 2: The adversary aborts. As noted in the simulator, the
adversary can abort in two phases of the protocol. We deal
with the two case separately:
abort1 : The adversary aborts immediately after running the
′ . In both the real and ideal world, honest parMPC for F∆t
ties do not get any output. Thus, we need to argue that the
adversary’s view is indistinguishable when he receives a witness encryption of the actual output as opposed to when he
received the witness encryption of a random string. To the
contrary, assume that the adversary can distinguish between
these two cases. Since there only polynomially many witnesses, we use the extractor for the adversary to recover the
witness. Since the honest parties aborts without revealing its
share of the token, we can use the extractor to construct an
adversary that breaks the security of the injective one-way
function.
abort2 : The adversary aborts on receiving the honest party’s
tokens without posting to the bulletin board. We use the
same technique as above, leveraging the extractor for witness encryption, to construct an adversary that breaks the
unforgability of the authentication tags issued by the bulletin
board.


Model Following the approach of Pass et al. [59] we model all
available trusted hardware processors from a given manufacturer
as a single, globally shared functionality denoted Gatt (see Figure 5).
We describe the functionalities required for our construction, and
refer the reader to [59] for details. install loads the program prog
onto the attested hardware. It returns an enclave identifier eid. (For
simplicity, we skip the session identifier used in [59].) The enclave
identifier is be used to identify the enclave upon resume. resume
allows for a stateful resume using the unique enclave identifier
generated. On running over a given input, the output produced is
signed to attest that the enclave with identifier eid was installed
with a program prog, which was then executed to produce the
output. The program’s input is not included in the attestation.

Claim 2. The simulator S outputs fail with only negligible probability.
The proof can be found in Appendix A.;
We assume that the value of T chosen in the protocol is such that
the real execution of the protocol ends in time bounded above by a
′ implements an additional check
polynomial д(λ). Otherwise F∆t
to ensure this.

Description. We describe here the main ideas in this construction
that differ from the previous construction. Upon loading the program onto the attested hardware (enclaves), there is an initial key
exchange to establish a secure authenticated channel between the
enclaves. Any information passed over this channel is hidden from
the parties. It is important that enclaves attest to the fact that they
are running the correct programs prior to the key exchange.
Next, the shares of the release token and the key are input to
the enclave. The enclaves use the established secure authenticated
channel to exchange this information and set up consistent parameters (over all enclaves) for the decryption circuit. The parties then
run an MPC protocol external to the enclaves to compute an encrypted version of the output. As in our previous construction, the
players exchange shares of the release token that they are required
to post onto the bulletin board in order to decrypt.
For technical reasons, we need to ensure that the key share that
a party sends to the enclave is the one used in the MPC. This is ensured by using a commitment scheme which the MPC computation
verifier before returning the output.
Our protocol makes requires the following primitives:

Claim 3. The simulator S runs in expected polynomial time.
Proof. With probability 1 − q, the simulator aborts prior to step
6. With probability q, the simulator goes through the estimation
phase and then attempts to force an accepting transcript onto the
adversary. The expected number of iterations for the estimation
t < t .
phase is qt and the cut-off point for forcing the transcript is qb
2q
Hence the total expected running time is bounded by


t
2t
д(λ) · q ·
+
= д ′ (λ)
q
q
Thus S runs in expected polynomial time.

FAIRNESS FROM SECURE HARDWARE

A key limitation of our previous constructions is the need to use
Witness Encryption (WE) to protect the output of the MPC protocol.
Unfortunately, current proposed WE construction are inefficient,
due to the high overhead of current constructions of multilinear
maps. Moreover, the Witness Encryption paradigm requires the
parties to compute a new WE ciphertext for each invocation of the
MPC protocol.
In this section we investigate an alternative paradigm that uses
secure hardware. Our work is motivated by the recent deployment
of commodity virtualization technologies such as Intel’s Software
Guard Extensions (SGX). These technologies allow for the deployment of secure “enclave” functionalities that can store secrets and
perform correct computation even when executed in an adversarial
environment. Moreover, these systems allow an enclave to remotely
attest to their correct functioning, which allows for the establishment of trustworthy communications between enclaves running
on different machines.



Given the above claims, the following theorem follows.
Theorem 5.1. Assuming the security of injective one-way functions, witness encryption for polynomial witness language and the
unforgeability of the authentication scheme, the above protocol satis′ -hybrid model.
fies Definition 3.1 in the F∆t
As mentioned in the introduction, in order to rely on the standard
security of WE, we require the bulletin board’s proof of publish to be
implemented via unique signatures [43, 56]. If the bulletin board is
implemented via standard signatures (e.g., in Google Transparency
Certificates) or proofs of stake (e.g., in Etherium), then we require
the stronger assumption of extractable witness encryption [19].

(1) A one-way function f .6
(2) A signature schemes (Gen, Sign, Verify).
6 In practice we suggest using a hash function.

727

Session C5: Using Blockchains

CCS’17, October 30-November 3, 2017, Dallas, TX, USA

(3) An authentication scheme with public verification (Gen, Tag,
VerifyBB ).
(4) A multi-party computation in the CRS model for computing
F ′ defined as

to post newly-issued certificates to a public log. These entries are
then (1) signed by the log maintainer, and (2) added to a Merkle
hash tree. The root of the hash tree is also signed by (one or more)
log maintainers and published to the world.
A collection of users known as monitors can access the CT log
to view the contents of certificates. While the CT log is itself not
fundamentally tamper resistant – since the servers operating it can
remove portions and/or be disabled by remote network attacks –
any tampering is detectable due to the structure of the Merkle hash
tree. The location of the entry within the Merkle hash tree also
serves to act as a proxy for a monotonically increasing sequence
number.
Under the assumption that the existing CT logs are reliable and
trustworthy, we can use CT to build fairness systems by entombing
the required public data into a component of an X.509 certificate
signing request and requesting the certificate from a free certificate
authority such as LetsEncrypt [2]. Because LetsEncrypt submits all
certificates to a public log7 it is possible for any party to recover
these certificates and verify a cryptographic proof that the entries
have been published.



x i , ki , {comi j }j ∈[n] , r i i ∈[n] =

 

if ∃i, i ′ s.t. {comi j }j ∈[n] , {comi ′ j }j ∈[n]
F′




⊥



⊥



y


if ∃i s.t. comii , Com(ki ; r i )
otherwise

where y = AE.EncÉn ki (F (x 1 , · · · , x n )). Essentially the
i =1
MPC takes in a the input, key share, a commitment tuple
and a decommitment from each party. It checks if the tuple
pairs received are the same throughout and the commitment
linked to each party decommits to the key share. If this check
fails it just returns ⊥, or it returns the output y.
(5) Two instances of AE scheme (Enc, Dec) with INT-CTXT
security for authentication and semantic security.
(6) A commitment scheme (Com) with computational hiding
and statistically binding.
We describe and prove the protocol in the two party setting.
Both extended naturally to the multi-party setting. The protocol is
described in Figure 2.
We note that there are two trapdoors installed into functionalities
of progfair . These are used for the security reduction of the one-way
function, and to program the output correspondingly. Specifically,
the trapdoor is used to get the enclave to attest to a value of choice.
These trapdoors can be used by an adversarial party, but this makes
no difference to the security since these values are not sent across
to the other party.

Public blockchains. Crypto-currencies such as Bitcoin or Etherium
rely on a publicly available data structure called a blockchain. Blockchains are an append-only ledger that is maintained by an ad-hoc
group of network peers. Blockchains come in two basic types. The
first type use computational proofs of work to determine which
peer should be allowed to add a new block of transactions to the
blockchain. Clients accept the longest chain that contains well
formed transactions; as a result the system is secure as long as a
supermajority of the computational power in the network is controlled by honest peers. This approach is tolerant of churn, and
thus we need not pick a set of honest parties in advance.
An alternative approach uses proof of stake [16]. In these systems
a quorum of peers is sampled from the network with probability
proportional to the fraction of monetary holdings controlled by
each peer. This quorum is responsible for producing the next block
and selecting the next quorum by the same mechanism. The peers
authenticate the resulting block by signing it using a secure digital
signature scheme. The security assumption here assumes that the
parties with the largest share of the cryptocurrency have a vested
interest in keeping it running. Proof of stake systems are in their
infancy both in terms of deployment and theory. However, they
provide an interesting middle ground between the costs of a pure
proof of work approach and the challenges with selecting a set of
trusted parties a priori to maintain the bulletin board.

Theorem 6.1. Assume that F is one-way, the signature scheme is
existentially unforgeable under chosen message attacks, the authentication scheme satisfies standard notion of unforgeability, the encryption scheme is perfectly correct, authenticated encryption scheme that
is perfectly correct and satisfies standard notions of INT-CTXT and
semantic security, decisional Diffie-Hellman assumption holds in the
algebraic group adopted. Then, the above protocol satisfies Definition
3.1 in the (Gatt , F ′ )-hybrid model.
The proof can be found in Appendix A.2.

7

INSTANTIATING THE BULLETIN BOARD

Our proposed paradigm relies on a verifiable public bulletin board
that makes three guarantees about entries posted to it:
– The entry’s presence can be cryptographically verified using
a public operation.
– Once posted, the entry is available to all parties.
– Entries are assigned a unique monotonically increasing sequence number.
We now consider several existing techniques that we can leverage
to obtain such a bulletin board.

8

IMPLEMENTATION

In this section we present an implementation of the protocol given
in Section 6, and show that the protocol is efficient. Our implementation consists of three major pieces: the bulletin board instantiated
using Bitcoin, the MPC protocol instantiated using the SPDZ framework [3, 29], and a “witness decryptor” instantiated using an Intel
SGX secure enclave. We describe each component in more detail
below.

Certificate Transparency Logs. Certificate Transparency (CT) [1]
is a public audit log operated by a coalition of browser vendors and
certificate authorities. CT allows individual certificate authorities

7 See https://crt.sh/?id=15707024

728

Session C5: Using Blockchains

CCS’17, October 30-November 3, 2017, Dallas, TX, USA

progfair [∆t, P0 , P1 , vkBB , i] where i ∈ {0, 1} //for party Pi
On input (“keyex”):
Let a ← Zp , and return дa
On input (“init”, k, t, ρ, r ):
let ki B k, ti B t, ρ i B ρ i
comi B Com(ki ; r ), return comi
On input (“send”, дb ):
$

a

let sk = дb , cti ← AE.Encsk (ki , ti , ρ i , comi )
return cti
′ ):
On input (“receive”, ct1−i
assert “init” and “send” have been called.


′
(k 1−i , t 1−i , ρ 1−i , com1−i ) B AE.Decsk ct1−i
return com1−i

On input (“getParams”, v):
assert “init”, “send” and “receive” have been called
T B max{t 0 , t 1 }, y B f (ρ 0 ⊕ ρ 1 ), K B k 0 ⊕ k 1
if v ,⊥, return v, else return (T , y)
On input (“output”, ctMPC , t, ρ, σ , v):
if v ,⊥, return v
assert “getParams” has been called
assert t ∈ {T ,T + 1, · · · ,T + ∆t }
assert f (ρ) = y
assert VerBB (t, ρ, σ )
return AE.DecK (ctMPC )

Protfair [F , ∆t, P 0 , P 1 , vkBB , i] where i ∈ {0, 1} //for party Pi , P j = P1−i
Input: x i
Protocol:
(1) let eidi ← Gatt .install(progfair [∆t, P0 , P1 , vkBB , i]).



(2) Initiate the key exchange procedure. Let (дa , σi ) ← Gatt .resume(eidi , “keyex”). Send (eidi , дa , σi ) to P j , await eidj , дb , σ j from P j .
Check if Vermpk ((eidj , progfair [∆t, P0 , P1 , vkBB , j], дb ), σ j ) = 1, else abort.

(3) ki ← {0, 1} λ , ρ i ← {0, 1} λ , r i ← {0, 1} λ , ti ← BB(getCurrentCounter).
(4) Initialize the enclave with the values obtained in the previous step. (comi , _) B Gatt .resume(eidi , “init”, ρ i , ki , ti , r i ).
(5) Set up the exchange of information between enclaves. Let (cti , _) ← Gatt .resume(eidi , “send”). Send cti to P j and wait for ctj in
response. On receiving ctj , send it to the enclave (com1−i , _) ← Gatt .resume(eidi , “receive”, ctj ). At this point, both commitments are
available to the party.
(6) Get parameters for the MPC computation, (T , y) ← Gatt .resume(eidi , “getParams”, ⊥)
(7) Send (x i , ki , com0 , com1 , r i ) to F ′ and receive ctMPC . Abort if ⊥ is received. // ctMPC of the form AE.EncK (F (x 0 , x 1 ))
(8) Send token share ρ i to P j and wait for token share ρ j .
– If ρ j not received, or f (ρ 0 ⊕ ρ 1 ) , y, then wait to see if P j posts the right value on the bulletin board, when the counter is between
T and T + ∆t. If the counter goes beyond T + ∆t, and no such value posted, abort. If the right value is posted at counter t BB ,
(σBB , ρ) ← BB(getContent, t BB ).
– ρ j received and f (ρ 0 ⊕ ρ 1 ) = y. Wait for the counter value to get to T , and then post ρ 0 ⊕ ρ 1 on the bulletin board to get the
corresponding authentication tag, i.e. (σBB , t BB ) ← BB(post, ρ 0 ⊕ ρ 1 ).
– Output Gatt .resume(eidi , “output”, t BB , ρ 0 ⊕ ρ 1 , σBB , ⊥).
$

$

$

Figure 2: Two party fair protocol Protfair in the (Gatt , F ′ )-hybrid model.
Initialization Decrypt
mean 1.180 ± 0.112 0.039 ± 0.001
mean 0.002 ± 0.000 0.037 ± 0.001
Table 1: Performance of SGX enclave setup and decryption (not MPC). Average and standard deviation of 500 runs.

Bitcoin as a bulletin board. For our prototype implementation
we use the Bitcoin network, which supports a limited scripting
system called Bitcoin Script. In Bitcoin each transaction contains
a script that is evaluated to ensure the transaction is authorized.
This scripting system supports an instruction named OP_RETURN,
which allows the sender of a transaction to embed up to 40 bytes of
arbitrary data into a transaction that is transmitted for inclusion in
the Bitcoin blockchain. Each block of transactions in the blockchain
contains a computational proof of work (PoW) that is computed

by the network. This proof is bound cryptographically to all of the
transactions within a block, as well as to the hash of the previous
block. At current network difficulty, computing a proof of work for
a single block requires an expected 264 invocations of the SHA2
hash function on the standard Bitcoin network. To verify publication on the bulletin board, our implementation requires a fragment
consisting of six consecutive blocks (where the transaction is located in the first block of the fragment). The cost of forging such a
fragment scales linearly in the number of blocks required.

729

Session C5: Using Blockchains

CCS’17, October 30-November 3, 2017, Dallas, TX, USA

We note that the use of a computational proof of work bulletin board provides somewhat different fairness properties than a
signature-based bulletin board, e.g., Certificate Transparency or a
proof-of-stake blockchain. Specifically, in this setting an attacker
with sufficient time or computational power can always “forge” a
satisfying chain of blocks, and use this private result as a witness
to enable decryption. Such an attack would be economically costly,
since the corresponding effort – if applied to crypto-currency mining – would be worth a substantial sum of money.8 However, we can
further restrict this attacker by employing a trusted clock within
the witness decryptor (e.g., Intel SGX) 9 . This optimization requires
the attacker to complete the forgery within a pre-defined time limit
that approximates the expected time for the full Bitcoin network.
Thus a successful attacker must possess most of the available hashpower of the Bitcoin network (which currently approximates the
electrical consumption of Turkmenistan).
For our experiments, we use the public Bitcoin testnet. The
Bitcoin testnet functions similarly to the main Bitcoin network, but
uses a zero-value currency and a low difficulty setting for the proof
of work. We selected testnet for our experiments mainly because
blocks are mined extremely rapidly and transactions require no
monetary expenditure for “transaction fees”. However our code can
use the production Bitcoin blockchain without any code changes.

The randomness of the commitment scheme is used as the key to
the cipher, with the commitment message as the plaintext.
We construct an MPC circuit for SPDZ-2 that takes in a private
input x i , a keyshare ki , a randomness share r i , and commitment to
the master key com(msk; r ). The first circuit computes the output
of the desired MPC functionality f (x 1 , . . . , x N ). Next it computes
r = ⊕1≤i ≤N r i and opens the commitment. It compares ⊕1≤i ≤N ki
with the msk from the commitment. If they do not match, sets
f (x 1 , . . . , x N ) = 0. Finally, the circuit computes the encryption of
f (x 1 , . . . , x N ) using msk and outputs the final ciphertext.
SGX as Witness Decryptor. Intel’s SGX is a set of extensions to
the x86 instruction set that allows for code to be executed in a
protected enclave. SGX programs are segmented into two pieces:
an untrusted application and a trusted enclave. The application
consists of standard software running on a standard operating
system and we assume that it may behave maliciously if the i t h
player is corrupted. Code within an enclave is verified upon startup
and isolated from inspection and tampering, even from an adversary
that controls the system’s operating system. The root of trust of
an SGX enclave is the Intel processor, which enforces the enclave’s
isolation. It is worth noting that the code run within an enclave is
not private; however secrets may be generated or retrieved after
the enclave is initialized. Note that the enclave has no direct access
to network communications, and must rely on the untrusted part
of the application.11
We adapt an existing SGX-bitcoin client called Obscuro [4] to
perform the role of the Witness Decryptor. This enclave is instantiated by each of the N parties participating in the protocol. A single
master instance of the enclave uses the sgx_read_rand function,
supplied by the SGX environment, to generate an AES master key
msk that will eventually encrypt the output of the MPC circuit.
Additionally, the master enclave generates a random 320-bit release token t that must be verifiably posted to a bulletin board
before the ciphertext can be decrypted. Next, the master applies a
secret sharing scheme to derive secret shares (k 1 , . . . , k N ) of msk
and (t 1 , . . . , t N ) of t. Finally, the master computes a commitment
com(msk; r ) and secret shares the randomness into r 1 . . . r N . Now
for i = 1 to N it distributes the tuple (ki , ti , msk, t, com(msk; r ), r i )
to the i t h enclave via a secure channel.12
Once all secrets have been distributed by the master enclave, the
channels are closed and each enclave outputs its key share ki to
the application. The users now invokes SPDZ to conduct the MPC
protocol, using as its private inputs x i , ki , r i , and com(msk; r ). If the
MPC protocol does not complete successfully, the application aborts
and a full restart is required. Otherwise, the application obtains a
ciphertext C output by the MPC protocol and provides this as input
to the enclave. The enclave attempts to decrypt the ciphertext under
msk and if and only if this decryption check completes successfully
(and the result is the proper format and length), it releases ti , which
the application then transmits to all of the remaining parties.
To access the encrypted output of the MPC, at least one party
must re-compute the release token as t = (t 1 ⊕ · · · ⊕ t N ) and post

MPC Protocol. Our protocol can be used to extend any MPC
scheme that supports efficient symmetric encryption. We note that
one could employ Intel SGX directly to perform a naive form of
MPC. However, our goal in this work is to demonstrate that our
approach works efficiently even when instantiated with a “cryptographic” MPC protocol.10
Thus for our implementation we use the SPDZ-2 framework
developed by the University of Bristol [3]. SPDZ-2 is designed to
tolerate dishonest majorities during computation. In SPDZ circuits
are designed in python and then compiled down into a circuit structure. The computation is done in two phases: an offline phase that
does not require the computation inputs and an online phase that
performs the actual computation. In order to optimize the running
time of the online phase, the pre-computation and compilation
phases are relatively more time consuming.
The maintainers of SPDZ-2 have implemented the AES-128 cipher in order to benchmark its efficiency. We repurpose this code
to build a simple authenticated encryption system for that uses 3
rounds of AES to encrypt and authenticate one 128-bit block of
data output from the computation. The encryption scheme takes
as input each party’s private computation input x i and keyshare
ki . It computes as output a ciphertext C encrypted under msk. We
also use this AES-128 cipher to implement a commitment scheme.

8 At present rates as of July 2017, this opportunity cost is approximately $28,000 per

block forged.
9 Correctly accessing trusted time from within an enclave is part of the Intel SGX
specification, but it is not yet supported as it relies on platform services which are not
active. In our implementation, we include code to properly access trusted time, but do
not include it in our measurements because of the lack of support.
10 Additionally, we remark that if SGX is used to implement the MPC protocol itself,
a security breach of the SGX system will result in the loss of all security properties
provided by the MPC. On the other hand, if we employ a cryptographic MPC protocol,
then a failure of Intel’s SGX risks only the fairness property. We view this as a benefit
of our approach.

11 This enables the application to censor or tamper with communications between the

application and the network.
12 SGX supports the creation of authenticated, secure channels using attestation and

DHKE.

730

Session C5: Using Blockchains

CCS’17, October 30-November 3, 2017, Dallas, TX, USA

this value to the Bitcoin network inside of a transaction. Each user’s
application monitors the Bitcoin network using RPC calls to a local
Bitcoin client bitcoincli which is running on the user’s machine.
This userland code then feeds the resulting blockchain fragment
(which consists of six consecutive blocks) back to the enclave, which
confirms that the release token matches its stored value t, and also
verifies the proofs of work on each block. While an adversarial user
can block this response, they are unable to falsify or tamper with it
due to the fact that such tampering would require an impractical
amount of computation. The application also supplies the enclave
with the output of the MPC C.
If all verifications succeed, the enclave decrypts the ciphertext C
using an authenticated encryption scheme under msk, and outputs
the resulting plaintext.
Optimizations. In a bid to optimize the implementation, there are
a few differences from the described protocol in section 6. They do
not make a difference to the security of the protocol, and are briefly
described here:
– Instead of each party generating its key and token shares,
a designated master enclave chooses them and distributes
them to the other enclaves.
– Instead of a commitment for each share of the key, there is
only a single “master commitment” of the key.

Figure 4: Mean runtimes for our AES circuit varied over the
number of players participating. Only the online portion of
the MPC is shown. This circuit is dominated by 3 AES operations.

particularly important when the output of the MPC is extremely
valuable. While adding three rounds of AES to a simple MPC scheme
represents a high cost, it adds a only a negligible cost when considering more time consuming computations. In Figure 3 we show the
average runtime over 50 trials of a number of different circuits in
SPDZ-2. The cost of encryption is clearly dwarfed by large search
problems and set intersection.
While we ran the MPC experiments with N=2 players, SPDZ-2
allows computations with more players. In Figure 4 we consider only
the cost of running the encryption component of the MPC protocol
with higher numbers of players. Because each player contributes
a key share, the cost of running the protocol increases with each
player. While the runtime of the encryption operation does increase,
we note that it is still adds only a fraction of one second of online
computation time up to N = 6.

Sample computation and performance. For proof of concept,
we implemented a search program that takes as input a search value
x from one party and a list (y1 , . . . , yn ), from the other party. These
circuitsÉ
each calculate an integer output M and encrypt the result
as Enc( n1 ki ; M). Since these are two-party functions we tested
with N = 2 and n = (100, 500, 1000).

SGX Runtime. Intel SGX offers an extremely efficient method
of trusted program execution. We benchmark our SGX Enclave
over 500 trials of the two party protocol for some fixed parameters. We run our test on an Intel i5-6600K 3.5GHz processor with
16 GB of RAM running Ubuntu 14.04 and SGXSDK-1.7, running
both the master and minion on the same hardware. For the purpose of benchmarking, we hardcode into the master enclave the
master AES key and fix the release token to be the results of an
OP_RETURN instruction in a known block of the Bitcoin Testnet.
Additionally, we run the MPC protocol once to generate a valid
ciphertext. With the pre-fixed values, we can effectively check the
running time of the various parts of the enclave’s execution. All
key exchange and interaction with the bitcoincli is still run as in
the real protocol. In Table 1 we show the average running times of
the various segments of the enclave, both for the master instance
and minion instance. For the minion’s execution time, we pause the
timer while it is waiting for the minion to open a network connection. It is clear that the slowest piece of the program is the enclave

Figure 3: Mean runtimes for a linear search on n items using
SPDZ taken over 50 iterations. Only the online portion of
the MPC is shown. In blue, we show the cost of running the
search without any provision for fairness. In red, the overhead from AES encryption needed for fairness.
Cost of fairness in the MPC. Our implementation demonstrates
that our approach can be used add fairness to MPC schemes efficiently using current technology. We recall that fairness in MPC is

731

Session C5: Using Blockchains

CCS’17, October 30-November 3, 2017, Dallas, TX, USA

initialization. This is because the enclave must provision all memory that it may require from the SGX driver during initialization.
Our implementation allocates more memory than it will use to be
conservative.

9

[26] Jean-Sébastien Coron, Tancrède Lepoint, and Mehdi Tibouchi. 2013. Practical
Multilinear Maps over the Integers. In CRYPTO. 476–493.
[27] Jean-Sébastien Coron, Tancrède Lepoint, and Mehdi Tibouchi. 2015. New Multilinear Maps Over the Integers. In CRYPTO. 267–286.
[28] Ronald Cramer and Victor Shoup. 1998. A Practical Public Key Cryptosystem
Provably Secure Against Adaptive Chosen Ciphertext Attack. In Advances in
Cryptology - CRYPTO ’98, 18th Annual International Cryptology Conference, Santa
Barbara, California, USA, August 23-27, 1998, Proceedings. 13–25.
[29] Ivan Damgard, Marcel Keller, Enrique Larraia, Valerio Pastro, Peter Scholl, and
Nigel P. Smart. 2012. Practical Covertly Secure MPC for Dishonest Majority – or:
Breaking the SPDZ Limits. Cryptology ePrint Archive, Report 2012/642. (2012).
http://eprint.iacr.org/2012/642.
[30] Yevgeniy Dodis, Pil Joong Lee, and Dae Hyun Yum. 2007. Optimistic Fair Exchange in a Multi-user Setting. In Public Key Cryptography - PKC 2007, 10th
International Conference on Practice and Theory in Public-Key Cryptography, Beijing, China, April 16-20, 2007, Proceedings. 118–133.
[31] Shimon Even, Oded Goldreich, and Abraham Lempel. 1985. A Randomized
Protocol for Signing Contracts. Commun. ACM 28, 6 (1985), 637–647.
[32] Juan A. Garay and Markus Jakobsson. 2002. Timed Release of Standard Digital
Signatures. In Financial Cryptography. 168–182.
[33] Juan A. Garay, Markus Jakobsson, and Philip D. MacKenzie. 1999. Abuse-Free
Optimistic Contract Signing. In CRYPTO. 449–466.
[34] Juan A. Garay, Philip D. MacKenzie, Manoj Prabhakaran, and Ke Yang. 2006.
Resource Fairness and Composability of Cryptographic Protocols. In TCC. 404–
428.
[35] Juan A. Garay and Carl Pomerance. 2003. Timed Fair Exchange of Standard
Signatures: [Extended Abstract]. In Financial Cryptography, 7th International
Conference, FC 2003, Guadeloupe, French West Indies, January 27-30, 2003, Revised
Papers. 190–207.
[36] Sanjam Garg, Craig Gentry, and Shai Halevi. 2013. Candidate Multilinear Maps
from Ideal Lattices. In EUROCRYPT. 1–17.
[37] Sanjam Garg, Craig Gentry, Amit Sahai, and Brent Waters. 2013. Witness Encryption and its Applications. Cryptology ePrint Archive, Report 2013/258. (2013).
http://eprint.iacr.org/2013/258.
[38] Craig Gentry, Sergey Gorbunov, and Shai Halevi. 2015. Graph-Induced Multilinear
Maps from Lattices. In TCC, Part II. 498–527.
[39] Craig Gentry, Allison B. Lewko, and Brent Waters. 2014. Witness Encryption
from Instance Independent Assumptions. In CRYPTO. 426–443.
[40] Oded Goldreich and Ariel Kahan. 1996. How to Construct Constant-Round
Zero-Knowledge Proof Systems for NP. J. Cryptology 9, 3 (1996), 167–190.
[41] Oded Goldreich, Silvio Micali, and Avi Wigderson. 1987. How to play any mental
game. In STOC.
[42] Shafi Goldwasser and Leonid A. Levin. 1990. Fair Computation of General
Functions in Presence of Immoral Majority. In CRYPTO. 77–93.
[43] Shafi Goldwasser and Rafail Ostrovsky. 1992. Invariant Signatures and NonInteractive Zero-Knowledge Proofs are Equivalent (Extended Abstract). In
CRYPTO. 228–245.
[44] S. Dov Gordon. 2010. On Fairness in Secure Computation. Ph.D. Dissertation.
(2010). https://www.cs.umd.edu/~jkatz/THESES/gordon.pdf.
[45] S. Dov Gordon, Carmit Hazay, Jonathan Katz, and Yehuda Lindell. 2008. Complete
fairness in secure two-party computation. In STOC. 413–422.
[46] S. Dov Gordon, Yuval Ishai, Tal Moran, Rafail Ostrovsky, and Amit Sahai. 2010.
On Complete Primitives for Fairness. In TCC. 91–108.
[47] S. Dov Gordon and Jonathan Katz. 2009. Complete Fairness in Multi-party
Computation without an Honest Majority. In Theory of Cryptography, 6th Theory
of Cryptography Conference, TCC 2009, San Francisco, CA, USA, March 15-17, 2009.
Proceedings. 19–35.
[48] S. Dov Gordon and Jonathan Katz. 2010. Partial Fairness in Secure Two-Party
Computation. In EUROCRYPT. 157–176.
[49] Aggelos Kiayias, Alexander Russell, Bernardo David, and Roman Oliynykov. 2017.
Ouroboros: A Provably Secure Proof-of-Stake Blockchain Protocol. In CRYPTO
’17.
[50] Dafna Kidron and Yehuda Lindell. 2011. Impossibility Results for Universal
Composability in Public-Key Models and with Fixed Inputs. J. Cryptology 24, 3
(2011), 517–544. https://doi.org/10.1007/s00145-010-9069-7
[51] Handan Kilinç and Alptekin Küpçü. 2016. Efficiently Making Secure Two-Party
Computation Fair. In Financial Cryptography and Data Security - 20th International
Conference, FC 2016, Christ Church, Barbados, February 22-26, 2016, Revised Selected
Papers. 188–207. https://doi.org/10.1007/978-3-662-54970-4_11
[52] Ranjit Kumaresan and Iddo Bentov. 2016. Amortizing Secure Computation with
Penalties. In ACM CCS. 418–429.
[53] Ranjit Kumaresan, Tal Moran, and Iddo Bentov. 2015. How to Use Bitcoin to Play
Decentralized Poker. In ACM CCS. 195–206.
[54] Alptekin Küpçü and Anna Lysyanskaya. 2010. Usable Optimistic Fair Exchange.
In CT-RSA. 252–267.
[55] Yehuda Lindell. 2009. Legally Enforceable Fairness in Secure Two-Party Communication. Chicago J. Theor. Comput. Sci. 2009 (2009).

ACKNOWLEDGMENTS

This research was supported in part by the National Science Foundation under awards CNS-1010928, CNS-1228443, CNS-1653110,
CNS-1414023 and EFMA-1441209; The Office of Naval Research
under contract N00014-14-1-0333; DARPA/ARL Safeware Grant
W911NF-15-C-0213; and the Mozilla Foundation.

REFERENCES
[1] 2017. Certificate Transparency. Available at https://www.certificate-transparency.
org/. (2017).
[2] 2017. Let’s Encrypt. Available at https://letsencrypt.org/. (2017).
[3] 2017. Multiparty computation with SPDZ online phase and MASCOT offline
phase. Github. (2017). https://github.com/bristolcrypto/SPDZ-2.
[4] 2017. Obscuro. Github. (2017). https://github.com/BitObscuro/Obscuro.
[5] Bar Alon and Eran Omri. 2016. Almost-Optimally Fair Multiparty Coin-Tossing
with Nearly Three-Quarters Malicious. In TCC, Part I. 307–335.
[6] Marcin Andrychowicz, Stefan Dziembowski, Daniel Malinowski, and Lukasz
Mazurek. 2014. Secure Multiparty Computations on Bitcoin. In IEEE Symposium
on Security and Privacy. 443–458.
[7] Gilad Asharov. 2014. Towards Characterizing Complete Fairness in Secure TwoParty Computation. In TCC. 291–316.
[8] Gilad Asharov, Amos Beimel, Nikolaos Makriyannis, and Eran Omri. 2015. Complete Characterization of Fairness in Secure Two-Party Computation of Boolean
Functions. In TCC, Part I. 199–228.
[9] Gilad Asharov, Yehuda Lindell, and Tal Rabin. 2013. A Full Characterization of
Functions that Imply Fair Coin Tossing and Ramifications to Fairness. In TCC.
243–262.
[10] Gilad Asharov, Yehuda Lindell, and Hila Zarosim. 2013. Fair and Efficient Secure
Multiparty Computation with Reputation Systems. In ASIACRYPT. 201–220.
[11] N. Asokan, Matthias Schunter, and Michael Waidner. 1997. Optimistic Protocols
for Fair Exchange. In CCS ’97, Proceedings of the 4th ACM Conference on Computer
and Communications Security, Zurich, Switzerland, April 1-4, 1997. 7–17.
[12] N. Asokan, Victor Shoup, and Michael Waidner. 1998. Optimistic Fair Exchange
of Digital Signatures (Extended Abstract). In EUROCRYPT. 591–606.
[13] Donald Beaver and Shafi Goldwasser. 1989. Multiparty Computation with Faulty
Majority. In CRYPTO. 589–590.
[14] Amos Beimel, Yehuda Lindell, Eran Omri, and Ilan Orlov. 2011. 1/p-Secure
Multiparty Computation without Honest Majority and the Best of Both Worlds.
In CRYPTO. 277–296.
[15] Michael Ben-Or, Oded Goldreich, Silvio Micali, and Ronald L. Rivest. 1985. A
Fair Protocol for Signing Contracts (Extended Abstract). In ICALP. 43–52.
[16] Iddo Bentov, Ariel Gabizon, and Alex Mizrahi. 2016. Cryptocurrencies without
proof of work. In International Conference on Financial Cryptography and Data
Security. Springer, 142–157.
[17] Iddo Bentov and Ranjit Kumaresan. 2014. How to Use Bitcoin to Design Fair
Protocols. In CRYPTO. 421–439.
[18] Dan Boneh and Moni Naor. 2000. Timed Commitments. In CRYPTO. 236–254.
[19] Elette Boyle, Kai-Min Chung, and Rafael Pass. 2014. On Extractability Obfuscation.
In TCC. 52–73.
[20] Christian Cachin and Jan Camenisch. 2000. Optimistic Fair Secure Computation.
In CRYPTO. 93–111.
[21] Ran Canetti, Yevgeniy Dodis, Rafael Pass, and Shabsi Walfish. 2007. Universally
Composable Security with Global Setup. In Theory of Cryptography, 4th Theory
of Cryptography Conference, TCC 2007, Amsterdam, The Netherlands, February
21-24, 2007, Proceedings. 61–85.
[22] Ran Canetti, Abhishek Jain, and Alessandra Scafuro. 2014. Practical UC security
with a Global Random Oracle. In Proceedings of the 2014 ACM SIGSAC Conference
on Computer and Communications Security, Scottsdale, AZ, USA, November 3-7,
2014. 597–608.
[23] Ran Canetti, Yehuda Lindell, Rafail Ostrovsky, and Amit Sahai. 2002. Universally
composable two-party and multi-party secure computation. In Proceedings on
34th Annual ACM Symposium on Theory of Computing, May 19-21, 2002, Montréal,
Québec, Canada. 494–503.
[24] Liqun Chen, Caroline Kudla, and Kenneth G. Paterson. 2004. Concurrent Signatures. In EUROCRYPT. 287–305.
[25] Richard Cleve. 1986. Limits on the Security of Coin Flips when Half the Processors
Are Faulty (Extended Abstract). In STOC. 364–369.

732

Session C5: Using Blockchains

CCS’17, October 30-November 3, 2017, Dallas, TX, USA

A.2

[56] Anna Lysyanskaya. 2002. Unique Signatures and Verifiable Random Functions
from the DH-DDH Separation. In CRYPTO. 597–612.
[57] Silvio Micali. 2003. Simple and fast optimistic protocols for fair electronic exchange. In PODC. 12–19.
[58] Rafael Pass, Elaine Shi, and Florian Tramèr. 2016. Formal Abstractions for Attested
Execution Secure Processors. IACR Cryptology ePrint Archive 2016 (2016), 1027.
http://eprint.iacr.org/2016/1027
[59] Rafael Pass, Elaine Shi, and Florian Tramèr. 2017. Formal Abstractions for Attested
Execution Secure Processors. In EUROCRYPT. 260–289.
[60] Benny Pinkas. 2003. Fair Secure Two-Party Computation. In EUROCRYPT. 87–
105.
[61] Tal Rabin and Michael Ben-Or. 1989. Verifiable Secret Sharing and Multiparty
Protocols with Honest Majority (Extended Abstract). In STOC. 73–85.
[62] Andrew Chi-Chih Yao. 1982. Protocols for Secure Computations (Extended
Abstract). In FOCS. 160–164.

Proof of Theorem 6.1

We consider the two party setting where P 1 is corrupted. The other
case is symmetric. The simulator S works as follows:
(1) Unless otherwise mentioned, S passes through messages
between adversary A(P 1 ) and Gatt .
(2) S loads the program to get the corresponding eid0 , i.e. eid0 ←
Gatt .install(progfair [∆t, P0 , P1 , vkBB , 0]).
(3) Next, S initiates the key exchange phase (дa , σ0 ) ← Gatt .
a
resume(eid0 , “keyex”)
 and sends
 (eid0 , д , σ0 ) message to A.
(4) S waits to receive eid1 , дb , σ1 from A.
The simulator
sees messages between A and Gatt , and can


A PROOFS
A.1 Proof of Claim 2

see if eid1 , дb , σ1 sent by A is different from the corresponding tuple it received from Gatt . If the tuples differ and
the signature verifies, output ⊥ Gatt and exit.

The analysis for the proof below is taken from [40, 44].

(5) Pick k 0 ← {0, 1} λ , ρ 0 ← {0, 1} λ , r 0 ← {0, 1} λ , t 0 ←
BB(getCurrentCounter) and initialize Gatt with these values, (com0 , _)Gatt .resume(eid0 , “init”, ρ 0 , k 0 , t 0 , r 0 ). Simulator sees the values (ρ 1 , k 1 , t 1 , r 1 ) that A sends to Gatt .
(6) S calls (ct1 , _) ← Gatt .resume(eid0 , “send”), sends ct1 to A
and waits for ct0 .
As before, the simulator observes if ct0 sent by A is different
from the value it received from Gatt . If so, and Gatt doesn’t
throw an exception, output ⊥AE1 and exit.
(7) Make a call to Gatt to get the parameters, (T , y, _) ← Gatt .
resume(eid0 , “getParams”, ⊥).
(8) Wait for A to send (x 1 , k 1′ , com0′ , com1′ , r 1′ ) intended for F ′ .
If the commitment values are not the same as the ones
received earlier, send abort to the ideal functionality and
send ⊥ to the adversary. If k 1′ , k 1 , i.e. the key shares sent
at different points differ, and if com1′ = Com(k 1′ ; r 1′ ) output ⊥com and exit. Else, pick K ′ randomly and compute
ctMPC ← AE.EncK ′ (F (0, x 1 )) to send to A.
(9) S obtains its token share from Gatt , (ρ 0 , _) ← Gatt .resume
(eid0 , “getTokenShare”, ⊥).
(10) If A aborts immediately after receiving the output from F ′
without the honest party getting it, send abort to the ideal
functionality. But continue running S. If the adversary sends
to the bulletin board or enclave the correct pre-image of y,
S outputs ⊥f and exits.
(11) If A has not aborted, send ρ 0 to A. If the adversary does not
send ρ 1 , or post a valid pre-image during the interval T to T +
∆T , but queries Gatt for the output on a valid authentication
tag, then we output ⊥BB and exit.
(12) Alternatively, we split the behavior of the simulator three
cases:
– If A responds with a valid ρ 1 (i.e. f (ρ 0 ⊕ ρ 1 ) = y), then
post to the bulletin board. Recollect that S has reached
this point only if the key shares sent by A were consistent. Send x 1 to the ideal functionality to receive out. If A
makes the correct query to the enclave, i.e. the ciphertext
sent is the same as the one from the MPC, S programs the
output by returning Gatt .resume(eid1 , “output”, t BB , σBB , out).
If the ciphertext is different and authenticates under key
K ′ , then output ⊥AE2 and exit.
$

Proof. The simulator S outputs fail only if it has reached step 7
and then fails in producing an accepting transcript. S fails to reach
step 7 with probability q.
We denote by p, the probability that the adversary does not aborts
when given the witness encryption of the correct functionality,
i.e., p is the probability when the adversary is given the witness
encryption of F (x 1 , · · · , x n ). Recollect that q is the probability of
the adversary not aborting when given the witness encryption of
F (b
x 1 , · · · , xbn ) where ∀a, xba = x a and ∀h, xbh = 0. From the security
of witness encryption, we require |q −p| is negligible in the security.
(probability is taken over the random coins used to generate the
′ .)
output of F∆t

Õ  1
Pr[S outputs fail] = q
Pr
= i (1 − p)t ·i
qe
i




t
q
q
1
1
≤ qPr
≥
(1 − p) qe + qPr
<
qe 2
qe 2
t

≤ q(1 − p) 2q + negl(λ)

(1)

To show that the above equation is negligible in λ, we split the
analysis into two cases:
q

– Case 1: p ≥ 2 . Substituting, we get

t
t
q  2qt
(1 − p) 2q ≤ 1 −
< e− 4
2
which is negligible is λ since t is polynomial in λ.
q
– Case 1: p < 2 . To the contrary, let us assume Equation 1 is
non-negligible. Then, there is a polynomial poly and infinitely many values λ such that
t

q ≥ q(1 − p) 2q + negl(λ) >

1
.
poly(λ)

Thus q > poly1′ (λ) for some polynomial poly ′ . This gives us
|q − p| >

q
1
>
.
2
2poly ′ (λ)

This breaks the security of the witness encryption scheme.
Thus S outputs fail with only negligible probability.



733

$

$

Session C5: Using Blockchains

CCS’17, October 30-November 3, 2017, Dallas, TX, USA

– If the adversary does not send ρ 1 but posts a pre-image
of y during the interval T to T + ∆T , S follows the same
approach as the previous step.
– If A attempts to use the backdoor, forward the message
to Gatt without modification.

– ⊥com is output with only negligible probability. Else, we
can leverage the adversary to break the statistical binding
property of the commitment scheme.
– ⊥f is output with only negligible probability. Else we can
break the security of the one way function. This follows
from the fact that the simulator is see the queries that the
adversary makes to the enclave and the bulletin board. Since
we want to force the challenge value y ∗ onto the adversary,
we use a backdoor in the function. This backdoor does not
give the adversary any undue advantage as the value is not
sent across to the other party.
– ⊥BB is output with negligible probability. Else, we can leverage the adversary to break the unforgeability of the authentication scheme for the bulletin board. This is because the
adversary was able to produce a signature that has not been
queried for before.

We prove indistinguishability of the real and ideal worlds through
a sequence of hybrids.
Hyb0 : Identical to the real execution.
Hyb1 : Identical to Hyb0 except that we introduce the following
check.
Observe

 the messages between A and Gatt , and can see if
b
eid1 , д , σ1 sent by A is different from the corresponding tuple
it received from Gatt . If the tuples differ and the signature verifies,
output ⊥ Gatt and exit.
Claim 4. Assuming that the underlying signature scheme is secure,
Hyb1 is computationally indistinguishable from Hyb0 .



Proof. Hyb1 exits with output ⊥ Gatt with only negligible probability. If not, we can use A to construct an adversary that breaks
the signature scheme.


Hyb4 : Identical to Hyb3 except that we intercept the ciphertext
query for the output, and program the output using the trapdoor
to be AE.DecK (ct) if the other conditions are satisfied. Here K is
the key in the enclave.

Hyb2 : Identical to Hyb1 except that we replace all occurrences
of sk = дab with a random key.

Claim 7. Hyb4 is statistically indistinguishable from Hyb3 .

Claim 5. Assuming that DDH holds, Hyb2 is computationally
indistinguishable from Hyb1 .


Proof. This follows from the fact that it was only a statistical
change. This is because we moved the exact check to the outside of
the enclave.


Hyb3 : Identical to Hyb2 except that we add the following additional checks:

Hyb5 : Identical to Hyb4 except that replace com2 to be a commitment of a random value.

– observe if ct0 sent by A is different from the value it received
from Gatt . If so, and Gatt doesn’t throw an exception, output
⊥AE1 and exit.
′ and
– if A sends a different key share k 1′ intended for F∆t
′
′
′
com 1 = Com(k 1 ; r 1 ), output ⊥com and exit.
– if A aborts immediately after receiving the output from F ′
(without the honest party getting it), send abort to the ideal
functionality. Additionally, wait to see if the adversary sends
to the bulletin board or enclave the correct pre-image of y.
If so, outputs ⊥f and exit.
– if the adversary does not send ρ 1 and does not post a valid
pre-image during the interval T to T + ∆T but queries Gatt
on a valid authentication tag, output ⊥BB and exit.

Claim 8. If the commitment scheme is computationally hiding,
Hyb5 is computationally indistinguishable from Hyb4 .

Proof. Follows directly from DDH security.

Proof. If the two hybrids are distinguishable, we can leverage
the adversary to break the computational hiding of the commitment
scheme.

Hyb5 : Identical to Hyb4 except that we pick K ′ randomly and
use K ′ to encrypt the output. Now, the output is programmed in
the last round with respect to the key K ′ .
Claim 9. If the semantic security of the AE scheme holds, Hyb5 is
computationally indistinguishable from Hyb4 .

Claim 6. Assuming the security of one-way permutation, statistical binding of the commitment scheme INT-CTXT security of AE and
unforgeability of the authentication scheme Hyb3 is computationally
indistinguishable from Hyb2 .

Proof. If the two hybrids are distinguishable, then we can build
an adversary that breaks the semantic security of the AE scheme.


Proof. The only changes are in the checks performed. We argue
that Hyb3 will output a special abort with only negligible probability:

Hyb6 : Identical to Hyb5 except that we add the following additional checks. If the ciphertext differs from the MPC output and it
authenticates under key K ′ , then output ⊥AE2 and exit.

– ⊥AE1 is output with only negligible probability. Else, we can
leverage the adversary to break the INT-CTXT security of
the AE scheme.

Claim 10. If INT-CTXT security of the AE scheme holds, Hyb6 is
computationally indistinguishable from Hyb5 .

734

Session C5: Using Blockchains

CCS’17, October 30-November 3, 2017, Dallas, TX, USA

Proof. If the two hybrids are distinguishable, then we can build
an adversary that breaks the semantic security of the encryption
scheme.


Proof. Since the only changes are additional checks, it is enough
to show that S outputs ⊥AE2 with only negligible probability. This
follows directly from the INT-CTXT security of the AE scheme.
Specifically, we can receive the challenge ciphertext to the be the
encryption of the function value (either under the challenge key,
or a random key). If the adversary is able to produce a verifying
ciphertext different from the one it receives it constitutes a forgery,
thus breaking the INT-CTXT security of the AE scheme.


Hyb9 : Identical to Hyb8 except that we replace all occurrences
of sk with дab again.
Claim 13. Assume DDH is hard, Hyb9 is computationally indistinguishable from Hyb8 .
Proof. Follows directly from DDH security.

Hyb7 : Identical to Hyb6 except that if check did not result in a
failure, send x 1 to the trusted party to obtain out. If the witness
checks succeeds, program the output of the enclave to be out. Else
program output to be ⊥.



Hyb9 is the same as our simulator, and hence we’re done.

B

SGX FUNCTIONALITY

The SGX functionality is presented in Figure 5. Additional notation
from [59] used is described below:
– P is the identifier of party.
– reg refers to the registry of machines with the trusted hardware.
– prog is the program.
– inp, outp refers to the input and output.
– mem is the program’s memory tape.
– Σ is a signature scheme.

Claim 11. Hyb7 is statistically indistinguishable from Hyb6 .
Proof. The change is only statistical since the execution thread
reaches the point only if all prior checks pass.

Hyb8 : Identical to Hyb7 except that we replace the value inside
the ciphertext to be F (0, x 1 ).
Claim 12. If the semantic security of the encryption scheme holds,
Hyb8 is computationally indistinguishable from Hyb7 .

735

Session C5: Using Blockchains

CCS’17, October 30-November 3, 2017, Dallas, TX, USA

Gatt [Σ, reg]
//initialization
On initialize : (mpk, msk) ← Σ.Gen(1λ ), T = ϕ
//public query interface
On receive∗ getpk() from some P : send mpk to P
Enclave operations
//local interface — install an enclave
On receive∗ install(idx, prog) from some P : ∈ reg
if P is honest, assert idx=sid
generate nonce eid ∈ {0, 1} λ , store T [eid, P] B (idx, prog, 0)
//local interface — resume an enclave
On receive∗ resume(eid, inp) from some P : ∈ reg
let (idx, prog, mem) B T [eid, P], abort if not found.
let (outp, mem) B prog(inp, mem), update T [eid, P] B (idx, prog, mem)
let σ ← Σ.Signmsk (idx, eid, prog, outp) and send (outp, σ ) to P.
Figure 5: A global functionality modeling an SGX-like secure processor. Blue (and starred*) activation points denote reentrant
activation points. Green activation points are executed at most once. The enclave program prog may be probabilistic and this is important for
privacy-preserving applications. Enclave program outputs are included in an anonymous attestation σ . For honest parties, the functionality
verifies that installed enclaves are parameterized by the session id sid of the current protocol instance.

736

