Journal of Machine Learning Research 17 (2016) 1-51

Submitted 4/15; Published 4/16

Extremal Mechanisms for Local Differential Privacy
Peter Kairouz

kairouz2@illinois.edu

Department of Electrical and Computer Engineering
University of Illinois at Urbana-Champaign
Urbana, IL 61801, USA

Sewoong Oh

swoh@illinois.edu

Department of Industrial and Enterprise Systems Engineering
University of Illinois at Urbana-Champaign
Urbana, IL 61820, USA

Pramod Viswanath

pramodv@illinois.edu

Department of Electrical and Computer Engineering
University of Illinois at Urbana-Champaign
Urbana, IL 61801, USA

Editor: Mehryar Mohri

Abstract
Local differential privacy has recently surfaced as a strong measure of privacy in contexts
where personal information remains private even from data analysts. Working in a setting
where both the data providers and data analysts want to maximize the utility of statistical
analyses performed on the released data, we study the fundamental trade-off between local
differential privacy and utility. This trade-off is formulated as a constrained optimization
problem: maximize utility subject to local differential privacy constraints. We introduce a
combinatorial family of extremal privatization mechanisms, which we call staircase mechanisms, and show that it contains the optimal privatization mechanisms for a broad class of
information theoretic utilities such as mutual information and f -divergences. We further
prove that for any utility function and any privacy level, solving the privacy-utility maximization problem is equivalent to solving a finite-dimensional linear program, the outcome
of which is the optimal staircase mechanism. However, solving this linear program can be
computationally expensive since it has a number of variables that is exponential in the size
of the alphabet the data lives in. To account for this, we show that two simple privatization
mechanisms, the binary and randomized response mechanisms, are universally optimal in
the low and high privacy regimes, and well approximate the intermediate regime.
Keywords: local differential privacy, privacy-preserving machine learning algorithms,
information theoretic utilities, f -divergences, mutual information, statistical inference, hypothesis testing, estimation

1. Introduction
In statistical analyses involving data from individuals, there is an increasing tension between
the need to share data and the need to protect sensitive information about the individuals.
For example, users of social networking sites are increasingly cautious about their privacy,
but still find it inevitable to agree to share their personal information in order to benefit
c 2016 Peter Kairouz and Sewoong Oh and Pramod Viswanath.

Kairouz, Oh and Viswanath

from customized services such as recommendations and personalized search (Acquisti, 2004;
Acquisti and Grossklags, 2007). There is a certain utility in sharing data for both data
providers and data analysts, but at the same time, individuals want plausible deniability
when it comes to sensitive information.
For such applications, there is a natural core optimization problem to be solved. Assuming both the data providers and analysts want to maximize the utility of the released
data, how can they do so while preserving the privacy of participating individuals? The
formulation and study of a framework that addresses the fundamental tradeoff between
utility and privacy is the focus of this paper.
1.1 Local differential privacy
The need for data privacy appears in two different contexts: the local privacy context, as
in when individuals disclose their personal information (e.g., voluntarily on social network
sites), and the global privacy context, as in when institutions release databases of information
of several people or answer queries on such databases (e.g., US Government releases census
data, companies like Netflix release proprietary data for others to test state of the art
machine learning algorithms). In both contexts, privacy is achieved by randomizing the
data before releasing it. We study the setting of local privacy, in which data providers do
not trust the data collector (analyst). Local privacy dates back to Warner (1965), who
proposed the randomized response method to provide plausible deniability for individuals
responding to sensitive surveys.
A natural notion of privacy protection is making inference of information beyond what
is released hard. Differential privacy has been proposed in the global privacy context to
formally capture this notion of privacy (Dwork, 2006; Dwork et al., 2006b; Dwork and Lei,
2009). In a nutshell, differential privacy ensures that an adversary should not be able to
reliably infer an individualâ€™s record in a database, even with unbounded computational
power and access to every other record in the database. Recently, Duchi et al. (2013)
extended the notion of differential privacy to the local privacy context. Formally, consider
a setting where there are n data providers each owning a data Xi defined on an input
alphabet X . The Xi â€™s are independently sampled from some distribution PÎ½ parameterized
by Î½. A statistical privatization mechanism Q is a conditional distribution that maps Xi âˆˆ X
stochastically to Yi âˆˆ Y, where Y is an output alphabet possibly larger than X . The Yi â€™s
are referred to as the privatized (sanitized) views of Xi â€™s. In a non-interactive setting, the
same privatization mechanism Q is used locally by all individuals. This setting is shown in
Figure 1 for the special case of n = 2. For some non-negative Îµ, we follow the definition of
Duchi et al. (2013) and say that a mechanism Q is Îµ-locally differentially private if
sup
SâŠ‚Y,x,x0 âˆˆX

Q(S|x)
â‰¤ eÎµ ,
Q(S|x0 )

(1)

where Q(S|x) = P(Yi âˆˆ S|Xi = x) represents the privatization mechanism. This ensures
that for small values of Îµ, given a privatized data Yi , it is (almost) equally likely to have
come from any data, i.e. x or x0 . A small value of Îµ means that we require a high level of
privacy and a large value corresponds to a low level of privacy. At one extreme, for Îµ = 0,
the privatized output must be independent of the private data, and on the other extreme,
for Îµ = âˆ, the privatized output can be made equal to the private data.
2

Extremal Mechanisms for Local Differential Privacy

X1 âˆ¼ PÎ½

Privatization
Q

Y1

âˆ¼

M

Î½

Data Analyst

Clients

X2 âˆ¼ PÎ½

Privatization
Q

Y2

âˆ¼

MÎ½

Figure 1: Client i owns Xi sampled from PÎ½ . Each Xi is privatized by the same Îµ-locally
differentially private mechanism Q. The data analyst only observes the privatized
data (Yi â€™s) and makes an inference on the statistics of the original distribution of
the data.

1.2 Information theoretic utilities for statistical analysis
In analyses of statistical databases, the analyst is interested in the statistics of the data as
opposed to individual records. Naturally, the utility should also be measured in terms of the
distribution rather than sample quantities. Concretely, consider a client-server setting where
each client with data Xi releases Yi , a privatized version of the data, via a non-interactive Îµlocally differentially private privatization mechanism Q. Assume all the clients use the same
privatization mechanism Q, and each clientâ€™s data is an i.i.d. sample from a distribution PÎ½
for some parameter Î½. Given the privatized views {Yi }ni=1 , the data analyst would like to
make inferences based on the induced marginal distribution
X

MÎ½ (S) â‰¡

Q(S|x)PÎ½ (x) ,

(2)

xâˆˆX

for S âŠ† Y. We consider a broad class of convex utility functions, and identify the class
of optimal mechanisms, which we call staircase mechanisms, in Section 2. We apply this
framework to two specific applications: (a) hypothesis testing where the utility is measured
in Kullback-Leibler divergence (Section 3) and (b) information preservation where the utility
is measured in mutual information (Section 4).
In the binary hypothesis testing setting, Î½ âˆˆ {0, 1}; therefore, X can be generated by
one of two possible distributions P0 and P1 . The power to discriminate data generated
from P0 to data generated from P1 depends on the â€˜distanceâ€™ between the marginals M0
and M1 . To measure the ability of such statistical discrimination, our choice of utility of a
particular privatization mechanism Q is an information theoretic quantity called CsiszaÌrâ€™s
f -divergence defined as
Df (M0 ||M1 ) =

X  M0 (x) 
f
M1 (x) ,
M1 (x)

xâˆˆX

3

(3)

Kairouz, Oh and Viswanath

for some convex function f such that f (1) = 0. The Kullback-Leibler (KL) divergence
Dkl (M0 ||M1 ) is a special case with f (x) = x log x, and so is the total variation distance
kM0 âˆ’M1 kTV with f (x) = (1/2)|xâˆ’1|. Such f -divergences capture the quality of statistical
inference, such as minimax rates of statistical estimation or error exponents in hypothesis
testing (Tsybakov and Zaiats, 2009; Cover and Thomas, 2012). As a motivating example,
suppose a data analyst wants to test whether the data is generated from P0 or P1 based
on privatized views Y1 , . . . , Yn . According to Chernoff-Steinâ€™s lemma, for a bounded type
I error probability, the best type II error probability scales as eâˆ’n Dkl (M0 ||M1 ) . Naturally,
we are interested in finding a privatization mechanism Q that minimizes the probability of
error by solving the following constraint maximization problem
maximize
Q

Dkl (M0 ||M1 )
,

(4)

subject to Q âˆˆ DÎµ
where DÎµ is the set of all Îµ-locally differentially private mechanisms satisfying (1).
In the information preservation setting, X is generated from an underlying distribution
P . We are interested in quantifying how much information can be preserved when releasing
a private view of the data. In other words, the data provider would like to release an Îµlocally differentially private view Y of X that preserves the amount of information in X as
much as possible. The utility in this case is measured by the mutual information between
X and Y


XX
Q (y|x)
I (X; Y ) =
P (x) Q (y|x) log P
.
(5)
lâˆˆX P (l) Q (y|l)
X

Y

Mutual information, as the name suggests, measures the mutual dependence between two
random variables. It has been used as a criterion for feature selection and as a measure of
similarity between two different clusterings of a data set, in addition to many other applications in signal processing and machine learning. To characterize the fundamental tradeoff
between privacy and mutual information, we solve the following constrained maximization
problem
maximize I(X; Y )
Q
,
(6)
subject to Q âˆˆ DÎµ
where DÎµ is the set of all Îµ-locally differentially private mechanisms satisfying (1).
Motivated by such applications in statistical analysis, our goal is to provide a general
framework for finding optimal privatization mechanisms that maximize information theoretic utilities under local differential privacy. We demonstrate the power of our techniques
in a very general setting that includes both hypothesis testing and information preservation.
1.3 Our contributions
We study the fundamental tradeoff between local differential privacy and a rich class of
convex utility functions. This class of utilities includes several information theoretic quantities such as mutual information and f -divergences. The privacy-utility tradeoff is posed as
a constrained maximization problem: maximize utility subject to local differential privacy
constraints. This maximization problem is (a) nonlinear: the utility functions we consider
4

Extremal Mechanisms for Local Differential Privacy

are convex in Q; (b) non-standard: we are maximizing instead of minimizing a convex
function; and (c) infinite dimensional: the space of all differentially private mechanisms is
infinite dimensional. We show, in Theorem 2, that for all utility functions considered and
any privacy level Îµ, a finite family of extremal mechanisms (a finite subset of the corner
points of the space of differentially private mechanisms), which we call staircase mechanisms, contains the optimal privatization mechanism. We further prove, in Theorem 4, that
solving the original privacy-utility problem is equivalent to solving a finite dimensional linear program, the outcome of which is the optimal mechanism. However, solving this linear
program can be computationally expensive because it has 2|X | variables. To account for
this, we show that two simple staircase mechanisms (the binary and randomized response
mechanisms) are optimal in the high and low privacy regimes, respectively, and well approximate the intermediate regime. This contributes an important progress in the differential
privacy area, where the privatization mechanisms have been few and almost no exact optimality results are known. As an application, we show that the effective sample size reduces
from n to Îµ2 n under local differential privacy in the context of hypothesis testing.
We also study the fundamental tradeoff between utility and approximate differential
privacy, a generalized notion of privacy that was first introduced in Dwork et al. (2006a).
The techniques we develop for differential privacy do not generalize to approximate differential privacy. To account for this, we use an operational interpretation of approximate
differential privacy (developed in Kairouz et al. (2014a)) to prove that a simple mechanism
maximizes utility for all levels of privacy when the data is binary.
1.4 Related work
Our work is closely related to the recent work of Duchi et al. (2013) where an upper bound
on Dkl (M0 ||M1 ) was derived under the same local differential privacy setting. Precisely,
Duchi et. al. proved that the KL-divergence maximization problem in (4) is at most 4(eÎµ âˆ’
1)2 kP1 âˆ’ P2 k2T V . This bound was further used to provide a minimax bound on statistical
estimation using information theoretic converse techniques such as Fanoâ€™s and Le Camâ€™s
inequalities. Such tradeoffs also provide tools for comparing various notions of privacy
(Barber and Duchi, 2014).
In a similar spirit, we are also interested in maximizing information theoretic quantities
under local differential privacy. We generalize the results of Duchi et al. (2013), and provide
stronger results in the sense that we (a) consider a broader class of information theoretic
utilities; (b) provide explicit constructions for the optimal mechanisms; and (c) recover the
existing result of (Duchi et al., 2013, Theorem 1) (with a stronger condition on Îµ).
Our work also provides a formal connection to an information theoretic notion of privacy called information leakage (Chatzikokolakis et al., 2010; Sankar et al., 2013). Given
a privatization mechanism Q, the information leakage is measured by the mutual information between the private data X and the released output Y , i.e. I(X; Y ). Information
leakage has been widely studied as a practical notion of privacy. However, connections to
differential privacy have been studied only indirectly through comparisons to how much
distortion is incurred under the two notions of privacy (Sarwate and Sankar, 2014; Wang
et al., 2014a). We show that under Îµ-local differential privacy, I(X; Y ) is upper bounded by
5

Kairouz, Oh and Viswanath

0.5Îµ2 maxAâŠ†X P (A)P (Ac )+O(Îµ3 ) for small Îµ. Moreover, we provide an explicit privatization
mechanism that achieves this bound.
While there is a vast literature on differential privacy, exact optimality results are only
known for a few cases. The typical recipe is to propose a differentially private mechanism
inspired by the work of Dwork (2006); Dwork et al. (2006b); McSherry and Talwar (2007)
and Hardt and Rothblum (2010), and then establish its near-optimality by comparing the
achievable utility to a converse, for example in linear dynamical systems (Wang et al.,
2014b), principal component analysis (Chaudhuri et al., 2012; Blocki et al., 2012; Hardt
and Roth, 2012; Kapralov and Talwar, 2013), linear queries (Hardt and Talwar, 2010; Hardt
et al., 2012), logistic regression (Chaudhuri and Monteleoni, 2008) and histogram release
(Lei, 2011). In this paper, we take a different route and solve the utility maximization
problem exactly.
Optimal differentially private mechanisms are known only in a few cases. Ghosh et al.
(2012) showed that the geometric noise adding mechanism is optimal (under a Bayesian
setting) for monotone utility functions under count queries (sensitivity one). This was generalized by Geng et. al. (for a worst-case input setting) who proposed a family of mechanisms
and proved its optimality for monotone utility functions under queries with arbitrary sensitivity (Geng and Viswanath, 2012, 2013a,b). The family of optimal mechanisms was called
staircase mechanisms because for any y and any neighboring x and x0 , the ratio of Q(y|x)
to Q(y|x0 ) takes one of three possible values eÎµ , eâˆ’Îµ , or 1. Since the optimal mechanisms
we develop also have an identical property, we retain the same nomenclature.
1.5 Organization
The remainder of the paper is organized as follows. In Section 2, we introduce the family of
staircase mechanisms, prove its optimality for a broad class of convex utility functions, and
study its combinatorial structure. In Section 3, we study the problem of private hypothesis
testing and prove that two staircase mechanisms, the binary and randomized response
mechanisms, are optimal for KL-divergence in the high and low privacy regimes, respectively,
and (nearly) optimal the intermediate regime. We show, in Section 4, similar results for
mutual information. In Section 5, we study approximate local differential privacy, a more
general notion of local privacy. Finally, we conclude this paper in Section 6 with a few
interesting and nontrivial extensions.

2. Main Results
In this section, we first present a formal definition for staircase mechanisms and prove that
they are the optimal solutions to optimization problems of the form (8). We then provide
a combinatorial representation for staircase mechanisms that allows us to reduce the infinite dimensional nonlinear program of (8) to a finite dimensional linear program with 2|X |
variables. For any given privacy level Îµ and utility function U (Â·), one can solve this linear
program to obtain the optimal privatization mechanism, albeit with significant computational challenges since the number of variables scales exponentially in the alphabet size. To
address this issue, we prove, in Sections 3 and 4, that two simple staircase mechanisms,
which we call the binary mechanism and the randomized response mechanism, are optimal
6

Extremal Mechanisms for Local Differential Privacy

in the high and low privacy regimes, respectively, and well approximate the intermediate
regime.
2.1 Optimality of staircase mechanisms
For an input alphabet X with |X | = k, we represent the set of Îµ-locally differentially private
mechanisms that lead to output alphabets Y with |Y| = ` by


Q (S|x)
0
DÎµ,` = QkÃ—` âˆ© Q : âˆ€ x, x âˆˆ X , S âŠ† Y, ln
â‰¤Îµ ,
Q (S|x0 )
where QkÃ—` denotes the set of all k Ã— ` dimensional conditional distributions. The set of all
Îµ-locally differentially private mechanisms is given by
DÎµ = âˆª`âˆˆN DÎµ,` .

(7)

The set of all conditional distributions acting on X is given by Q = âˆª`âˆˆN Qk,` .
We consider two types of utility functions, one for the hypothesis testing setup and
another for the information preservation setup. In the hypothesis testing setup, the utility
is a function of the privatization mechanism and two priors defined on the input alphabet.
Namely, U (P0 , P1 , Q) : Sk Ã— Sk Ã— Q â†’ R+ , where P0 and P1 are positive priors defined
on X , and Sk is the (k âˆ’ 1)-dimensional probability simplex. PÎ½ is said to be positive if
PÎ½ (x) > 0 for all x âˆˆ X . In the information preservation setup, the utility is a function of
the privatization mechanism and a prior defined on the input alphabet. Namely, U (P, Q) :
Sk Ã— Q â†’ R+ , where P is a positive prior defined on X . For notational convenience, we
will use U (Q) to refer to both U (P, Q) and U (P0 , P1 , Q).
Definition 1 (Sublinear Functions) A function Âµ (z) : Rk â†’ R is said to be sublinear
if the following two conditions are met
1. Âµ (Î³z) = Î³Âµ (z) for all Î³ âˆˆ R+ .
2. Âµ (z1 + z2 ) â‰¤ Âµ (z1 ) + Âµ (z2 ) for all z1 , z2 âˆˆ Rk .
Let Qy be the column of Q corresponding to Q(y|Â·) and Âµ be any sublinear function.
We are interested in utilities that can be decomposed into a sum of sublinear functions.
We study the fundamental tradeoff between privacy and utility by solving the following
constrained maximization problem
X
maximize U (Q) =
Âµ(Qy )
Q
yâˆˆY
.
(8)
subject to Q âˆˆ DÎµ
This includes maximization over information theoretic quantities of interest in statistical estimation and hypothesis testing such as mutual information, total variation, KL-divergence,
and Ï‡2 -divergence (Tsybakov and Zaiats, 2009). Since sub-linearity implies convexity, (8)
is in general a complicated nonlinear program: we are maximizing (instead of minimizing)
a convex function in Q; further, the dimension of Q might be unbounded: the optimal
7

Kairouz, Oh and Viswanath

privatization mechanism Qâˆ— might produce an infinite output alphabet Y. The following
theorem proves that one never needs an output alphabet larger than the input alphabet in
order to achieve the maximum utility, and provides a combinatorial representation for the
optimal solution.
Theorem 2 For any sublinear function Âµ and any Îµ â‰¥ 0, there exists an optimal mechanism
Qâˆ— maximizing the utility in (8) over all Îµ-locally differentially private mechanisms, such
that
(a) the output alphabet size is at most the input alphabet size, i.e. |Y| â‰¤ |X |; and
(b) for all y âˆˆ Y, and x, x0 âˆˆ X
ln

Qâˆ— (y|x)
âˆˆ {0, Îµ} .
Qâˆ— (y|x0 )

(9)

The first claim of bounded alphabet size is more generally true for any general utility U (Q)
that is convex in Q (not necessarily decomposing into a sum of sublinear functions as in (8)).
The second claim establishes that there is an optimal mechanism with an extremal structure;
the absolute value of the log-likelihood ratios can only take one of the two extremal values:
0 or eÎµ (see Figure 2 for example). We refer to such a mechanism as a staircase mechanism,
and define the family of staircase mechanisms formally as
SÎµ â‰¡ {Q | satisfying (9)} .
P
For all choices of U (Q) = Y Âµ(Qy ) and any Îµ â‰¥ 0, Theorem 2 implies that the family
of staircase mechanisms includes the optimal solutions to maximization problems of the
form (8). Notice that staircase mechanisms are Îµ-locally differentially private, since any Q
satisfying (9) implies that Q(y|x)/Q(y|x0 ) â‰¤ eÎµ .
For global differential privacy, we can generalize the definition of staircase mechanisms to
hold for all neighboring database queries x, x0 (or equivalently within some sensitivity), and
recover all known existing optimal mechanisms. Precisely, the geometric mechanism shown
to be optimal in Ghosh et al. (2012), and the mechanisms shown to be optimal in Geng
and Viswanath (2012, 2013a) (also called staircase mechanisms) are special cases of the
staircase mechanisms defined above. We believe that the characterization of these extremal
mechanisms and the analysis techniques developed in this paper can be of independent
interest to researchers interested in optimal mechanisms for global privacy and more general
utilities.
2.2 Combinatorial representation of the staircase mechanisms
Now that we know that staircase mechanisms are optimal, we can try to combinatorially
search for the best staircase mechanism for an instance of the function Âµ and a fixed Îµ. To
this end, we give a simple representation for all staircase mechanisms, exploiting the fact
that they are scaled copies of a finite number of patterns.
Let Q âˆˆ R|X |Ã—|Y| be a staircase mechanism, and k = |X | denote the size of the input
alphabet. Then, from the definition of staircase mechanisms, Q(y|x)/Q(y|x0 ) âˆˆ {eâˆ’Îµ , 1, eÎµ }
and each column Q(y|Â·) must be proportional to one of the canonical staircase patterns we
define next.
8

Extremal Mechanisms for Local Differential Privacy

 Îµ Îµ

e e
1 eÎµ 1
1
T
Q = 1+eÎµ
1 1 eÎµ 1 eÎµ

ï£¹
ï£® Îµ
e
1 1 1
ï£¯
eÎµ 1 1 ï£º
1 ï£¯1
ï£º
QT = 3+e
Îµ ï£°
1 1 eÎµ 1 ï£»
1 1 1 eÎµ
eÎµ
3+eÎµ

eÎµ
1+eÎµ

y=1

1
3+eÎµ

1
1+eÎµ

y=1

2
3
2
4
x=1

2

3

4

5

x=1

2

3

4

Figure 2: Examples of staircase mechanisms: the binary (left) and the randomized response
(right) mechanisms.

Definition 3 (Staircase Pattern Matrix) Let bj be the k-dimensional binary vector cork
responding to the binary representation of j for j â‰¤ 2k âˆ’ 1. A matrix S (k) âˆˆ {1, eÎµ }kÃ—2 is
(k)
called a staircase pattern matrix if the j-th column of S (k) is Sj = (eÎµ âˆ’ 1) bjâˆ’1 + 1, for
j âˆˆ {1, . . . , 2k }. Each column of S (k) is a staircase pattern.
When k = 3, there are 2k = 8 staircase patterns and the staircase pattern matrix is given
by
ï£¹
ï£®
1 1 1 1 eÎµ eÎµ eÎµ eÎµ
S (3) = ï£°1 1 eÎµ eÎµ 1 1 eÎµ eÎµ ï£» .
1 eÎµ 1 eÎµ 1 eÎµ 1 eÎµ
For all values of k, there are exactly 2k such patterns, and any column Q(y|Â·) of Q, a
staircase mechanism, is a scaled version of one of the columns of S (k) . Using this pattern
matrix, we can show that any staircase mechanism Q can be represented as
Q = S (k) Î˜ ,

(10)

where Î˜ = diag(Î¸) is a 2k Ã—2k diagonal matrix and Î¸ is a 2k -dimensional vector representing
the scaling of the columns of S (k) . We can now formulate the problem of maximizing the
utility as a linear program and prove their equivalence.

9

Kairouz, Oh and Viswanath

Theorem 4 For any sublinear function Âµ and any Îµ â‰¥ 0, the nonlinear program of (8) and
the following linear program have the same optimal value
k

maximize
Î¸âˆˆR2k

subject to

2
X

(k)

Âµ(Sj )Î¸j = ÂµT Î¸

(11)

j=1

S (k) Î¸ = 1
Î¸â‰¥0,

and the optimal solutions are related by (10).
Thus, the infinite dimensional nonlinear program of (8) is now reduced to a finite dimensional linear program. The constraints in (11) ensure that we get a valid probability matrix
Q = S (k) Î˜ with rows that sum to one. One could potentially solve this LP with 2k variables
but its computational complexity scales exponentially in the alphabet size k = |X |. For
practical values of k this might not always be possible. However, in the following sections,
we prove that in the high privacy regime (Îµ â‰¤ Îµâˆ— for some positive Îµâˆ— ), there is a single
optimal mechanism, which we call the binary mechanism, which dominates over all other
mechanisms in a very strong sense for all utility functions of practical interest.
In order to understand the above theorem, observe that both the objective function
and differential privacy constraints are invariant under permutations (or relabelling) of the
columns of a privatization mechanism Q. In other words, shuffling the columns of an Îµlocally differentially private mechanism Q results in a new Îµ-locally differentially private
mechanism Q0 that achieves the same utility. Similarly, both the objective function and
differential privacy constraints are invariant under merging/splitting of outputs with the
same pattern. To be specific, consider a privatization mechanism Q and suppose that
there exist two outputs y and y 0 that have the same pattern, i.e. Q(y|Â·) = C Q(y 0 |Â·) for
some positive constant C. Then, we can consider a new mechanism Q0 by merging the
two columns corresponding to y and y 0 . Let y 00 denote this new output. It follows that
Q0 satisfies the differential privacy constraints and the resulting utility is also preserved.
Precisely, using the fact that Q(y|Â·) = C Q(y 0 |Â·), it follows that
Âµ(Qy ) + Âµ(Qy0 ) = Âµ((1 + C)Qy ) = Âµ(Q0y00 ) ,
by the homogeneity property of Âµ. Therefore, we can naturally define equivalence classes
for staircase mechanisms that are equivalent up to a permutation of columns and merging/splitting of columns with the same pattern:
[Q] = {Q0 âˆˆ SÎµ | âˆƒ a sequence of permutations and merge/split of columns from Q0 to Q} .
To represent an equivalence class, we use a mechanism in [Q] that is ordered and merged to
match the patterns of the pattern matrix S (k) . For any staircase mechanism Q, there exists
a possibly different staircase mechanism Q0 âˆˆ [Q] such that Q0 = S (k) Î˜ for some diagonal
matrix Î˜ with nonnegative entries. Therefore, to solve optimization problems of the form
(8), we can restrict our attention to such representatives of equivalent classes. Further, for
privatization mechanisms of the form Q = S (k) Î˜, the objective function takes the form
P
(k)
j Âµ(Sj )Î¸j , a simple linear function of Î˜.
10

Extremal Mechanisms for Local Differential Privacy

3. Hypothesis Testing
In this section, we study the fundamental tradeoff between local differential privacy and
hypothesis testing. In this setting, there are n individuals each with data Xi sampled from
a distribution PÎ½ for a fixed Î½ âˆˆ {0, 1}. Let Q be a non-interactive privatization mechanism
guaranteeing Îµ-local differential privacy. The output of the privatization mechanism Yi is
distributed according to the induced marginal MÎ½ defined in (2). With a slight abuse of
notation, we will use MÎ½ and PÎ½ to represent both probability distributions and probability
mass functions. The power to discriminate data sampled from P0 to data sampled from P1
depends on the â€˜distanceâ€™ between the marginals M0 and M1 . To measure the ability of
such statistical discrimination, our choice of utility of a privatization mechanism Q is an
information theoretic quantity called CsiszaÌrâ€™s f -divergence defined as
Df (M0 ||M1 ) =

X

M1 (y)f

 M (y) 

Y

0

M1 (y)

= U (P0 , P1 , Q) = U (Q) ,

(12)

for some convex function f such that f (1) = 0. The Kullback-Leibler (KL) divergence
Dkl (M0 ||M1 ) is a special case of f -divergence with f (x) = x log x. The total variation
distance kM0 âˆ’ M1 kTV is also special case with f (x) = (1/2)|x âˆ’ 1|. Note that in general,
the f -divergence is not necessarily a distance metric since it need not be symmetric or
satisfy triangular inequality. We are interested in characterizing the optimal solution to
Df (M0 ||M1 )
,
subject to Q âˆˆ DÎµ

maximize
Q

(13)

where DÎµ is the set of all Îµ-locally differentially private mechanisms defined in (7).
A motivating example for this choice of utility is the Neyman-Pearson hypothesis testing
framework (Cover and Thomas, 2012). Given the privatized views {Yi }ni=1 , the data analyst
wants to test whether they are generated from M0 or M1 . Let the null hypothesis be H0 :
Yi â€™s are generated from M0 , and the alternative hypothesis H1 : Yi â€™s are generated from M1 .
For a choice of rejection region R âŠ† Y n , the probability of false alarm (type I error) is
Î± = M0n (R) and the probability of miss detection (type II error) is Î² = M1n (Y n \ R). Let
âˆ—
Î² Î± = minRâŠ†Y n ,Î±<Î±âˆ— Î² denote the minimum type II error achievable while keeping the type
I error rate at most Î±âˆ— . According to Chernoff-Stein lemma (Cover and Thomas, 2012), we
know that
lim

1

nâ†’âˆ n

âˆ—

log Î² Î± = âˆ’Dkl (M0 ||M1 ) .

Suppose the analyst knows P0 , P1 , and Q. Then in order to achieve optimal asymptotic
error rate, one would want to maximize the KL divergence of the induced marginals, over
all Îµ-locally differentially private mechanisms Q. The results we present in this section
(Theorems 5 and 8 to be precise) provide an explicit construction of optimal mechanisms
in high and low privacy regimes. Using these optimality results, we prove a fundamental
limit on the achievable error rates under differential privacy. Precisely, with data collected
from an Îµ-locally differentially privatization mechanism, one cannot achieve an asymptotic
11

Kairouz, Oh and Viswanath

type II error smaller than
1
(1 + Î´)(eÎµ âˆ’ 1)2
(1 + Î´)(eÎµ âˆ’ 1)2
âˆ—
2
log Î² Î± â‰¥ âˆ’
kP
âˆ’
P
k
â‰¥
âˆ’
Dkl (P0 ||P1 ) ,
0
1 TV
nâ†’âˆ n
(eÎµ + 1)
2(eÎµ + 1)
lim

whenever Îµ â‰¤ Îµâˆ— , where Îµâˆ— is dictated by Theorem 5 and Î´ > 0 is some arbitrarily small
but positive constant. In the equation above, the second inequality follows from Pinskerâ€™s
inequality. Since (eÎµ âˆ’ 1)2 = O(Îµ2 ) for small Îµ, the effective sample size is now reduced
from n to Îµ2 n. This is the price of privacy. In the low privacy regime where Îµ â‰¥ Îµâˆ— , for Îµâˆ—
dictated by Theorem 8, one cannot achieve an asymptotic type II error smaller than
1
âˆ—
log Î² Î± â‰¥ âˆ’Dkl (P0 ||P1 ) + (1 âˆ’ Î´)G(P0 , P1 )eâˆ’Îµ .
nâ†’âˆ n
lim

3.1 Optimality of staircase mechanisms
From the definition of Df (M0 ||M1 ), we have that
X
X
Df (M0 ||M1 ) =
(P1T Qy )f (P0T Qy /P1T Qy ) =
Âµ (Qy ) ,
Y

where PÎ½T Qy =

P

Y

T
T
T
X PÎ½ (x) Q (y|x) and Âµ (Qy ) = (P1 Qy )f (P0 Qy /P1 Qy ). For any Î³ > 0,



P1T (Î³Qy ) f P0T (Î³Qy ) /P1T (Î³Qy )


= Î³ P1T Qy f P0T Qy /P1T Qy

Âµ (Î³Qy ) =

= Î³Âµ (Qy ) .

Moreover, since the function Ï†(z, t) = tf zt is convex in (z, t) for 0 â‰¤ z, t â‰¤ 1, then
Âµ is convex in Qy . Convexity and homogeniety together imply sublinearlity. Therefore,
Theorems 2 and 4 apply to Df (M0 ||M1 ) and we have that staircases are optimal.
3.2 Optimality of the binary mechanism
For a given P0 and P1 , the binary mechanism is defined as a staircase mechanism with only
two outputs y âˆˆ {0, 1} satisfying (see Figure 2)
ï£±
ï£±
eÎµ
eÎµ
ï£´
ï£´
ï£²
ï£²
if
P
(x)
â‰¥
P
(x)
,
if P0 (x) < P1 (x) ,
0
1
1 + eÎµ
1 + eÎµ
Q(1|x)
=
(14)
Q(0|x) =
1
1
ï£´
ï£´
ï£³
ï£³
if
P
(x)
<
P
(x)
.
if
P
(x)
â‰¥
P
(x)
.
0
1
0
1
1 + eÎµ
1 + eÎµ
Although this mechanism is extremely simple, perhaps surprisingly, we will establish that
it is the optimal mechanism when a high level of privacy is required. Intuitively, the output
should be very noisy in the high privacy regime, and we are better off sending just one bit
of information that tells you whether your data is more likely to have come from P0 or P1 .
Theorem 5 For any pair of distributions P0 and P1 , there exists a positive Îµâˆ— that depends
on P0 and P1 such that for any f -divergences and any positive Îµ â‰¤ Îµâˆ— , the binary mechanism
maximizes the f -divergence between the induced marginals over all Îµ-locally differentially
private mechanisms.
12

Extremal Mechanisms for Local Differential Privacy

This implies that in the high privacy regime, which is a typical setting studied in much
of the differential privacy literature, the binary mechanism is universally optimal for all
f -divergences. In particular this threshold Îµâˆ— is universal, in that it does not depend on the
particular choice of which f -divergence we are maximizing. It is only a function of P0 and
P1 . This is established by proving a very strong statistical dominance using Blackwellâ€™s celebrated result on comparisons of statistical experiments Blackwell (1953). In a nutshell, we
prove that any Îµ-locally differentially private mechanism can be simulated from the output
of the binary mechanism for sufficiently small Îµ. Hence, the binary mechanism dominates
over all other mechanisms and at the same time achieves the maximum divergence. A similar idea has been used previously in (Kairouz et al., 2013) to exactly characterize how much
privacy degrades under composition attacks.
The optimality of binary mechanisms is not just for high privacy regimes. The next
theorem shows that it is the optimal solution of (13) for all Îµ, when the objective function
is the total variation distance: Df (M0 ||M1 ) = kM0 âˆ’ M1 kTV .
Theorem 6 For any pair of distributions P0 and P1 , and any Îµ â‰¥ 0, the binary mechanism
maximizes the total variation distance between the induced marginals M0 and M1 among all
Îµ-locally differentially private mechanisms.
When maximizing the KL divergence between the induced marginals, we show that the
binary mechanism still achieves good performance for Îµ â‰¤ C where C is a constant that
does not depend on P0 and P1 . For the special case of KL divergence, let OPT denote the
maximum value of (13) and BIN denote the KL divergence when the binary mechanism is
used. The next theorem shows that
BIN â‰¥

1
OPT .
2(eÎµ + 1)2

Theorem 7 For any Îµ and any pair of distributions P0 and P1 , the binary mechanism is an
1/(2(eÎµ + 1)2 ) approximation of the maximum KL divergence between the induced marginals
M0 and M1 among all Îµ-locally differentially private mechanisms.
Observe that 2(eÎµ + 1)2 â‰¤ 32 for Îµ â‰¤ 1. Therefore, for any Îµ â‰¤ 1, the simple binary
mechanism is at most a constant factor away from the optimal mechanism.
3.3 Optimality of the randomized response mechanism
The randomized response mechanism (see Figure 2) is a staircase mechanism with Y = X
satisfying
eÎµ
|X | âˆ’ 1 + eÎµ
Q(y|x) =
1
ï£´
ï£³
|X | âˆ’ 1 + eÎµ
ï£±
ï£´
ï£²

if y = x ,
(15)
if y 6= x .

In other words, the randomized response is a simple randomization over the same alphabet
where the true data is released with probability eÎµ / (|X | âˆ’ 1 + eÎµ ). We view it as a multiple
13

Kairouz, Oh and Viswanath

choice generalization to the randomized response method proposed by Warner (1965). We
now establish that for the special case of optimizing the KL divergence between the induced
marginals, the randomized response mechanism is the optimal solution of (13) in the low
privacy regime (i.e., Îµ â‰¥ Îµâˆ— for some threshold Îµâˆ— that depends on P0 and P1 ).
Theorem 8 There exists a positive Îµâˆ— that depends on P0 and P1 such that for all P0
and P1 , and all Îµ â‰¥ Îµâˆ— , the randomized response mechanism maximizes the KL divergence
between the induced marginals among all Îµ-locally differentially private mechanisms.
The randomized response mechanism is particularly important because it does not depend
on P0 or P1 . Thus, even if the data providers and analysts do not have access to the
priors, they can still use the randomized response mechanism to achieve the optimal (or
near-optimal) utility in the moderate to low privacy regimes.
3.4 Numerical Experiments
A typical approach for achieving Îµ-local differential privacy is to add geometric noise with
appropriately chosen variance. For an input with alphabet size |X | = k, this amounts
to relabelling the inputs as integers {1, . . . , k} and adding geometric noise, i.e., Q(y|x) =
((1 âˆ’ Îµ1/(kâˆ’1) )/(1 + Îµ1/(kâˆ’1) ))Îµ|yâˆ’x|/(kâˆ’1) for y âˆˆ Z. The output is then truncated at 1 and
k to preserve the support.
For 100 instances of randomly chosen P0 and P1 defined over an input alphabet of
size |X | = 6, we compare the average performance of the binary, randomized response,
and geometric mechanisms to the average performance of the optimal staircase mechanism
for various values of Îµ. The optimal staircase mechanism is computed by solving the linear
program in Equation (11) for each fixed pair (P0 , P1 ) and Îµ. The left panel of Figure 3 shows
the average performance measured by the normalized divergence Dkl (M0 ||M1 )/Dkl (P0 ||P1 )
for all 4 mechanisms. The average is taken over the 100 instances of P0 and P1 . In the
low privacy (large Îµ) regime, the randomized response achieves optimal performance (which
converges exponentially in Îµ to 1) as predicted. In the high privacy regime (small Îµ), the
binary mechanism achieves optimal performance (which converges quadratically in Îµ to 0)
as predicted. In all regimes, both the binary and randomized response mechanisms provide
significant gains over the geometric mechanism.
To illustrate how much worse the binary and the randomized response mechanisms
can be relative to the optimal staircase mechanism, we plot in the right panel of Figure
3 the divergence under each mechanism normalized by the divergence under the optimal
mechanism. This is done for all 100 instances of P0 and P1 . In all instances, the binary
mechanism is optimal for small Îµ and the randomized response mechanism is optimal for
large Îµ. However, Dkl (M0 ||M1 ) under the randomized response mechanism can be as bad as
10% of the optimal one (for small Îµ). Similarly, Dkl (M0 ||M1 )) under the binary mechanism
can be as bad as 25% of the optimal one (for large Îµ). To overcome this issue, we propose the
following simple strategy: use the better among these two mechanisms. The performance
of this strategy is illustrated in Figure 4. For various input alphabet size |X | âˆˆ {3, 4, 6, 12},
we plot the performance of this mixed strategy for each value of Îµ and each of the 100
randomly generated instances of P0 and P1 . This mixed strategy achieves at least 70% for
|X | = 6 (and 55% for |X | = 12) of the optimal divergence for all instances. Figure 4 shows
14

Extremal Mechanisms for Local Differential Privacy

Dkl (M0 ||M1 )
Dkl (P0 ||P1 )

Dkl (M0 ||M1 )
OP T

1

optimal mechanism
binary mechanism
randomized response
0.8 geometric mechanism

1

0.9

0.9
0.8

0.7

0.7

0.6
0.5

0.6

0.4

0.5

0.3

0.4

0.2

0.3

0.1

0.2

0

0.1
0

1

2

3

4

5

6

7

8

9

10

binary mechanism
randomized response
0

Îµ

1

2

3

4

5

6

7

8

Â·Â·

9

10

Îµ

Figure 3: The binary and randomized response mechanisms are optimal in the high-privacy
(small Îµ) and low-privacy (large Îµ) regimes, respectively, and improve over the
geometric mechanism significantly (left). When the regimes are mismatched,
Dkl (M0 ||M1 ) under these mechanisms can be as bad as 10% of the optimal one
(right).

that this mixed strategy is not too sensitive to the size of the alphabet k. Therefore, this
strategy provides a good mechanism that can be readily used in practice for any value of Îµ.
3.5 Lower bounds
In this section, we provide converse results on the fundamental limit of differentially private
mechanisms; these results follow from our main theorems and are of independent interest
in other applications where lower bounds in statistical analysis are studied (Beimel et al.,
2008; Hardt and Talwar, 2010; Chaudhuri and Hsu, 2012; De, 2012). For example, a bound
similar to (16) was used to provide converse results on the sample complexity for statistical
estimation with differentially private data in Duchi et al. (2013).

Corollary 9 For any Îµ â‰¥ 0, let Q be any conditional distribution that guarantees Îµ-local
differential privacy. Then, for any pair of distributions P0 , P1 and any positive Î´ > 0,
there exists a positive Îµâˆ— that depends on P0 , P1 and Î´ such that for any Îµ â‰¤ Îµâˆ— the induced
marginals M0 and M1 satisfy the bound



Dkl M0 ||M1 + Dkl M1 ||M0 â‰¤
15

2(1 + Î´)(eÎµ âˆ’ 1)2
2
P0 âˆ’ P1 TV .
(eÎµ + 1)

(16)

Kairouz, Oh and Viswanath

Dkl (M0 ||M1 )
OP T

Dkl (M0 ||M1 )
OP T

|X | = 3

1

1

0.9

0.9

0.8

0.8

0.7

0.7

0.6

0.6

0.5

|X | = 4

0.5
0

1

2

3

4

5

6

7

8

9

10

0

1

2

3

4

Îµ
Dkl (M0 ||M1 )
OP T

5

6

7

8

9

10

7

8

9

10

Îµ
Dkl (M0 ||M1 )
OP T

|X | = 6

1

1

0.9

0.9

0.8

0.8

0.7

0.7

0.6

0.6

0.5

|X | = 12

0.5
0

1

2

3

4

5

6

7

8

9

10

0

Îµ

1

2

3

4

5

6

Îµ

Figure 4: For varying input alphabet size |X | âˆˆ {3, 4, 6, 12}, at least 55% of the optimal
divergence can be achieved by taking the better one between the binary and the
randomized response mechanisms.

This follows from Theorem 5 and observing that the binary mechanism achieves

Dkl M0 ||M1
 1 + (eÎµ âˆ’ 1)P (T ) 
(eÎµ âˆ’ 1)P0 (T ) + 1
0
=
log
eÎµ + 1
1 + (eÎµ âˆ’ 1)P1 (T )
 1 + (eÎµ âˆ’ 1)P (T c ) 
(eÎµ âˆ’ 1)P0 (T c ) + 1
0
+
log
eÎµ + 1
1 + (eÎµ âˆ’ 1)P1 (T c )
(eÎµ âˆ’ 1)2
=
(P0 (T ) âˆ’ P1 (T )) + O(Îµ3 )
eÎµ + 1
(eÎµ âˆ’ 1)2
2
=
P0 âˆ’ P1 TV + O(Îµ3 ) ,
Îµ
e +1
where T âŠ† X is the set of x such that P0 (x) â‰¥ P1 (x). Compared to (Duchi et al., 2013,
Theorem 1), we recover their bound of 4(eÎµ âˆ’ 1)2 kP0 âˆ’ P1 k2TV with a smaller constant.
16

Extremal Mechanisms for Local Differential Privacy

We want to note that Duchi et al.â€™s bound holds for all values of Îµ and uses a different
technique of bounding the KL divergence directly, however no achievable mechanism has
been provided. We instead provide an explicit mechanism, that is optimal in high privacy
regime.
Similarly, in the low privacy regime, we can show the following converse result.
Corollary 10 For any Îµ â‰¥ 0, let Q be any conditional distribution that guarantees Îµ-local
differential privacy. Then, for any pair of distributions P0 and P1 and any positive Î´ > 0,
there exists a positive Îµâˆ— that depends on P0 and P1 and Î´ such that for any Îµ â‰¥ Îµâˆ— the
induced marginals M0 and M1 satisfy the bound


Dkl M0 ||M1 + Dkl M1 ||M0 â‰¤ Dkl (P0 ||P1 ) âˆ’ (1 âˆ’ Î´)G(P0 , P1 )eâˆ’Îµ .
where G(P0 , P1 ) =

(17)

P

X (1 âˆ’ P0 (x)) log(P1 (x)/P0 (x)).

This follows directly from Theorem 8 and observing that the randomized response mechanism achieves Dkl (M0 ||M1 ) = Dkl (P0 ||P1 ) âˆ’ G(P0 , P1 )eâˆ’Îµ + O(eâˆ’2Îµ ) .
Figure 5 illustrates the gap between the divergence achieved by the geometric mechanism
described in the previous section and the optimal mechanisms (the binary mechanism for the
high privacy regime and the randomized response mechanism for the low privacy regime).
For each instance of the 100 randomly generated P0 and P1 defined over input alphabets
of size k = 6, we plot the resulting divergence Dkl (M0 ||M1 ) as a function of kP0 âˆ’ P1 kTV
for Îµ = 0.1, and as a function of Dkl (P0 ||P1 ) for Îµ = 10. The binary and the randomized
response mechanisms exhibit the scaling predicted by Equation (16) and (17), respectively.
Similarly, for total variation, we can get the following converse result.
Dkl (M0 ||M1 )
0.0035

Dkl (M0 ||M1 )
4

binary mechanism
Laplace mechanism

0.003

randomized response
geometric mechanism

3.5
3

0.0025

2.5
0.002
2
0.0015
1.5
0.001

1

0.0005

0.5

0

0
0.1

0.2

0.3

0.4

0.5

0.6

0.7

0.8

0

kP0 âˆ’ P1 kTV

0.5

1

1.5

2

2.5

3

3.5

4

Dkl (P0 ||P1 )

Figure 5: For small Îµ = 0.1 (left) the binary mechanism achieves the optimal KL divergence, which scales as Equation (16). For large Îµ = 10 (right) the randomized
response achieves the optimal KL divergence, which scales as Equation (17). Both
mechanisms improve significantly over the geometric mechanism.

17

Kairouz, Oh and Viswanath

Corollary 11 For any Îµ â‰¥ 0, let Q be any conditional distribution that guarantees Îµ-local
differential privacy. Then, for any pair of distributions P0 and P1 , the induced marginals
M0 and M1 satisfy the bound M0 âˆ’M1 TV â‰¤ ((eÎµ âˆ’ 1)/(eÎµ + 1)) P0 âˆ’P1 TV , and equality
is achieved by the binary mechanism.
This follows from Theorem 6 and explicitly computing the total variation achieved by the
binary mechanism.

4. Information Preservation
In this section, we study the fundamental tradeoff between local privacy and mutual information. Consider a random variable X distributed according to P . The information
content in X is captured by entropy
X
H (X) = âˆ’
P (x) log P (x) .
X

We are interested in releasing a differentially private version of X represented by Y . The
random variable Y should preserve the information content of X as much as possible while
meeting the local differential privacy constraints. Similar to the hypothesis testing setting,
we will show that a variant of the binary mechanism is optimal in the high privacy regime
and the randomized response mechanism is optimal in the low privacy regime.
Let Q be a non-interactive privatization mechanism guaranteeing Îµ-local differential
privacy. The output of the privatization mechanism Y is distributed according to the
induced marginal M given by
X
M (S) =
Q(S|x)P (x) ,
xâˆˆX

for S âŠ† Y. With a slight abuse of notation, we will use M and P to represent both
probability distributions and probability mass functions. The information content in Y
about X is captured by the well celebrated information theoretic quantity called mutual
information. The mutual information between X and Y is given by


XX
Q (y|x)
I (X; Y ) =
P (x) Q (y|x) log P
= U (P, Q) = U (Q) .
lâˆˆX P (l) Q (y|l)
X

Y

Notice that I (X; Y ) â‰¤ H (X) and I (X; Y ) is convex in Q (Cover and Thomas, 2012). To
preserve the information context in X, we wish to choose a privatization mechanism Q such
that the mutual information between X and Y is maximized subject to differential privacy
constraints. In other words, we are interested in characterizing the optimal solution to
maximize
Q

I (X; Y )
,

(18)

subject to Q âˆˆ DÎµ
where DÎµ is the set of all Îµ-locally differentially private mechanisms defined in (7). The
above mutual information maximization problem can be thought of as a conditional entropy
minimization problem since I (X; Y ) = H (X) âˆ’ H (X|Y ).
18

Extremal Mechanisms for Local Differential Privacy

4.1 Optimal staircase mechanisms
From the definition of I (X; Y ), we have that
 X

XX
Q (y|x)
=
Âµ (Qy ) ,
I (X; Y ) =
P (x) Q (y|x) log
P T Qy
Y

Y

X


where P T Qy = X P (x)Q (y|x) and Âµ (Qy ) = X P (x) Q (y|x) log Q (y|x) /P T Qy . Notice that Âµ (Î³Qy ) = Î³Âµ (Qy ), and by the log-sum inequality, Âµ is convex. Convexity and
homogeneity together imply sublinearity. Therefore, Theorems 2 and 4 apply to I (X; Y )
and we have that staircase mechanisms are optimal.
For a given P , the binary mechanism for mutual information is defined as a staircase
mechanism with only two outputs y âˆˆ {0, 1} (see Figure 2). Let T âŠ† X be the set that
partitions X into two partitions, T and T c , such that |P (T )âˆ’P (T c )| is minimized. Precisely,
P

P

T

âˆˆ arg min P (A) âˆ’
AâŠ†X

1
.
2

(19)

Observe that there are always multiple choices for T . Indeed, for any minimizing set T , T c
is also a minimizing set since |P (T ) âˆ’ 1/2| = |P (T c ) âˆ’ 1/2|. When there is only one such
pair, the binary mechanism is uniquely defined as
ï£±
ï£±
eÎµ
eÎµ
ï£´
ï£´
ï£²
ï£²
if
x
âˆˆ
T
,
if x âˆˆ
/T ,
1 + eÎµ
1 + eÎµ
Q(0|x) =
Q(1|x)
=
(20)
1
1
ï£´
ï£´
ï£³
ï£³
if
x
âˆˆ
/
T
.
if
x
âˆˆ
T
.
1 + eÎµ
1 + eÎµ
When there are multiple pairs, any pair (T, T c ) can be chosen to define the binary mechanism. All resulting binary mechanisms are equivalent from a utility maximization perspective.
In what follows, we will establish that this simple mechanism is the optimal mechanism in
the high privacy regime. Intuitively, in the high privacy regime, we cannot release more than
one bit of information, and hence, the input alphabet is reduced to a binary output alphabet.
In this case we have to maximize the information contained in the
 released bit by maximizing
c
c
its entropy: T âˆˆ arg max âˆ’ P (A) log P (A) âˆ’ P (A ) log P (A ) = arg max|P (A) âˆ’ 1/2| (see
AâŠ†X

AâŠ†X

Section 9.1 for a proof).
Theorem 12 For any distribution P , there exists a positive Îµâˆ— that depends on P such that
for any positive Îµ â‰¤ Îµâˆ— , the binary mechanism maximizes the mutual information between
the input and the output of a privatization mechanism over all Îµ-locally differentially private
mechanisms.
This implies that in the high privacy regime, the binary mechanism is the optimal solution
for (18).
Next, we show that the binary mechanism achieves near-optimal performance for all
(X , P ) and Îµ â‰¤ 1 even when Îµâˆ— < 1. Let OPT denote the maximum value of (18) and BIN
denote the mutual information achieved by the binary mechanism given in (20). The next
theorem shows that
1
BIN â‰¥
OPT .
1 + eÎµ
19

Kairouz, Oh and Viswanath

Theorem 13 For any Îµ â‰¤ 1 and any distribution P , the binary mechanism is an (1 + eÎµ )approximation of the maximum mutual information between the input and the output of a
privatization mechanism among all Îµ-locally differentially private mechanisms.
Note that 1 + eÎµ â‰¤ 4 for Îµ â‰¤ 1 which is a commonly studied regime in differential privacy
applications. Therefore, we can always use the simple binary mechanism and the resulting
mutual information is at most a constant factor away from the optimal.
In the low privacy regime (Îµ â‰¥ Îµâˆ— ), the randomized response mechanism defined in(15)
is optimal.
Theorem 14 There exists a positive Îµâˆ— that depends on P such that for any distribution P
and all Îµ â‰¥ Îµâˆ— , the randomized response mechanism maximizes the mutual information between the input and the output of as privatization mechanism over all Îµ-locally differentially
private mechanisms.
4.2 Numerical Experiments
For 100 instances of randomly chosen P defined over input alphabet of size |X | = 6, we
compare the average performance of the binary, randomized response, and the geometric
mechanisms to the optimal mechanism. We plot (in Figure 6, left) the average performance
measured by the normalized mutual information I (X; Y )/H (X) for all 4 mechanisms. The
average is taken over the 100 instances of P . In the low privacy (large Îµ) regime, the
randomized response achieves optimal performance as predicted, which converges to one.
In the high privacy regime (small Îµ), the binary mechanism achieves optimal performance
as predicted. In all regimes, both mechanisms significantly improve over the geometric
mechanism. To illustrate how much worse the binary and randomized response mechanisms
can be (relative to the optimal staircase mechanism), we plot (in Figure 6, right) the mutual
information under each mechanism normalized by the mutual information under the optimal
staircase mechanism. This is done for all 100 instances of P . In all instances, the binary
mechanism is optimal for small Îµ and the randomized response mechanism is optimal for
large Îµ. However, I (X; Y ) under the randomized response mechanism can be as bad as
35% of the optimal one (for small Îµ). Similarly, I (X; Y ) under the binary mechanism can
be as bad as 40% of the optimal one (for large Îµ).
For |X | âˆˆ {3, 4, 6, 12}, we plot (in Figure 7) the performance of better between the
binary and randomized response mechanisms normalized by the optimal mechanism for all
100 randomly generated instances of P . This mixed strategy achieves at least 75% for
|X | = 6 (and 65% for |X | = 12) of the optimal mutual infirmation for all instances of P .
Moreover, it is not sensitive to the size of the alphabet |X |.
4.3 Lower bounds
In this section, we provide converse results on the fundamental limit of locally differentially
private mechanisms when utility is measured via mutual information.
Corollary 15 For any Îµ â‰¥ 0, let Q be any conditional distribution that guarantees Îµ-local
differential privacy. Then, for any distribution P and any positive Î´ > 0, there exists a
20

Extremal Mechanisms for Local Differential Privacy

I(X;Y )
H(X)

I(X;Y )
OP T

1

optimal mechanism
binary mechanism
randomized response
0.8 geometric mechanism

1

0.9

0.9

0.7

0.8

0.6
0.7

0.5
0.4

0.6

0.3

0.5

0.2
0.4

0.1

0.3

0
0

1

2

3

4

5

6

7

8

9

10

binary mechanism
randomized response
0

1

2

3

4

Îµ

5

6

7

8

Â·Â·

9

10

Îµ

Figure 6: The binary and randomized response mechanisms are optimal in the high-privacy
(small Îµ) and low-privacy (large Îµ) regimes, respectively, and improve over the
geometric mechanism significantly (left). When the regimes are mismatched,
I (X; Y ) under these mechanisms can each be as bad as 35% of the optimal one
(right).

positive Îµâˆ— that depends on P and Î´ such that for any Îµ â‰¤ Îµâˆ— the following bound holds
1
I (X; Y ) â‰¤ (1 + Î´) P (T ) P (T c ) Îµ2 ,
2

(21)

where T is defined in (19).
This follows from Theorem 12 (optimality of the binary mechanism) and observing that the
binary mechanism achieves


1
eÎµ
1
c
I (X; Y ) = Îµ
P (T ) eÎµ log
+
P
(T
)
log
e +1
P (T c ) + eÎµ P (T )
P (T c ) + eÎµ P (T )


1
eÎµ
1
c Îµ
+ Îµ
P (T ) e log
+ P (T ) log
e +1
P (T ) + eÎµ P (T c )
P (T ) + eÎµ P (T c )

1
=
P (T ) P (T c ) Îµ2 + O Îµ3 .
2
Similarly, in the low privacy regime, we can show the following converse result.
Corollary 16 For any Îµ â‰¥ 0, let Q be any conditional distribution that guarantees Îµ-local
differential privacy. Then, for any distributions P and any positive Î´ > 0, there exists a
positive Îµâˆ— that depends on P and Î´ such that for any Îµ â‰¥ Îµâˆ— the following bound holds
I (X; Y ) â‰¤ H (X) âˆ’ (1 âˆ’ Î´) (k âˆ’ 1) Îµeâˆ’Îµ .
This follows directly from Theorem 14 (optimality of the randomized response mechanism)
and observing that the randomized response mechanism achieves
I (X; Y ) = H (X) âˆ’ (k âˆ’ 1) Îµeâˆ’Îµ + O(eâˆ’2Îµ ).
21

(22)

Kairouz, Oh and Viswanath

I(X;Y )
OP T

I(X;Y )
OP T

|X | = 3

1.05

1.05

1

1

0.95

0.95

0.9

0.9

0.85

0.85

0.8

0.8

0.75

0.75

0.7

0.7

0.65

|X | = 4

0.65
0

1

2

3

4

5

6

7

8

9

10

0

1

2

3

4

5

Îµ
I(X;Y )
OP T

6

7

8

9

10

7

8

9

10

Îµ
I(X;Y )
OP T

|X | = 6

1.05

1.05

1

1

0.95

0.95

0.9

0.9

0.85

0.85

0.8

0.8

0.75

0.75

0.7

0.7

0.65

|X | = 12

0.65
0

1

2

3

4

5

6

7

8

9

10

0

1

2

3

4

Îµ

5

6

Îµ

Figure 7: For varying input alphabet size |X | âˆˆ {3, 4, 6, 12}, at least 65% of the maximum
I (X; Y ) can be achieved by taking the better one between the binary and the
randomized response mechanisms.

Figure 8 illustrates the gap between the mutual information achieved by the geometric
mechanism and the optimal mechanisms (the binary mechanism for the high privacy regime
and the randomized response mechanism for the low privacy regime). For each instance
of the 100 randomly generated P over input of size k = 6, we plot the resulting mutual
information I (X; Y ) as a function of P (T ) P (T c ) for Îµ = 0.1, and as a function of H (X) for
Îµ = 10. The binary and the randomized response mechanisms exhibit the scaling predicted
by Equations (21) and (22), respectively.

5. Generalizations to approximate differential privacy
In this section, we generalize the results of the previous sections in the following ways.
1. We consider the class of utility functions that obey the data processing inequality.
Consider the composition of two privatization mechanisms QW = Q â—¦ W where the
22

Extremal Mechanisms for Local Differential Privacy

I (X; Y )
0.002
0.0018

I (X; Y )
2.6

binary mechanism
geometric mechanism

randomized response
geometric mechanism

2.4
2.2

0.0016

2

0.0014

1.8

0.0012

1.6

0.001

1.4

0.0008

1.2

0.0006

1

0.0004

0.8

0.0002

0.6

0
0.16 0.17 0.18 0.19 0.2 0.21 0.22 0.23 0.24 0.25

0.4
0.8

1

1.2

P (T ) P (T c )

1.4

1.6

1.8

2

2.2

2.4

2.6

H (X)

Figure 8: For Îµ = 0.1 (left) the binary mechanism achieves the maximum I (X; Y ), which
scales as Equation (21). For Îµ = 10 (right) the randomized response mechanism
achieves the optimal mutual information, which scales as Equation (22).

output of the first mechanism Q is applied to another mechanism W . We say that a
utility function U (Â·) obeys the data processing inequality if the following inequality
holds for all Q and W
U (QW ) â‰¤ U (Q) .
The following proposition, proved in Section 10, shows that the class of utilities obeying the data processing inequality includes all the utility functions we studied in
Section 2.
Proposition
17 Any utility function that can be written in the form of U (Q) =
P
Âµ(Q
),
where
Âµ is any sublinear function, obeys the data processing inequality.
y
Y
2. We consider (Îµ, Î´)-differential privacy which generalizes the notion of Îµ-differential
privacy. (Îµ, Î´)-differential privacy is commonly referred to as approximate differential
privacy and it was first introduced in Dwork et al. (2006a). For the release of a random
variable X âˆˆ X , we say that a mechanism Q is (Îµ, Î´)-locally differentially private if

Q (S|x) â‰¤ eÎµ Q S|x0 + Î´,
(23)
for all S âŠ† Y and all x, x0 âˆˆ X . Note that Îµ-local differential privacy is a special case
of (Îµ, Î´)-local differential privacy where Î´ = 0.
3. We prove that the quaternary mechanism, defined in Equation (24), is optimal for any
Îµ and any Î´. This is different from the treatment conducted in the previous sections
where we proved the optimality of the binary (randomized response) mechanism for
sufficiently small (large) Îµ and Î´ = 0.
23

Kairouz, Oh and Viswanath

The treatment in this section, even though more general than the one in previous sections in
the ways described above, holds only for binary alphabets (i.e., |X | = 2). Finding optimal
privatization mechanisms under (Îµ, Î´)-local differential privacy for larger input alphabets
(i.e., |X | > 2) is an interesting open question. Unlike Îµ-local differential privacy, the privacy constraints under (Îµ, Î´)-local differential privacy no longer decompose into separate
constraints on each output y. This makes it difficult to generalize the techniques developed
in previous sections of this paper. However, for the special case of binary input alphabets,
we can prove the optimality of one mechanism for all values of (Îµ, Î´) and all utility functions
that obey the data processing inequality.
For a binary random variable X âˆˆ X = {0, 1}, the quaternary mechanism maps X to a
quaternary random variable Y âˆˆ Y = {0, 1, 2, 3} and is defined as


Î´ if x = 0 ,
0 if x = 0 ,
QQT (0|x) =
QQT (1|x) =
(24)
0 if x = 1 .
Î´ if x = 1 .

QQT (2|x) =

1
(1 âˆ’ Î´) 1+e
Îµ
eÎµ
(1 âˆ’ Î´) 1+eÎµ

if x = 0 ,
if x = 1 .


QQT (3|x) =

Îµ

e
(1 âˆ’ Î´) 1+e
Îµ
1
(1 âˆ’ Î´) 1+e
Îµ

if x = 0 ,
if x = 1 .

In other words, the quaternary mechanism passes X unchanged with probability Î´ and
applies the binary mechanism (defined in previous sections) with probability 1 âˆ’ Î´. The
main result of this section can be stated formally as follows.
Theorem 18 If |X | = 2, then for any Îµ, any Î´, and any U (Q) that obeys the data processing inequality, the quaternary mechanism maximizes U (Q) subject to Q âˆˆ D(Îµ,Î´) , the set of
all (Îµ, Î´)-locally differentially private mechanism.
The proof of Theorem 18 depends on an operational definition of differential privacy
which we describe next. Consider a privatization mechanism Q that maps X âˆˆ {0, 1}
stochastically to Y âˆˆ Y. Given Y , construct a binary hypothesis test on whether X = 0
or X = 1. Any binary hypothesis test is completely described by a, possibly randomized,
decision rule XÌ‚ : Y â†’ {0, 1}. The two types of error associated with XÌ‚ are false alarm:
XÌ‚ = 1 when X = 0, and miss detection: XÌ‚ = 0 when X = 1. The probability of false
alarm is given by PFA = P(XÌ‚ = 1|X = 0) while the probability of miss detection is given
by PMD = P(XÌ‚ = 0|X = 1). For a fixed Q, the convex hull of all pairs (PMD , PFA ) for all
decision rules XÌ‚ defines a two-dimensional error region where PMD is plotted against PFA .
For example, the quaternary mechanism given in Figure 9a has an error region RQQT shown
in Figure 9b.
It turns out that (Îµ, Î´)-local differential privacy imposes the following conditions on the
error region of all (Îµ, Î´)-locally differentially private mechanisms
PFA + eÎµ PMD â‰¥ 1 âˆ’ Î´ ,

and

eÎµ PFA + PMD â‰¥ 1 âˆ’ Î´ ,

for any decision rule XÌ‚. These two conditions define an error region RÎµ,Î´ shown in Figure
9b. Interestingly, the next theorem shows that the converse result is also true.
Theorem 19 A mechanism Q is (Îµ, Î´)-locally differentially private if and only if RQ âŠ†
RÎµ,Î´ .
24

Extremal Mechanisms for Local Differential Privacy

y=0

Î´

0

y=1

0

Î´

y=2

(1âˆ’Î´)eÎµ
1+eÎµ

(1âˆ’Î´)
1+eÎµ

PFA
1
1ï€­ï¤

0.5

1ï€­ï¤
1 ï€« eï¥

y=3

(1âˆ’Î´)
1+eÎµ

(1âˆ’Î´)eÎµ
1+eÎµ

RQQT = RÎµ,Î´

0

0

x=0 x=1
(a) Privatization mechanism

1ï€­ï¤
1 ï€« eï¥

0.5

1ï€­ï¤

PMD
1

(b) Error region

Figure 9: The quaternary mechanism
The proof of the above theorem can be found in Kairouz et al. (2013). Notice that it is no
coincidence that RQQT = RÎµ,Î´ . This property will be essential in proving the optimality of
the quaternary mechanism.
Theorem 19 allows us to benefit from the data processing inequality (DPI) and its
converse, which follows from a celebrated result by Blackwell (1953). These inequalities,
while simple by themselves, lead to surprisingly strong technical results. Indeed, there is a
long line of such a tradition in the information theory literature (see Chapter 17 of Cover
and Thomas (2012)). Consider two privatization mechanisms, Q(1) and Q(2) . Let Y and
Z denote the output of the mechanisms Q(1) and Q(2) , respectively. We say that Q(1)
dominates Q(2) if there exists a coupling of Y and Z such that Xâ€“Y â€“Z forms a Markov
chain. In other words, we say Q(1) dominates Q(2) if there exists a stochastic mapping Q
such that Q(2) = Q(1) â—¦ Q.
Theorem 20 A mechanism Q(1) dominates a mechanism Q(2) if and only if RQ(2) âŠ† RQ(1) .
The proof of the above theorem can be found in Blackwell (1953). Observe that by Theorems
20 and 19, and the fact that RQQT = RÎµ,Î´ , the quaternary mechanism dominates any other
differentially private mechanism. In other words, for any differentially private mechanism
Q, there exists a stochastic mapping W such that Q = W â—¦ QQT . Therefore, for any
(Îµ, Î´) and any utility function U (.) obeying the data processing inequality, we have that
U (Q) â‰¤ U (QQT ). This finishes the proof of Theorem 18.

6. Discussion
In this paper, we have considered a broad class of convex utility functions and assumed a
setting where individuals cannot collaborate (communicate with each other) before releasing
25

Kairouz, Oh and Viswanath

their data. It turns out that the techniques developed in this work can be generalized to find
optimal privatization mechanisms in a setting where different individuals can collaborate
interactively and each individual can be an analyst (Kairouz et al., 2014b).
Binary hypothesis testing and information preservation are two canonical problems with
a wide range of applications. However, there are a number of non-trivial and interesting
extensions to our work.
Correlation among data. In some scenarios the Xi â€™s could be correlated (e.g., when
different individuals observe different functions of the same random variable). In this case,
the data analyst is interested in inferring whether the data was generated from P0n or P1n ,
where PÎ½n is one of two possible joint priors on X1 , ..., Xn . This is a challenging problem because knowing Xi reveals information about Xj , j 6= i. Therefore, the utility maximization
problems for different individuals are coupled in this setting.
Robust and m-ary hypothesis testing. In some cases the data analyst need not have
access to P0 and P1 , but rather two classes of prior distribution PÎ¸0 and PÎ¸1 for Î¸0 âˆˆ Î›0 and
Î¸1 âˆˆ Î›1 . Such problems are studied under the rubric of universal hypothesis testing and
robust hypothesis testing. One possible direction is to select the privatization mechanism
that maximizes the worst case utility: Qâˆ— = arg maxQâˆˆDÎµ minÎ¸0 âˆˆÎ›0 ,Î¸1 âˆˆÎ›1 Df (MÎ¸0 ||MÎ¸1 ),
where MÎ¸Î½ is the induced marginal under PÎ¸Î½ .
The more general problem of private m-ary hypothesis testing is also an interesting
but challenging one. In this setting, the Xi â€™s can follow one of m distributions P0 , P1 , ...,
Pmâˆ’1 . Consequently, the Yi â€™s can follow one of m distributions M0 , M1 , ..., Mmâˆ’1 . The
utility
P can be defined as the average f -divergence between any two distributions: 1/(m(m âˆ’
1)) i6=j Df (Mi ||Mj ), or the worst case one: mini6=j Df (Mi ||Mj ).
Non-exchangeable utility functions. The utility studied in this paper was measured by
functions that are exchangeable, i.e. the utility did not depend on the naming (labelling) of
the private and privatized data (X and Y ). This made sense for statistical learning applications that depend on information theoretic quantities such as f -divergences and mutual
information. However, in some other applications, the utility might be defined over X âˆª Y
in a metric space, where there exists a natural measure of distance (or distortion) between
the data points. In this case, we can formulate the problem as a distortion minimization
one
minimizeQâˆˆDÎµ

X

d(x, y)P (x)Q(y|x) ,

x,y

where d(x, y) is some distortion metric. Wang et al. (2014a) studied this problem, and
showed that the mechanism Q(y|x) âˆ eÎµ(1âˆ’d(x,y)) /(k âˆ’ 1 + eÎµ ) achieves near optimal performance when Îµ is large enough, which is the low privacy regime. Notice that when Hamming
distance is used, d(x, y) = I(x 6= y), this recovers the randomized response mechanism
exactly. This provides a starting point for generalizing the search for optimal mechanisms
under non-exchangeable utility functions.
26

Extremal Mechanisms for Local Differential Privacy

7. Proof of Theorems 2 and 4
We start the proof with a few definitions, a lemma, and a general result that applies to any
convex utility function that obeys a mild assumption.
Recall that for an input alphabet X with |X | = k, we represent the set of Îµ-locally
differentially private mechanisms that lead to output alphabets Y with |Y| = ` by DÎµ,` . The
set of all Îµ-locally differentially private mechanisms is given by DÎµ = âˆª`âˆˆN DÎµ,` . A utility

function U (Q) is convex in Q if U Î»Q(1) + (1 âˆ’ Î») Q(2) â‰¤ Î»U Q(1) + (1 âˆ’ Î») U Q(2) for
any Î» âˆˆ (0, 1). Convex utility functions are ubiquitous in information theory and statistics.
Assumption 1 If a kÃ—` privatization mechanism Q(1) âˆˆ DÎµ,` is obtained by deleting
an all

zero column of a k Ã— ` + 1 privatization mechanism Q(2) âˆˆ DÎµ,`+1 , then U Q(1) = U Q(2) .
Naturally, one would expect that if we delete the zero columns of a privatization mechanism
Q(2) to obtain a new privatization mechanism Q(1) , we would still get the same utility. This
is because a â€œreasonableâ€ utility function should not depend on output alphabets with zero
probability.
Theorem 21 If U (Q) is a convex utility function that satisfies Assumption 1, then the
following holds
max U (Q) = max U (Q) .
QâˆˆDÎµ

Qâˆˆâˆªk`=1 DÎµ,`

This theorem implies that among all Îµ-locally differentially private mechanisms, we only
need to consider those that lead to output alphabets of size ` â‰¤ k. In other words, enlarging
the input alphabet cannot further maximize the utility. The proof of Theorem 21 is given
in Section 7.1.
Lemma 22 A k Ã— ` conditional distribution Q is Îµ-locally differentially private if and only
if it can be written as Q = SÎ˜, where S is a k Ã— ` matrix with Sij âˆˆ [1, eÎµ ] and Î˜ =
diag (Î¸1 , . . . , Î¸` ) with its diagonal entries in R+ .
The proof of Lemma 22 is provided in Section 7.2. With the above results, we are now
ready to prove Theorems
2 and 4. By Lemma 22, for any Q âˆˆ DÎµ,` we have that Qj = Î¸j Sj .
P
Suppose U (Q) = jâˆˆ[`] Âµ(Qj ), where Âµ is a sublinear function. Since Âµ is sublinear, it is
convex and Âµ (Î¸j Sj ) = Î¸j Âµ (Sj ). U (Q) is convex in Q because



X  (1) (1)
(2) (2)
U Î»Q(1) + (1 âˆ’ Î») Q(2)
=
Âµ Î»Î¸j Sj + (1 âˆ’ Î») Î¸j Sj
jâˆˆ[`]

â‰¤

X





(1) (1)
(2) (2)
Î»Âµ Î¸j Sj
+ (1 âˆ’ Î») Âµ Î¸j Sj

jâˆˆ[`]





= Î»U Q(1) + (1 âˆ’ Î») U Q(2) ,

(25)

for any Î» âˆˆ (0, 1). Furthermore, U (Q) satisfies Assumption 1 because Âµ (Qj ) = 0 whenever
Î¸j = 0. Let Qâˆ— = S âˆ— Î˜âˆ— âˆˆ arg maxQâˆˆâˆªk DÎµ,` U (Q) and note that by Theorem 21, U (Qâˆ— ) =
`=1

27

Kairouz, Oh and Viswanath

maxQâˆˆDÎµ U (Q). Suppose that Qâˆ— is of dimensions k Ã—`, where ` â‰¤ k. Each of the ` columns
of Qâˆ— can be expressed as a convex combination of the columns of S (k) , the staircase pattern
matrix. This is because the 2k columns of S (k) are the corner points of the cube [1, eÎµ ]k
Pk
(k)
and each Sjâˆ— âˆˆ [1, eÎµ ]k . Therefore, Sjâˆ— = 2i=1 Î»ij Si , where Î»ij â‰¥ 0 for all i and j, and
P2k
P`
âˆ—
k
j=1 Î»ij Î¸j and
i=1 Î»ij = 1 for all j. Create the 2 -dimensional vector Î¸Ìƒ such that Î¸Ìƒi =
let QÌƒ = S (k) Î˜Ìƒ.
ï£«ï£«
ï£¶
ï£¶
`
2k
`
X
X
X

(k)
U (Qâˆ— ) âˆ’ U (QÌƒ) =
Âµ Sjâˆ— Î¸jâˆ— âˆ’
Âµ ï£­ï£­
Î»ij Î¸jâˆ— ï£¸ S ï£¸
j

j=1

=

`
X

j=1

ï£«
ï£¶
2k
2k X
`


X
X
(k)
(k)
âˆ—
Âµï£­
Î»ij S ï£¸ Î¸j âˆ’
Î»ij Î¸jâˆ— Âµ S
i

j=1

=

i=1

`
X
j=1

i=1

j

i=1 j=1

ï£± ï£«
ï£¼
ï£¶
2k
2k
ï£²

ï£½
X
X
(k)
(k)
Î¸jâˆ— Âµ ï£­
Î»ij Si ï£¸ âˆ’
Î»ij Âµ Sj
ï£³
ï£¾
i=1

i=1

â‰¤ 0,

(26)

by the convexity of Âµ (z) and the non-negativity of Î¸jâˆ— â€™s. Moreover, observe that since
S (k) Î¸Ìƒ = 1, Î¸Ìƒ is a valid choice for the linear program of (11). This implies that
max
S (k) Î¸=1,Î¸â‰¥0

2k


X
(k)
Âµ Sj
Î¸j â‰¥ U (QÌƒ) â‰¥ U (Qâˆ— ) = max U (Q)
QâˆˆDÎµ

j=1

On the other hand, for any QÌƒ = S (k) Î˜Ìƒ, where Î¸Ìƒ is valid for thelinear program of (11), we
Pk
(k)
Î¸j â‰¤ maxQâˆˆD U (Q).
have that QÌƒ âˆˆ DÎµ,2k âŠ‚ DÎµ and therefore, maxS (k) Î¸=1,Î¸â‰¥0 2j=1 Âµ Sj


P2k
(k)
Î¸j = maxQâˆˆD U (Q). This proves Theorem 4.
Thus, maxS (k) Î¸=1,Î¸â‰¥0 j=1 Âµ Sj
The polytope given by S (k) Î¸ = 1 and Î¸ â‰¥ 0 is a closed and bounded one. Thus, the
linear program of (11) is bounded and has a solution, say Î¸âˆ— , at one of the corner points of
the polytope. Since there are k equality constraints given by S (k) Î¸ = 1 and 2k inequality
constraints given by Î¸ â‰¥ 0, any corner point, including Î¸âˆ— , cannot have more than k nonzero entries. Form SÌƒ by deleting the columns of S (k) corresponding to zero entries of Î¸âˆ— .
Similarly, form Î¸Ìƒ by deleting the zero entries of Î¸âˆ— and let QÌƒ = SÌƒ Î˜Ìƒ, where Î˜Ìƒ = diagÎ¸Ìƒ.
It is easy to verify that U (QÌƒ) = U (Qâˆ— ) = ÂµT Î¸âˆ— ; hence, QÌƒ solves linear program of (11).
Moreover, QÌƒ has at most k columns and SÌƒij = {1, eÎµ }. Therefore, QÌƒ is a staircase mechanism
of dimension k Ã— `, where ` â‰¤ k.
7.1 Proof of Theorem 21
We start the proof of Theorem 21 with an important lemma the proof of which is presented
in Section 7.3.
Lemma 23 The set of all k Ã— `, Îµ-locally differentially private mechanisms DÎµ,` forms a
closed and bounded polytope in Rk`
+ . Moreover, let Q be a corner point of the polytope formed
by DÎµ,` , then Q has at most k non-zero columns.
28

Extremal Mechanisms for Local Differential Privacy

Fix an ` > k. Since U (Q) is convex in Q, it suffices to consider the corner points of
DÎµ,` when maximizing U (Q) subject to Q âˆˆ DÎµ,` . By Lemma 23, any Q(1) , a k Ã— ` corner
point of DÎµ,` , has at most k non-zero columns. Therefore, the privatization mechanism
Q(2) , obtained by deleting the all-zero columns of Q(1) , has at most k columns.
Notice that

(2)
k
(1)
Q âˆˆ âˆªi=1 DÎµ,i . Since U (Q) satisfies Assumption 1, we have that U Q
= U Q(2) and
k
therefore, it suffices to consider Q âˆˆ âˆªi=1 DÎµ,i when maximizing U (Q) subject to Q âˆˆ DÎµ,` .
Thus,


sup U (Q) = sup max U (Q)
QâˆˆDÎµ

QâˆˆDÎµ,`

`âˆˆN

(
= sup
`âˆˆN

=

)
max

Qâˆˆâˆªki=1 DÎµ,i

max

Qâˆˆâˆªki=1 DÎµ,i

U (Q)

U (Q) ,

(27)

which finishes the proof.
7.2 Proof of Lemma 22
Claim 1 Let Q âˆˆ DÎµ,` . If Qij = 0 for some j âˆˆ {1, ..., `} then Qij = 0 for all i âˆˆ {1, ..., k}.
Proof Assume that Qi1 j = 0 and Qi2 j 6= 0 for some i1 , i2 âˆˆ {1, ..., k}. It is obvious that
q (yj |xi2 ) â‰¤ q (yj |xi1 ) eÎµ is not satisfied. Therefore, Q is not a locally differentially private
mechanism.
It is easy to check that any k Ã— ` stochastic matrix Q = SÎ˜, where Î˜ is a diagonal
matrix with non-negative entries and S is a k Ã— ` matrix with Sij âˆˆ [1, eÎµ ], satisfies the local
differential privacy constraints. Thus, Q âˆˆ DÎµ,` . On the other hand, assume that Q âˆˆ DÎµ,` .
If Qij = 0 for some j then by Claim 1 we have that Qij = 0 for all i and therefore, we
can set Î¸j = 0 and Sij = 1 for all i. If Qij > 0 then by Claim 1 we have that Qij > 0
for all i. In this case, let Î¸j = mini Qij and observe that Î¸j > 0 since Qij > 0 for all i.
Let Sij = Qij /Î¸i , then it is clear (from the definition of Î¸i ) that Sij â‰¥ 1. On the other
hand, from the differential privacy constraints, we have that Qij â‰¤ Qkj eÎµ for all k and thus,
Qij â‰¤ mink Qkj eÎµ which proves that Sij = Qij / mink Qkj â‰¤ eÎµ . This establishes that any
Q âˆˆ DÎµ,` can be written as Q = SÎ˜, where Î˜ is a diagonal matrix with non-negative entries
and S is a k Ã— ` matrix with Sij âˆˆ [1, eÎµ ].
7.3 Proof of Lemma 23
We start by showing that DÎµ,` forms a closed and bounded polytope in Rk`
+ . We are interested
in studying the corner points of the polytope formed by DÎµ,` because convex utility functions
are maximized at one of these corner points whenever the space of privatization mechanisms
is restricted to DÎµ,` .
Claim 2 A privatization mechanism Q âˆˆ DÎµ,` if and only if for all x, x0 âˆˆ X and all y âˆˆ Y
we have that Q (y|x) â‰¤ Q (y|x0 ) eÎµ .
29

Kairouz, Oh and Viswanath

Proof By definition, Q is differentially private if for all x, x0 âˆˆ X and all B âŠ† Y we have
that Q (B|x) â‰¤ Q (B|x0 ) eÎµ . By choosing B = {y} for some y âˆˆ Y the first direction of the
above lemma is proven. In order to prove the other direction, assume that for all x, x0 âˆˆ X
and all y âˆˆ Y we have that Q (y|x) â‰¤ Q (y|x0 ) eÎµ . Then for any B âŠ† Y, the following holds
X
X

Q (y|x) â‰¤
Q y|x0 eÎµ
(28)
yâˆˆB

yâˆˆB


â‡” Q (B|x) â‰¤ Q B|x0 eÎµ .

Let Q âˆˆ DÎµ,` , then by Claim 2, it is easy to see that Q must satisfy `k(k âˆ’ 1) inequalities
of the form Q (y|x) â‰¤ Q (y|x0 ) eÎµ . These inequalities can be compactly represented by
AÌƒq â‰¤ 0,
where q = [Q (y1 |x1 ) , ..., Q (y1 |xk ) , ...., Q (y` |x1 ) , ..., Q (y` |xk )]T and AÌƒ is a `k(k âˆ’ 1) Ã— k`
matrix that contains all the local differential privacy linear constraints. Observe that there
is a one-to-one mapping between Q and q. Here is an example for the case when k = ` = 2
ï£¹ï£®
ï£®
ï£¹
1 âˆ’eÎµ
0
0
Q (y1 |x1 )
ï£¯ âˆ’eÎµ
ï£º
ï£¯
1
0
0 ï£º
ï£º ï£¯ Q (y1 |x2 ) ï£º â‰¤ 0.
ï£¯
Îµ
ï£»
ï£° 0
ï£°
0
1 âˆ’e
Q (y2 |x1 ) ï£»
Îµ
Q (y2 |x2 )
0
0 âˆ’e
1
|
{z
}
AÌƒ

Moreover, since Q is a row stochastic matrix (a conditional distribution) it satisfies Q1 = 1,
where 1 represents the all ones vector of appropriate dimensions. This condition can be
rewritten as
Bq = 1,
where B is a k Ã— k` binary matrix. For the case when k = ` = 2, we have that
ï£®
ï£¹

 Q (y1 |x1 )
 
ï£º
1 0 1 0 ï£¯
ï£¯ Q (y1 |x2 ) ï£º = 1 .
0 1 0 1 ï£° Q (y2 |x1 ) ï£»
1
|
{z
} Q (y |x )
2

B

2

Finally, observe that Q (y|x) â‰¥ 0 for all x âˆˆ X and y âˆˆ Y. These constraints can be
h
iT
incorporated as follows. Let A = AÌƒT , âˆ’I`k , where I`k is the `k Ã— `k identity matrix,
then Aq â‰¤ 0. To summarize, Q âˆˆ DÎµ,` if and only if
Aq â‰¤ 0

(29)

Bq = 1.
Therefore, the set of all k Ã—`, Îµ-locally differentially private mechanisms DÎµ,` forms a convex
polytope in Rk`
+.
30

Extremal Mechanisms for Local Differential Privacy

We now proceed to proving that if Q is a corner point of the polytope formed by DÎµ,` ,
then Q has at most k non-zero columns. This claim is obvious for all k Ã— ` privatization
mechanisms with ` â‰¤ k. Therefore, we restrict our attention to the case where ` > k. Let
Aj be the matrix including all the inequality constraints imposed on the j th column of Q.
Observe that the rows of Aj form a subset of the rows of A, defined in (29), and recall that
there are k(k âˆ’ 1) differential privacy and k non-negativity inequality constraints imposed
on the j th column of Q. Therefore, Aj is a k 2 Ã— k matrix and we have that Aj Qj â‰¤ 0, where
Qj represents the j th column of Q. By Claim 1, we know that Qj is either equal to zero or
contains non-zero entries.
Claim 3 In what follows, the term linearly independent inequality constraints refers to
linear independent rows of Aj .
â€¢ If Qj = 0, then k linearly independent inequality constraints are achieved with equality.
â€¢ If Qj 6= 0, then at most kâˆ’1 linearly independent inequality constraints can be achieved
with equality.
Proof In fact, the number of linearly independent inequality constraints (achieved or not)
cannot exceed k because Aj has a rank less than or equal to k. If Qj = 0, then the k
non-negativity inequality constraints are achieved with equality and it is easy to see that
they are all linearly independent (in fact, they form an orthonormal basis to Rk ). This
proves the first part of the claim. We now establish the second part of the claim by showing that if Qj 6= 0, we cannot have k linearly independent inequality constraints achieved
with equality. Assume that Qj 6= 0 and let AÌƒj be the matrix including the largest collection of linearly independent rows of Aj corresponding to the inequality constraints that are
achieved with equality. In other words, AÌƒj Qj = 0. If AÌƒj contains k rows, then its rank is
equal to k. However, this implies that Qj = 0, a contradiction. Therefore, at most k âˆ’ 1
linearly independent inequality constraints can be achieved with equality when Qj 6= 0.
Suppose that Q is a corner point of DÎµ,` and out of its ` columns, `>0 are non-zero and
`=0 (`=0 = ` âˆ’ `>0 ) are zero. Moreover, assume that the number of non-zero columns of Q is
larger than k (i.e., `>0 > k). In this case, from Claim 3, we can see that Q achieves at most
`>0 (kâˆ’1)+(`âˆ’`>0 )k linearly independent inequality constraints with equality. Furthermore,
at most k additional linearly independent equality constraints (linearly independent rows
of the matrix B defined in (29)) can be met by Q. Therefore, the total number of linearly
independent constraints that Q achieves with equality is at most `>0 (kâˆ’1)+(`âˆ’`>0 )k+k =
âˆ’`>0 + (` + 1)k < `k, where the last strict inequality follows from the fact that `>0 > k.
This implies that Q cannot be a corner point of DÎµ,` . Therefore, any corner point of DÎµ,`
must have at most k non-zero columns.

8. Proofs for Hypothesis Testing
8.1 Proof of Theorem 5
Let T = {x : P0 (x) â‰¥ P1 (x)}. In other words, P0 (T ) âˆ’ P1 (T ) = maxAâŠ†X P0 (A) âˆ’ P1 (A).
Recall that for a given P0 and P1 , the binary mechanism is defined as a staircase mechanism
31

Kairouz, Oh and Viswanath

with only two outputs y âˆˆ {0, 1} satisfying

Q(0|x) =

eÎµ
1+eÎµ
1
1+eÎµ

if P0 (x) â‰¥ P1 (x) ,
if P0 (x) < P1 (x) .


Q(1|x) =

eÎµ
1+eÎµ
1
1+eÎµ

if P0 (x) < P1 (x) ,
if P0 (x) â‰¥ P1 (x) .

(30)

Lemma 24 For any pair of distributions P0 and P1 , there exists a positive Îµâˆ— that depends
on P0 and P1 such that for all y âˆˆ Y, all ` âˆˆ N, and all Q âˆˆ DÎµ,` with Îµ â‰¤ Îµâˆ— , we have that
(eÎµ âˆ’ 1) P0 (T c ) + 1
M0 (y)
(eÎµ âˆ’ 1) P0 (T ) + 1
â‰¤
â‰¤
.
(eÎµ âˆ’ 1) P1 (T c ) + 1
M1 (y)
(eÎµ âˆ’ 1) P1 (T ) + 1
Moreover, the above upper and lower bounds are achieved by the binary mechanism given
in (30).
Observe that because P0 (T ) â‰¥ P1 (T ) and P0 (T c ) â‰¤ P1 (T c ), the direction of the above
inequalities makes sense.
Let MÌƒÎ½ be the induced marginal for the binary mechanism when PÎ½ is the original
distribution. Following the analysis techniques developed in Kairouz et al. (2013), we define
hypothesis testing region R(MÌƒ0 , MÌƒ1 ) as the convex hull of all achievable probabilities of
missed detection and false alarm, when testing whether Î½ = 0 or Î½ = 1 based on Ybin
distributed as MÌƒÎ½ :


R(MÌƒ0 , MÌƒ1 ) â‰¡ conv (MÌƒ1 (S), MÌƒ0 (S c )) : âˆ€S âŠ† Y
,
where S âˆˆ Y is the accept region for hypothesis Î½ = 0. For the binary mechanism, this
ends up being a very simple triangular region. The slopes defining the two sides of the
triangular region are: âˆ’ maxS MÌƒ0 (S)/MÌƒ1 (S) = âˆ’((eÎµ âˆ’ 1)P0 (T ) + 1)/((eÎµ âˆ’ 1)P1 (T ) + 1)
and âˆ’ minS MÌƒ0 (S c )/MÌƒ1 (S c ) = âˆ’((eÎµ âˆ’ 1)P0 (T c ) + 1)/((eÎµ âˆ’ 1)P1 (T c ) + 1).
For any other mechanism satisfying the Îµ-local differential privacy for Îµ â‰¤ Îµâˆ— , the
above lemma implies that for any choice of the rejection region S, the slopes satisfy
âˆ’M0 (S)/M1 (S) â‰¥ âˆ’((eÎµ âˆ’ 1)P0 (T ) + 1)/((eÎµ âˆ’ 1)P1 (T ) + 1) and âˆ’M0 (S c )/M1 (S c ) â‰¤
âˆ’((eÎµ âˆ’ 1)P0 (T c ) + 1)/((eÎµ âˆ’ 1)P1 (T c ) + 1). In the hypothesis testing region, this implies
that
R(M0 , M1 ) âŠ† R(MÌƒ0 , MÌƒ1 ) ,
as in the following Figure 10.
From Theorem 2.5 of Kairouz et al. (2013), we know that this implies a certain Markov
property. Precisely, let Ybin denote the output of the binary mechanism, and Ydp denote the
output of any Îµ-local differentially private mechanism. Then, it follows that there exists a
coupling of Ybin and Ydp such that they form a Markov chain: Î½â€“Ybin â€“Ydp , where Î½ is the
hypothesis on PÎ½ whether the data was generated from Î½ = 0 or Î½ = 1. Then, it follows
from the data processing inequality of f -divergences that
Df (MÌƒ0 , MÌƒ1 ) â‰¥ Df (M0 , M1 ) .
It follows that there is no algorithm with larger f -divergence than the binary mechanism.
32

Extremal Mechanisms for Local Differential Privacy

MÌƒ0 (S c )

R(MÌƒ0 , MÌƒ1 )

R(M0 , M1 )

MÌƒ1 (S)

Figure 10: Hypothesis testing regions for two mechanisms.
8.2 Proof of Lemma 24
We start by showing that the binary mechanism achieves the upper and lower bounds
presented in the statement of the lemma. Let M0B and M1B denote the induced marginals
under the binary mechanism given in (30). For Î½ âˆˆ {0, 1}, we have that
MÎ½B (0) =

X

P0 (x) Q(0|x) =

xâˆˆX

MÎ½B (1) =

X

P0 (x) Q(1|x) =

xâˆˆX

1
((eÎµ âˆ’ 1) PÎ½ (T ) + 1)
eÎµ + 1
1
eÎµ + 1

((eÎµ âˆ’ 1) PÎ½ (T c ) + 1) .

(31)

Computing M0B (0) /M1B (0) and M0B (1) /M1B (1) we see that the binary mechanism achieves
the upper and lower bounds for all values of Îµ.
As in Lemma 22, for any ` âˆˆ N, Q âˆˆ DÎµ,` can be represented as Q = SÎ˜, where
S âˆˆ [1, eÎµ ]kÃ—` and Î˜ = diag (Î¸1 , ..., Î¸` ) with its diagonal entries in R+ . We now show that
for any ` âˆˆ N and any Q âˆˆ DÎµ,` , the following upper bound holds
P
M0 (y)
(eÎµ âˆ’ 1) P0 (T ) + 1
iâˆˆ[k] P0 (xi ) Sij
=P
â‰¤ Îµ
,
M1 (y)
(e âˆ’ 1) P1 (T ) + 1
iâˆˆ[k] P1 (xi ) Sij
33

Kairouz, Oh and Viswanath

for all y âˆˆ Y and sufficiently small Îµ. The above expression can be alternatively written as
X
(Sij âˆ’ 1) (P0 (T ) P1 (xi ) âˆ’ P1 (T ) P0 (xi ))
(eÎµ âˆ’ 1) (P0 (T ) âˆ’ P1 (T )) + (eÎµ âˆ’ 1)
iâˆˆ[k]

âˆ’

X

(Sij âˆ’ 1) (P0 (xi ) âˆ’ P1 (xi )) â‰¥ 0,

(32)

iâˆˆ[k]

where Sj âˆˆ [1, eÎµ ]k . Equation (32) is linear in Sj and is therefore minimized (and maximized)
at the corner points of [1, eÎµ ]kÃ—` , a cube in RkÃ—`
+ . The corner points of this cube are given
Îµ
k
by the staircase patterns: Sj âˆˆ {1, e } . To begin with, let Sj be a staircase pattern with
Tj = {xi : Sij = eÎµ } =
6 T . Then Equation (32) is equivalent to
(eÎµ âˆ’ 1) {(P0 (T ) âˆ’ P1 (T )) âˆ’ (P0 (Tj ) âˆ’ P1 (Tj ))}
+ (eÎµ âˆ’ 1)2 {P0 (T ) P1 (Tj ) âˆ’ P1 (T ) P0 (Tj )} â‰¥ 0. (33)
Using the fact that P0 (T ) âˆ’ P1 (T ) > P0 (Tj ) âˆ’ P1 (Tj ) for all Tj 6= T , the inequality
in (32) holds true for all Îµ whenever P0 (T ) P1 (Tj ) â‰¥ P1 (T ) P0 (Tj ). If P0 (T ) P1 (Tj ) <
P1 (T ) P0 (Tj ), then the inequality in (32) holds true for all Îµ â‰¤ Îµ(j), where


(P0 (T ) âˆ’ P1 (T )) âˆ’ (P0 (Tj ) âˆ’ P1 (Tj ))
Îµ(j) = log
+ 1 > 0.
P1 (T ) P0 (Tj ) âˆ’ P0 (T ) P1 (Tj )
On the other hand, it is easy to verify that when Tj = T , we have that
(eÎµ âˆ’ 1) {(P0 (T ) âˆ’ P1 (T )) âˆ’ (P0 (Tj ) âˆ’ P1 (Tj ))
+ (eÎµ âˆ’ 1) (P0 (T ) P1 (Tj ) âˆ’ P1 (T ) P0 (Tj ))} = 0, (34)
for all Îµ. In this case, set Îµ(j) = 0 and Îµ1 = minjâˆˆ[2k ] Îµ(j). Therefore, for any ` âˆˆ N and
any Q âˆˆ DÎµ,` , the upper bound in the statement of the lemma holds for all Îµ â‰¤ Îµ1 .
We now show that for for any ` âˆˆ N and any Q âˆˆ DÎµ,` , the following lower bound holds
P
(eÎµ âˆ’ 1) P0 (T c ) + 1
M0 (y)
iâˆˆ[k] P0 (xi ) Sij
P
â‰¤
=
,
(eÎµ âˆ’ 1) P1 (T c ) + 1
M1 (y)
iâˆˆ[k] P1 (xi ) Sij
for all y âˆˆ Y and sufficiently small Îµ. The above expression can be alternatively written as
X
(eÎµ âˆ’ 1) (P0 (T ) âˆ’ P1 (T )) + (eÎµ âˆ’ 1)
(Sij âˆ’ 1) (P0 (T ) P1 (xi ) âˆ’ P1 (T ) P0 (xi ))
iâˆˆ[k]

+eÎµ

X

(Sij âˆ’ 1) (P0 (xi ) âˆ’ P1 (xi )) â‰¥ 0,

(35)

iâˆˆ[k]

where Sj âˆˆ [1, eÎµ ]k . Equation (35) is linear in Sj and is therefore minimized at the corner
points of [1, eÎµ ]k , a cube in Rk+ . The corner points of this cube are given by staircase
patterns: Sj âˆˆ {1, eÎµ }k . To begin with, let Sj be a staircase pattern with Tj = {xi : Sij =
eÎµ } =
6 T c , then Equation (35) is equivalent to
(eÎµ âˆ’ 1) {(P0 (T ) âˆ’ P1 (T )) + eÎµ (P0 (Tj ) âˆ’ P1 (Tj ))}
+ (eÎµ âˆ’ 1)2 {P0 (T ) P1 (Tj ) âˆ’ P1 (T ) P0 (Tj )} â‰¥ 0.(36)
34

Extremal Mechanisms for Local Differential Privacy

Using the fact that P0 (T ) âˆ’ P1 (T ) > P1 (Tj ) âˆ’ P0 (Tj ) for all Tj 6= T c , then for sufficiently
small Îµ, Equation (35) can be written as

Îµ {(P0 (T ) âˆ’ P1 (T )) âˆ’ (P1 (Tj ) âˆ’ P0 (Tj ))} + O Îµ2 > 0.
This proves that there exists a positive Îµ(j) such that the left hand side of Equation (36)
is positive for all Îµ â‰¤ Îµ(j). On the other hand, it is easy to verify that when Tj = T c , we
have that
(eÎµ âˆ’ 1) {(P0 (T ) âˆ’ P1 (T )) + eÎµ (P0 (Tj ) âˆ’ P1 (Tj ))
+ (eÎµ âˆ’ 1) (P0 (T ) P1 (Tj ) âˆ’ P1 (T ) P0 (Tj ))} = 0, (37)
for all Îµ. In this case, let Îµ(j) = 0 and let Îµ2 = minjâˆˆ[2k ] Îµ(j). Therefore, for any ` âˆˆ N
and any Q âˆˆ DÎµ,` , the lower bound in the statement of the lemma holds for all Îµ â‰¤ Îµ2 . To
conclude, let Îµâˆ— = min(Îµ1 , Îµ2 ). Then both, the upper and lower bounds, hold for all Îµ â‰¤ Îµâˆ— .
8.3 Proof of Theorem 6
The total variation (TV) distance kM0 âˆ’M1 kTV is a special case of f -divergence Df (M0 ||M1 )
with f (x) = 21 |x âˆ’ 1|. Therefore, by Theorem 4, we have that
max M0 âˆ’ M1 TV =

maximize

QâˆˆDÎµ

Î¸

ÂµT Î¸

subject to S (k) Î¸ = 1

(38)

Î¸ â‰¥ 0,


(k)

where Âµj = Âµ Sj



= 21

(k)
iâˆˆ[k] (P0 (xi ) âˆ’ P1 (xi )) Sij

P

for j âˆˆ {1, . . . , 2k } and S (k) is the

k Ã— 2k staircase pattern matrix given in Definition 3.
The polytope given by S (k) Î¸ = 1 and Î¸ â‰¥ 0 is a closed and bounded one. Thus, there is
no duality gap and solving the above linear program is equivalent to solving its dual
minimize
Î±

1T Î±
T

(39)

subject to S (k) Î± â‰¥ Âµ.
Note that any satisfiable solution Î±âˆ— to (39) provides an upper bound to (38) since max ÂµT Î¸ =
(k)
min 1T Î± â‰¤ 1T Î±âˆ— . Let T = {x : P0 (x) â‰¥ P1 (x)} and Tj = {xi : Sij = eÎµ } for j âˆˆ [2k ]. Consider the following choice of dual variable
Î±iâˆ— =

1 eÎµ âˆ’ 1
P0 (xi ) âˆ’ P1 (xi ) ,
2 eÎµ + 1

for i âˆˆ [k]. Observe that
1T Î± âˆ— =

1 eÎµ âˆ’ 1 X
P0 (xi ) âˆ’ P1 (xi )
2 eÎµ + 1
iâˆˆ[k]

=
=

1 eÎµ âˆ’ 1

P0 âˆ’ P1 1
2 eÎµ + 1
eÎµ âˆ’ 1
P0 âˆ’ P1 TV .
eÎµ + 1
35

(40)

Kairouz, Oh and Viswanath

We claim that Î±âˆ— is a feasible dual variable for all values of Îµ. In order to prove that Î±âˆ— is
T
a feasible dual variable, we show that S (k) j Î±âˆ— âˆ’ Âµj â‰¥ 0 for all j âˆˆ [2k ] and all Îµ. For all
j âˆˆ [2k ], we have that


T
gj = 2 S (k) j Î±âˆ— âˆ’ Âµj
=

=

X
eÎµ âˆ’ 1 X
(k)
(k)
|P
(x
)
âˆ’
P
(x
)|
S
âˆ’
(P0 (xi ) âˆ’ P1 (xi )) Sij
0
i
1
i
ij
Îµ
e +1
iâˆˆ[k]
iâˆˆ[k]
ï£±
ï£¼
ï£²
ï£½
Îµ
X
X
e âˆ’1
(k)
(k)
(P0 (xi ) âˆ’ P1 (xi )) Sij +
(P1 (xi ) âˆ’ P0 (xi )) Sij
ï£¾
eÎµ + 1 ï£³
c
xi âˆˆT

X

âˆ’

xi âˆˆT

(k)

X

(P0 (xi ) âˆ’ P1 (xi )) Sij âˆ’

(k)

(P1 (xi ) âˆ’ P0 (xi )) Sij

.

(41)

xi âˆˆT c

xi âˆˆT

Notice that we have arranged the equation such that all the summands are non-negative.
Without loss of generality, we will assume that
X
X
(k)
(k)
(P0 (xi ) âˆ’ P1 (xi )) Sij â‰¥
(P1 (xi ) âˆ’ P0 (xi )) Sij .
xi âˆˆT c

xi âˆˆT

From the equality

P

xi âˆˆT (P0 (xi ) âˆ’ P1 (xi )) =

P

xi âˆˆT c (P1 (xi ) âˆ’ P0 (xi )) and the fact that

(k)
Sij âˆˆ {1, eÎµ } for all i and j, it follows that

eâˆ’Îµ

X

(k)

X

(P0 (xi ) âˆ’ P1 (xi )) Sij â‰¤

(k)

(P1 (xi ) âˆ’ P0 (xi )) Sij .

(42)

xi âˆˆT c

xi âˆˆT

(k)

This is true because the right-hand side is minimized when the Sij â€™s for xi âˆˆ T c are all
(k)

equal to 1 and the left-hand side is maximized when the Sij â€™s for xi âˆˆ T are all equal to
eÎµ . Now, (41) can be written as
ï£±
ï£¼
ï£²
ï£½
X
X
1
(k)
(k)
gj = Îµ
âˆ’2
(P0 (xi ) âˆ’ P1 (xi )) Sij + 2eÎµ
(P1 (xi ) âˆ’ P0 (xi )) Sij
ï£¾
e +1ï£³
c
xi âˆˆT

xi âˆˆT

â‰¥ 0,
where the last inequality follows from (42).
This establishes the satisfiability of Î±âˆ— for all Îµ which, in turn, shows that (40) is indeed
an upper bound to the primal problem. It remains to show that this upper bound can be
achieved via the binary mechanism. To this extent, recall that for a given P0 and P1 , the
binary mechanism is defined as a staircase mechanism with only two outputs y âˆˆ {0, 1}
satisfying
 eÎµ
 eÎµ
if P0 (x) â‰¥ P1 (x) ,
if P0 (x) < P1 (x) ,
Îµ
1+e
1+eÎµ
Q(0|x) =
Q(1|x) =
(43)
1
1
if
P
(x)
<
P
(x)
.
if P0 (x) â‰¥ P1 (x) .
0
1
1+eÎµ
1+eÎµ
36

Extremal Mechanisms for Local Differential Privacy

Computing the TV distance between M0 and M1 under (43), we get that
M0 âˆ’ M1 TV =

eÎµ âˆ’ 1
P0 âˆ’ P1 TV .
eÎµ + 1

Hence, the binary mechanism in (43) achieves the upper bound in (40). This proves the
optimality of the binary mechanism for all Îµ.
8.4 Proof of Theorem 8
The Kullback-Leibler (KL) divergence Dkl (M0 ||M1 ) is a special f -divergence Df (M0 ||M1 )
with f (x) = x log x. Therefore, by Theorem 4, we have that
max Dkl (M0 ||M1 ) =

ÂµT Î¸

maximize

QâˆˆDÎµ

Î¸

subject to S (k) Î¸ = 1

(44)

Î¸ â‰¥ 0,

where Âµj = Âµ



(k)
Sj



=

P

(k)
iâˆˆ[k] P0 (xi )Sij log

P

(k)
iâˆˆ[k] P0 (xi )Sij
P
(k)
iâˆˆ[k] P1 (xi )Sij



for j âˆˆ {1, . . . , 2k } and S (k)

is the k Ã— 2k staircase pattern matrix given in Definition 3.
The polytope given by S (k) Î¸ = 1 and Î¸ â‰¥ 0 is a closed and bounded one. Thus, there is
no duality gap and solving the above linear program is equivalent to solving its dual
minimize
Î±

1T Î±

subject to S

(k) T

(45)
Î± â‰¥ Âµ.

Note that any satisfiable solution Î±âˆ— to (45) provides an upper bound to (44) since max ÂµT Î¸ =
(k)
min 1T Î± â‰¤ 1T Î±âˆ— . Let T = {x : P0 (x) â‰¥ P1 (x)} and Tj = {xi : Sij = eÎµ } for j âˆˆ [2k ]. Set
ji = {j : Tj = xi } for i âˆˆ [k], and consider the following choice of dual variable
ï£±
ï£¼
ï£²
ï£½




X
1
(k)
(k)
Îµ
Î±iâˆ— = Îµ
(e
+
k
âˆ’
2)
Âµ
S
âˆ’
Âµ
S
,
ji
jl
ï£¾
(e âˆ’ 1) (eÎµ + k âˆ’ 1) ï£³
lâˆˆ[k],l6=i

for i âˆˆ [k]. Observe that since Tji = xi we have that PÎ½ (Tji ) = PÎ½ (xi ) and since
ï£«P

Âµj

ï£¶
(k)
P
(x
)S
iâˆˆ[k] 0 i ij ï£¸
(k)
=
P0 (xi )Sij log ï£­ P
(k)
iâˆˆ[k] P1 (xi )Sij
iâˆˆ[k]
X

= (P0 (Tj ) (eÎµ âˆ’ 1) + 1) log
37

(P0 (Tj ) (eÎµ âˆ’ 1) + 1)
(P1 (Tj ) (eÎµ âˆ’ 1) + 1)

(46)

Kairouz, Oh and Viswanath

we have that
1T Î±âˆ— =

=

=
=

ï£¼
ï£±
ï£½
ï£²




X
X
1
(k)
(k)
Îµ
Âµ Sjl
(e + k âˆ’ 2) Âµ Sji âˆ’
ï£¾
ï£³
(eÎµ âˆ’ 1) (eÎµ + k âˆ’ 1)
lâˆˆ[k],l6=i
iâˆˆ[k]
ï£¼
ï£±
ï£½
ï£²




X
X
X
1
(k)
(k)
Îµ
(e
+
k
âˆ’
2)
Âµ
S
âˆ’
Âµ
S
ji
jl
ï£¾
(eÎµ âˆ’ 1) (eÎµ + k âˆ’ 1) ï£³
iâˆˆ[k]
iâˆˆ[k] lâˆˆ[k],l6=i
ï£¼
ï£±
ï£²
X  (k) ï£½
X  (k) 
1
Âµ S ji
Âµ Sji âˆ’ (k âˆ’ 1)
(eÎµ + k âˆ’ 2)
ï£¾
(eÎµ âˆ’ 1) (eÎµ + k âˆ’ 1) ï£³
iâˆˆ[k]
iâˆˆ[k]
X  (k) 
1
Âµ Sji
(eÎµ + k âˆ’ 1)
iâˆˆ[k]

=

X
1
(P0 (xi ) (eÎµ âˆ’ 1) + 1)
Îµ
(P
(x
)
(e
âˆ’
1)
+
1)
log
.
0
i
(eÎµ + k âˆ’ 1)
(P1 (xi ) (eÎµ âˆ’ 1) + 1)

(47)

iâˆˆ[k]

We claim that Î±âˆ— is a feasible dual variable for sufficiently large Îµ. In order to prove that
T
Î±âˆ— is a feasible dual variable, we show that S (k) j Î±âˆ— âˆ’ Âµj â‰¥ 0 for all j âˆˆ [2k ] for all Îµ â‰¥ Îµâˆ— ,
where Îµâˆ— is a positive quantity that depends on the priors P0 and P1 . Using the facts that

log (a + eÎµ b) = Îµ + log b + O eâˆ’Îµ

1
(48)
= eâˆ’Îµ + O eâˆ’2Îµ ,
Îµ
e +kâˆ’1
for large Îµ, we get that
Âµj

(P0 (Tj ) (eÎµ âˆ’ 1) + 1)
= (P0 (Tj ) (eÎµ âˆ’ 1) + 1) log
(P1 (Tj ) (eÎµ âˆ’ 1) + 1)



P0 (Tj )
P0 (Tj ) Îµ
e + (1 âˆ’ P0 (Tj )) log
+ O eâˆ’Îµ .
=
P0 (Tj ) log
P1 (Tj )
P1 (Tj )

(49)

On the other hand,
T

S (k) j Î±âˆ—

ï£±
ï£²X

ï£¼

ï£½
1
P0 (xi ) Îµ
(k)
=
Sij (eÎµ + k âˆ’ 2) P0 (xi ) log
e + O (1)
Îµ
Îµ
ï£¾
(e âˆ’ 1) (e + k âˆ’ 1) ï£³
P1 (xi )
iâˆˆ[k]
ï£±
ï£¼

ï£½
ï£²X X
1
P0 (xl ) Îµ
(k)
âˆ’ Îµ
e + O (1)
Sij P0 (xl ) log
ï£¾
(e âˆ’ 1) (eÎµ + k âˆ’ 1) ï£³
P1 (xl )
iâˆˆ[k] lâˆˆ[k],l6=i
ï£«ï£«
ï£¶
ï£¶
X

1
P0 (xi ) ï£¸ 3Îµ
2Îµ ï£¸
ï£­ï£­
=
P
(x
)
log
e
+
O
e
0
i
(eÎµ âˆ’ 1) (eÎµ + k âˆ’ 1)
P1 (xi )
xi âˆˆTj
ï£«
ï£¶
X
P0 (xi ) ï£¸ Îµ
= ï£­
P0 (xi ) log
e + O (1) .
(50)
P1 (xi )
xi âˆˆTj

38

Extremal Mechanisms for Local Differential Privacy

Assume, to begin with, that j 6= {j1 , j2 , ..., jk }. Then
ï£«
ï£¶
X
P0 (Tj )
P0 (xi ) ï£¸ Îµ
T
S (k) j Î±âˆ— âˆ’ Âµj = ï£­P0 (Tj ) log
âˆ’
P0 (xi ) log
e + O (1) .
P1 (Tj )
P1 (xi )
xi âˆˆTj

P (T )

P0 (xi )
xi âˆˆTj P0 (xi ) log P1 (xi ) by the logT
sum inequality. Therefore, there exists a Îµ(j) > 0 such that S (k) j Î±âˆ— âˆ’Âµj â‰¥ 0 for all Îµ â‰¥ Îµ(j).
T
If j âˆˆ {j1 , j2 , ..., jk }, it is not hard to check that S (k) j Î±âˆ— âˆ’ Âµj = 0 for all Îµ. In this case,
set Îµ(j) = 0. This establishes the satisfiability of Î±âˆ— for all Îµ â‰¥ Îµâˆ— = maxjâˆˆ[2k ] Îµ(j). The
satisfiability of Î±âˆ— , in turn, shows that (47) is indeed an upper bound to the primal problem.

Notice that for j 6= {j1 , j2 , ..., jk }, P0 (Tj ) log P10 (Tjj ) >

P

It remains to show that this upper bound can be achieved via the randomized response. To
this extent, recall that the randomized response is given by
(
eÎµ
if y = x ,
|X |âˆ’1+eÎµ
Q(y|x) =
(51)
1
if y 6= x .
|X |âˆ’1+eÎµ
Computing the KL divergence between M0 and M1 under (51), we get that
X
1
(P0 (xi ) (eÎµ âˆ’ 1) + 1)
Dkl (M0 ||M1 ) = Îµ
.
(P0 (xi ) (eÎµ âˆ’ 1) + 1) log
(e + k âˆ’ 1)
(P1 (xi ) (eÎµ âˆ’ 1) + 1)
iâˆˆ[k]

Hence, the randomized response in (51) achieves the upper bound in (47). This proves the
optimality of the randomized response for all Îµ â‰¥ Îµâˆ— .
8.5 Proof of Theorem 7
We start the proof with a fundamental bound on the symmetrized KL divergence between
the M0 and M1 .
Lemma 25 For any Îµ â‰¥ 0, let Q be any conditional distribution that guarantees Îµ differential privacy. Then for any pair of distributions P0 and P1 , the induced marginals M0 and
M1 must satisfy the bound


2
Dkl M0 ||M1 + Dkl M1 ||M0 â‰¤ 4 (eÎµ âˆ’ 1)2 P0 âˆ’ P1 TV .
The above lemma appears as Theorem 1 in Duchi et al. (2013). By Lemma 25, we have
that

2
OPT = max Dkl M0 ||M1 â‰¤ 4 (eÎµ âˆ’ 1)2 P0 âˆ’ P1 TV .
(52)
QâˆˆDÎµ

Let M0B and M1B be the marginals obtained by using the binary mechanism given in (14).
Îµ âˆ’1
kP0 âˆ’ P1 TV . Consequently, by
By Corollary 11, we have that kM0B âˆ’ M1B kTV = eeÎµ +1
applying Pinskerâ€™s inequality to the KL divergence between M0B and M1B we get that

BIN = Dkl M0B ||M1B
2
â‰¥ 2 M0B âˆ’ M1B TV
 Îµ

e âˆ’1 2
2
= 2 Îµ
P0 âˆ’ P1 TV .
(53)
e +1
Combining (52) and (53) we get that BIN â‰¥ 2(eÎµ1+1)2 OPT which was to be shown.
39

Kairouz, Oh and Viswanath

9. Proofs for Information Preservation
9.1 Proof of Theorem 12
By Theorem 4, we have that
max I (X; Y ) =

ÂµT Î¸

maximize

QâˆˆDÎµ

Î¸

subject to S (k) Î¸ = 1

(54)

Î¸ â‰¥ 0,


 P
(k)
(k)
where Âµj = Âµ Sj
= iâˆˆ[k] P (xi ) Sij log P



(k)

Sij

(k)

iâˆˆ[k] P (xi )Sij

for j âˆˆ {1, . . . , 2k } and S (k)

is the k Ã— 2k staircase pattern matrix given in Definition 3. The polytope given by S (k) Î¸ = 1
and Î¸ â‰¥ 0 is a closed and bounded one. Thus, there is no duality gap and solving the above
linear program is equivalent to solving its dual
minimize
Î±

1T Î±
T

(55)

subject to S (k) Î± â‰¥ Âµ.
Note that any satisfiable solution Î±âˆ— to (55) provides an upper bound to (54) since max ÂµT Î¸ =
(k)
min 1T Î± â‰¤ 1T Î±âˆ— . Let Tj = {xi : Sij = eÎµ } and set j1 = {j : Tj = T } and j2 = {j : Tj =
T c }. Consider the following choice of dual variable
ï£±  (k)   (k) 
Îµ
ï£´
ï£² e Âµ Sj1 âˆ’Âµ Sj2
âˆ€i âˆˆ T
1
|T

| 

Î±iâˆ— = Îµ
.
Îµ Âµ S (k) âˆ’Âµ S (k)
Îµ
e
(e + 1) (e âˆ’ 1) ï£´
j2
j1
ï£³
c
âˆ€i âˆˆ T
|T c |
Observe that since Tj1 = T , Tj2 = T c , and
Âµj

= P (Tj ) eÎµ log

1
eÎµ
+ P (Tj c ) log
,
c
Îµ
P (Tj ) + e P (Tj )
P (Tj ) + eÎµ P (Tj )
c

(56)

we have that
1T Î±âˆ— =
=
=
=

1
Îµ
(e + 1) (eÎµ âˆ’ 1)

(
X 1 
iâˆˆT

|T |





(k)
(k)
eÎµ Âµ Sj1 âˆ’ Âµ Sj2

)




X 1 
(k)
(k)
+
eÎµ Âµ Sj2 âˆ’ Âµ Sj1
|T c |
c
iâˆˆT
 



1
(k)
(k)
Âµ
S
+
Âµ
S
j1
j1
(eÎµ + 1)


1
1
eÎµ
Îµ
c
P
(T
)
e
+
P
(T
)
log
+
log
eÎµ + 1
P (T c ) + eÎµ P (T )
P (T c ) + eÎµ P (T )


1
eÎµ
1
c Îµ
P (T ) e log
+ P (T ) log
. (57)
eÎµ + 1
P (T ) + eÎµ P (T c )
P (T ) + eÎµ P (T c )
40

Extremal Mechanisms for Local Differential Privacy

We claim that Î±âˆ— is a feasible dual variablefor sufficiently
small Îµ. In order to prove that

T âˆ—
âˆ—
(k)
Î± is a feasible dual variable, we show that S
Î±
âˆ’ Âµj â‰¥ 0 for all j âˆˆ {1, . . . , 2k } and
j

all Îµ â‰¤ Îµâˆ— , where Îµâˆ— is a positive quantity that depends on P . Using the following facts

1
eÎµ = 1 + Îµ + Îµ + O Îµ3
2

b(1 âˆ’ b) 2
log (a + eÎµ b) = bÎµ +
Îµ + O Îµ3
2

1 1
1
=
âˆ’ Îµ + O Îµ2 ,
(58)
Îµ
1+e
2 4
for small Îµ, we get that
eÎµ
1
+ P (Tj c ) log
c
c
Îµ
P (Tj ) + e P (Tj )
P (Tj ) + eÎµ P (Tj )
= P (Tj ) eÎµ Îµ âˆ’ (P (Tj ) (eÎµ âˆ’ 1) + 1) log (P (Tj ) (eÎµ âˆ’ 1) + 1)


1
=
P (Tj ) P Tjc Îµ2 + O Îµ3 .
(59)
2
On the other hand,


T
(k) T
S (k) Î±âˆ—
= Sj Î± âˆ—
j
(
(k) 




X Sij
1
(k)
(k)
Îµ
=
e
Âµ
S
âˆ’
Âµ
S
j1
j2
(eÎµ + 1) (eÎµ âˆ’ 1)
|T |
iâˆˆT
)
(k) 




X Sij
(k)
(k)
+
eÎµ Âµ Sj2 âˆ’ Âµ Sj1
c|
|T
iâˆˆT c





  |T âˆ© T |
|Tjc âˆ© T |
1
j
(k)
(k)
Îµ
Îµ
e Âµ Sj1 âˆ’ Âµ Sj2
e +
=
(eÎµ + 1) (eÎµ âˆ’ 1)
|T |
|T |







c
|Tj âˆ© T | Îµ |Tjc âˆ© T c |
1
(k)
(k)
Îµ
+ Îµ
e Âµ Sj2 âˆ’ Âµ Sj1
e +
(e + 1) (eÎµ âˆ’ 1)
|T c |
|T c |


c
c

|Tj âˆ© T c | |Tj âˆ© T |
1
1
c 2
3
=
P
(T
)
P
(T
)
Îµ
+
O
Îµ
+
(eÎµ + 1) 2
|T c |
|T c |

c
|Tj âˆ© T | |Tj âˆ© T |
+
+ O (Îµ)
+
|T |
|T |

1
=
P (T ) P (T c ) Îµ2 + O Îµ3 ,
(60)
2
where we have used the facts that Tj1 = T , Tj2 = T c , and



1
(k)
P (T ) P (T c ) Îµ2 + O Îµ3
Âµ Sj1
=
2



1
(k)
Âµ Sj2
=
P (T ) P (T c ) Îµ2 + O Îµ3 .
(61)
2
Âµj

= P (Tj ) eÎµ log

Let f (z) = |z âˆ’ 12 |, g(z) = âˆ’z log z âˆ’ (1 âˆ’ z) log(1 âˆ’ z), and h(z) = z(1 âˆ’ z) for 0 â‰¤ z â‰¤ 1.
On the one hand, g and h are monotonically increasing over 0 â‰¤ z â‰¤ 21 and monotonically
41

Kairouz, Oh and Viswanath

decreasing over 12 â‰¤ z â‰¤ 1 but on the other hand, f is monotonically decreasing over
0 â‰¤ z â‰¤ 12 and monotonically increasing over 12 â‰¤ z â‰¤ 1. Therefore,
T âˆˆ arg min P (A) âˆ’
AâŠ†X

1
2

â‡” T âˆˆ arg max âˆ’ P (A) log P (A) âˆ’ P (Ac ) log P (Ac )
AâŠ†X

â‡” T âˆˆ arg max P (A)P (Ac ).

(62)

AâŠ†X

Since thesetT was chosen so that it maximizes P (T ) P (T c ), we have that P (T ) P (T c ) â‰¥
P (Tj ) P Tjc for all j âˆˆ {1, . . . , 2k }. Assume, to begin with, that j 6= {j1 , j2 }. Then by the
c
uniqueness
 ofthe maximizer assumption stated in the theorem, we have that P (T ) P (T ) >
P (Tj ) P Tjc .



1
P (T ) P (T c ) âˆ’ P (Tj ) P Tjc Îµ2 + O Îµ3 ,
S T Î±âˆ— j âˆ’ Âµj =
2


T âˆ—
âˆ—
(k)
and thus, there exists an Îµ that depends on P such that S
Î±
âˆ’ Âµj â‰¥ 0 for all Îµ â‰¤ Îµâˆ— .
j


T
If j = {j1 , j2 }, it is not hard to check that S (k) Î±âˆ— âˆ’ Âµj = 0 for all Îµ. This establishes
j

the satisfiability of Î±âˆ— for all Îµ â‰¤ Îµâˆ— which proves an upper bound on the primal problem
(given in (57)). It remains to show that the upper bound can be indeed achieved via the
binary mechanism. To this extent, recall that the binary mechanism is given by

Q(0|x) =

eÎµ
1+eÎµ
1
1+eÎµ

if x âˆˆ T ,
if x âˆˆ
/T .


Q(1|x) =

eÎµ
1+eÎµ
1
1+eÎµ

if x âˆˆ
/T ,
if x âˆˆ T .

(63)

Computing the I (X; Y ) under (63), we get that


1
eÎµ
1
c
I (X; Y ) = Îµ
P (T ) eÎµ log
+
P
(T
)
log
+
e +1
P (T c ) + eÎµ P (T )
P (T c ) + eÎµ P (T )


1
eÎµ
1
c Îµ
P (T ) e log
+ P (T ) log
.(64)
eÎµ + 1
P (T ) + eÎµ P (T c )
P (T ) + eÎµ P (T c )
Hence, the binary mechanism in (63) achieves the upper bound in (57). This proves the
optimality of the binary mechanism for all Îµ â‰¤ Îµâˆ— .
9.2 Proof of Theorem 13
We start by proving an upper bound on maxQâˆˆDÎµ I (X; Y ) which is tight for Îµ â‰¤ 1. Recall
that by Theorem 4, we have that
k

OPT =

max I (X; Y ) =

QâˆˆDÎµ

maximize
Î¸

2
X

Âµj Î¸j

j=1

subject to S (k) Î¸ = 1
Î¸ â‰¥ 0,
42

Extremal Mechanisms for Local Differential Privacy

where
Âµj



(k)
= Âµ Sj
ï£«
=

X
iâˆˆ[k]

ï£¶

(k)
Sij

(k)

P (xi ) Sij log ï£­ P

(k)

iâˆˆ[k] P (xi ) Sij

ï£¸

= P (Tj ) eÎµ Îµ âˆ’ (P (Tj ) (eÎµ âˆ’ 1) + 1) log (P (Tj ) (eÎµ âˆ’ 1) + 1) ,

(65)

(k)

Tj = {i : Sij = eÎµ }, and S (k) is the k Ã— 2k staircase pattern matrix given in Definition 3.
Lemma 26 For all distributions P and all Îµ, the following bound holds


k
.
OPT = max I (X; Y ) â‰¤ max Âµj
Îµ
j
QâˆˆDÎµ
e +kâˆ’1
The proof of this lemma is given in Section 9.3. In what follows, we will make the dependency
of Âµj on P (Tj ) and Îµ explicit by writing Âµj (P (Tj ) , Îµ) for Âµj . From the proof of Theorem
12, we have that the partition set T defined in (19) is given by T âˆˆ arg maxAâŠ†X P (A)P (Ac ).
It is easy to check that the binary mechanism given in (20) achieves the following utility
BIN =

Âµ (P (T ) , Îµ) + Âµ (P (T c ) , Îµ)
.
eÎµ + 1

Lemma 27 For all distributions P and all Îµ â‰¤ 1, the following bound holds
maxj Âµj
â‰¤ 1.
Âµ (P (T ) , Îµ) + Âµ (P (T c ) , Îµ)
The proof of the above lemma is given in Section 9.4. Combining the results of lemmas 26
and 27 we get that
OPT
BIN

maxj Âµj
k
(eÎµ + 1)
c
Îµ
Âµ (P (T ) , Îµ) + Âµ (P (T ) , Îµ) e + k âˆ’ 1
k
â‰¤ Îµ
(eÎµ + 1)
e +kâˆ’1
â‰¤ eÎµ + 1,

â‰¤

(66)

for all Îµ â‰¤ 1. This concludes the proof.
9.3 Proof of Lemma 26
(k)

(k)

To begin with, since S1 = 1 = e1Îµ S2k and Âµ is homogenous, we have that Î¸1 Âµ1 + Î¸2k Âµ2k =

1
eÎµ Î¸1 + Î¸2k Âµ2k . Therefore, the following two maximization problems are equivalent
k

maximize
Î¸

2
X

Âµj Î¸j

j=1

maximize
Î¸

=

subject to S (k) Î¸ = 1

k âˆ’1
2X

ÂµÌƒj Î¸j

j=1

subject to SÌƒ (k) Î¸ = 1

Î¸â‰¥0

Î¸ â‰¥ 0,
43

Kairouz, Oh and Viswanath

where ÂµÌƒj = Âµj+1 and SÌƒ (k) is obtained by deleting the first column of S (k) . Moreover, using
the fact that maxjâˆˆ[2k âˆ’1] ÂµÌƒj â‰¤ maxjâˆˆ[2k ] Âµj and weak duality, we get that
maximize
Î¸


max ÂµÌƒj maximize



ÂµÌƒT Î¸

â‰¤

jâˆˆ[2k âˆ’1]

subject to SÌƒ (k) Î¸ = 1

Î¸

1T Î¸

subject to SÌƒ (k) Î¸ = 1

Î¸â‰¥0

Î¸â‰¥0

â‰¤


max Âµj minimize

jâˆˆ[2k ]

Î±

1T Î±
T

subject to SÌƒ (k) Î± â‰¥ 1.

(67)

1
Consider the following choice of dual variable Î±iâˆ— = eÎµ +kâˆ’1
. We claim that Î±âˆ— is satisfiable.
This can be easily verified by noting that



T

SÌƒ (k) Î±âˆ—

(k)T


j

= SÌƒj

Î±âˆ— =

|Tj |eÎµ + (k âˆ’ |Tj |)
|Tj |(eÎµ âˆ’ 1) + k
=
â‰¥1
eÎµ + k âˆ’ 1
eÎµ + k âˆ’ 1

where the last inequality holds since |Tj | â‰¥ 1 (this is true because we have deleted the first
k
column of S (k) ). Therefore, OPT â‰¤ (maxj Âµj ) 1T Î±âˆ— = (maxj Âµj ) eÎµ +kâˆ’1
which was to be
shown.
9.4 Proof of Lemma 27
Let Âµ (z, Îµ) be the function obtained by replacing P (Tj ) by the continuous variable z âˆˆ [0, 1]
in Âµj (P (Tj ) , Îµ). Taking the derivative of Âµ (z, Îµ) with respect to z we get
Âµ0 (z, Îµ) = eÎµ Îµ âˆ’ (eÎµ âˆ’ 1) âˆ’ (eÎµ âˆ’ 1) log (z(eÎµ âˆ’ 1) + 1) .
Observe that Âµ0 (z, Îµ) > 0 for all
z < z âˆ— (Îµ) =

1
eÎµ âˆ’ 1

 n Îµ

o
e Îµ
âˆ’1
e eÎµ âˆ’1
âˆ’1 ,

Âµ0 (z, Îµ) < 0 for all z > z âˆ— (Îµ), and Âµ0 (z, Îµ) = 0 for z = z âˆ— (Îµ). Combining this with the fact
that Âµ (0, Îµ) = Âµ (1, Îµ) = 0 we get that Âµ (z, Îµ) â‰¥ 0 for all z âˆˆ [0, 1] and for any fixed Îµ,
Âµ (z, Îµ) is maximized at z âˆ— (Îµ).
Set xâˆ— âˆˆ arg maxxâˆˆX P (x) and fix an Îµ â‰¤ 1. We will treat the following three cases
separately.
Case 1: P (xâˆ— ) âˆˆ [1 âˆ’ z âˆ— (Îµ), 1].
Claim 4 Let T = {xâˆ— }. Then {T, T c } = arg maxAâŠ†X P (A)P (Ac ) and maxAâŠ†X Âµ(P (A), Îµ) =
max (Âµ(P (T ), Îµ), Âµ(P (T c ), Îµ)).
Proof Observe that z âˆ— (Îµ) â‰¤ 12 for all Îµ and T c = X \ {xâˆ— }. The function f (z) = z(1 âˆ’ z)
decreases over the range [ 21 , 1] âŠ‡ [1 âˆ’ z âˆ— (Îµ), 1]. Thus, for all A âŠƒ T , P (T )P (T c ) >
44

Extremal Mechanisms for Local Differential Privacy

P (A)P (Ac ) because P (T ) â‰¥ 1 âˆ’ z âˆ— (Îµ). This proves that T âˆˆ arg maxAâŠ†X P (A)P (Ac ) and
for all A âŠƒ T , A âˆˆ
/ arg maxAâŠ†X P (A)P (Ac ). Using a similar approach, we can show that
T c âˆˆ arg maxAâŠ†X P (A)P (Ac ) and for all A âŠ‚ T c , A âˆˆ
/ arg maxAâŠ†X P (A)P (Ac ). Therec
c
fore, {T, T } = arg maxAâŠ†X P (A)P (A ). This proves the first part of the claim. The
function Âµ (z, Îµ) increases over the range [0, z âˆ— (Îµ)]. Thus, for all A âŠ† T c , Âµ(P (A), Îµ) â‰¤
Âµ(P (T c ), Îµ) because P (T c ) â‰¤ z âˆ— (Îµ). On the other hand, note that Âµ (z, Îµ) decreases
over the range [z âˆ— (Îµ), 1] which includes the range [1 âˆ’ z âˆ— (Îµ), 1]. Thus, for all A such
that A âŠ‡ T , Âµ(P (A), Îµ) â‰¤ Âµ(P (T ), Îµ) because P (T ) â‰¥ 1 âˆ’ z âˆ— (Îµ). This proves that
max (Âµ(P (T ), Îµ), Âµ(P (T c ), Îµ)) = maxAâŠ†X Âµ(P (A), Îµ).
Using the above claim, we can conclude that the partition set T defined in (19) is equal to
{xâˆ— } and
maxj Âµj
Âµ (P (T ) , Îµ) + Âµ (P (T c ) , Îµ)

maxAâŠ†X Âµ(P (A), Îµ)
Âµ (P (T ) , Îµ) + Âµ (P (T c ) , Îµ)
maxAâŠ†X Âµ(P (A), Îµ)
â‰¤
max (Âµ(P (T ), Îµ), Âµ(P (T c ), Îµ))
= 1.

=

(68)

Case 2: P (xâˆ— ) âˆˆ [ 12 , 1 âˆ’ z âˆ— (Îµ)]. Using the first part of the proof of Claim 4, we can show
that if T = {xâˆ— }, then {T, T c } = arg maxAâŠ†X P (A)P (Ac ). Therefore, the partition set T
defined in (19) is equal to {xâˆ— } and
maxj Âµj
Âµ (P (T ) , Îµ) + Âµ (P (T c ) , Îµ)

maxAâŠ†X Âµ(P (A), Îµ)
Âµ (P (T ) , Îµ) + Âµ (P (T c ) , Îµ)
Âµ(z âˆ— (Îµ), Îµ)
â‰¤
Âµ (P (xâˆ— ) , Îµ) + Âµ (1 âˆ’ P (xâˆ— ) , Îµ)
â‰¤ 1.

=

(69)

Case 3: P (xâˆ— ) âˆˆ [0, 21 ].
Claim 5 There exists a set A âŠ‚ X such that 21 âˆ’ P (xâˆ— ) â‰¤ P (A) â‰¤ 21 .
Proof Without loss of generality, assume
P (xi ), i âˆˆ [k], is sorted
Pl that the sequence
1
P
(x
)
â‰¥
in increasing order. Let lâˆ— = min{l :
}.
From
the definition of lâˆ— ,
i
i=1
2
1
1
P ({x1 , . . . , xlâˆ— âˆ’1 }) < 2 and P ({x1 , . . . , xlâˆ— }) â‰¥ 2 . Further,
P ({x1 , . . . , xlâˆ— âˆ’1 }) = P ({x1 , . . . , xlâˆ— }) âˆ’ P (xlâˆ— )
and since xâˆ— âˆˆ arg maxxâˆˆX P (x), P (xlâˆ— ) â‰¤ P (xâˆ— ). Therefore, if A = {x1 , . . . , xlâˆ— âˆ’1 }, then
1
1
âˆ—
2 âˆ’ P (x ) â‰¤ P (A) â‰¤ 2 .
Let P (T ) = min{P (B) : B âˆˆ arg maxAâŠ†X P (A)P (Ac )}. We claim that 41 â‰¤ P (T ) â‰¤ 12 .
The upper bound on P (T ) follows immediately from its definition. To prove the lower
bound on P (T ), consider the set A given in Claim 5 and observe that
P (T ) â‰¥ max(P (xâˆ— ), P (A))
1
â‰¥ max(P (xâˆ— ), âˆ’ P (xâˆ— ))
2
1
â‰¥
.
4
45

(70)

Kairouz, Oh and Viswanath

All the inequalities follow from Claim 5 and the fact that P (xâˆ— ) âˆˆ [0, 21 ].
Since 41 â‰¤ P (T ) â‰¤ 12 , we have that 12 â‰¤ P (T c ) â‰¤ 34 . Moreover, the function Âµ (z, Îµ)
decreases over the range
[z âˆ— (Îµ), 1] âŠƒ [ 12 , 34 ] and increases over therange [ 14 , z âˆ— (Îµ)]. Therefore,

Âµ (P (T c ), Îµ) â‰¥ Âµ 43 , Îµ and Âµ (P (T ), Îµ) â‰¥ min Âµ 21 , Îµ , Âµ 14 , Îµ . Putting it all together,
we have that
maxj Âµj
Âµ (P (T ) , Îµ) + Âµ (P (T c ) , Îµ)

maxAâŠ†X Âµ(P (A), Îµ)
Âµ (P (T ) , Îµ) + Âµ (P (T c ) , Îµ)
Âµ(z âˆ— (Îµ), Îµ)



â‰¤
min Âµ 21 , Îµ , Âµ 41 , Îµ + Âµ 34 , Îµ
â‰¤ 1.

=

(71)

9.5 Proof of Theorem 14
By Theorem 4, we have that
max I (X; Y ) =

QâˆˆDÎµ

ÂµT Î¸

maximize
Î¸

subject to S (k) Î¸ = 1

(72)

Î¸ â‰¥ 0,

where Âµj = Âµ



(k)
Sj



=

(k)
iâˆˆ[k] P (xi ) Sij log



(k)

Sij

P

P

(k)
iâˆˆ[k] P (xi )Sij



for j âˆˆ {1, . . . , 2k } and S (k)

is the k Ã— 2k staircase pattern matrix given in Definition 3. The polytope given by S (k) Î¸ = 1
and Î¸ â‰¥ 0 is a closed and bounded one. Thus, there is no duality gap and solving the above
linear program is equivalent to solving its dual
minimize
Î±

1T Î±
(73)

T

subject to S (k) Î± â‰¥ Âµ.
Note that any satisfiable solution Î±âˆ— to (73) provides an upper bound to (72) since max ÂµT Î¸ =
(k)
min 1T Î± â‰¤ 1T Î±âˆ— . Let Tj = {xi : Sij = eÎµ } and set ji = {j : Tj = i} for i âˆˆ {1, . . . , k}.
Consider the following choice of dual variable
ï£±
ï£¼
ï£²
ï£½




X
1
(k)
(k)
Îµ
Î±iâˆ— = Îµ
(e
+
k
âˆ’
2)
Âµ
S
âˆ’
Âµ
S
,
ji
jl
ï£¾
(e âˆ’ 1) (eÎµ + k âˆ’ 1) ï£³
lâˆˆ[k],l6=i

for i âˆˆ {1, . . . , k}. Observe that since Tji = i we have that P (Tji ) = P (xi ) and since
Âµj

= P (Tj ) eÎµ log

eÎµ
1
+ P (Tj c ) log
,
c
c
Îµ
P (Tj ) + e P (Tj )
P (Tj ) + eÎµ P (Tj )
46

(74)

Extremal Mechanisms for Local Differential Privacy

we have that

1T Î±âˆ— =

=

=
=
=

ï£¼
ï£±
ï£½



Xï£²
X
1
(k)
(k)
(eÎµ + k âˆ’ 2) Âµ Sji âˆ’
Âµ Sjl
ï£¾
ï£³
(eÎµ âˆ’ 1) (eÎµ + k âˆ’ 1)
iâˆˆ[k]
lâˆˆ[k],l6=i
ï£¼
ï£±
ï£½
ï£²




X
X
X
1
(k)
(k)
Îµ
Âµ
S
Âµ
S
âˆ’
(e
+
k
âˆ’
2)
jl
ji
ï£¾
(eÎµ âˆ’ 1) (eÎµ + k âˆ’ 1) ï£³
iâˆˆ[k] lâˆˆ[k],l6=i
iâˆˆ[k]
ï£¼
ï£±
ï£½
ï£²




X
X
1
(k)
(k)
Îµ
Âµ
S
Âµ
S
âˆ’
(k
âˆ’
1)
(e
+
k
âˆ’
2)
ji
ji
ï£¾
(eÎµ âˆ’ 1) (eÎµ + k âˆ’ 1) ï£³
iâˆˆ[k]
iâˆˆ[k]
X  (k) 
1
Âµ Sji
(eÎµ + k âˆ’ 1)
iâˆˆ[k]
X
1
eÎµ
Îµ
P
(x
)
e
log
i
(eÎµ + k âˆ’ 1)
P (xi ) (eÎµ âˆ’ 1) + 1
iâˆˆ[k]

1
+ (1 âˆ’ P (xi )) log
. (75)
P (xi ) (eÎµ âˆ’ 1) + 1

We claim that Î±âˆ— is a feasible dual variablefor sufficiently
large Îµ. In order to prove that

T âˆ—
âˆ—
(k)
Î± is a feasible dual variable, we show that S
Î±
âˆ’ Âµj â‰¥ 0 for all j âˆˆ {1, . . . , 2k } and
j

all Îµ â‰¥ Îµâˆ— , where Îµâˆ— is a positive quantity that depends on P . Using the fact that


log (a + eÎµ b) = Îµ + log b + O eâˆ’Îµ ,

for large Îµ, we get that

Âµj

1
eÎµ
+ P (Tj c ) log
c
c
Îµ
P (Tj ) + e P (Tj )
P (Tj ) + eÎµ P (Tj )
= P (Tj ) eÎµ Îµ âˆ’ (P (Tj ) (eÎµ âˆ’ 1) + 1) log (P (Tj ) (eÎµ âˆ’ 1) + 1)

= P (Tj ) eÎµ Îµ âˆ’ (P (Tj ) (eÎµ âˆ’ 1) + 1) Îµ + log P (Tj ) + O eâˆ’Îµ
= P (Tj ) eÎµ log

= âˆ’ (P (Tj ) log P (Tj )) eÎµ + O (Îµ) .
47

(76)

Kairouz, Oh and Viswanath

On the other hand,


T
(k) T
= Sj Î±âˆ—
S (k) Î±âˆ—
j
X
X
= eÎµ
Î±iâˆ— +
Î±iâˆ—
iâˆˆTj

= âˆ’

iâˆˆTjc

ï£±
ï£²X

1

(eÎµ âˆ’ 1) (eÎµ + k âˆ’ 1) ï£³
iâˆˆ[k]

(k)

Sij (eÎµ + k âˆ’ 2) (P (xi ) log P (xi ) eÎµ
)
+O (Îµ))

ï£±
ï£²X

ï£¼
ï£½
1
(k)
Îµ
+ Îµ
S
((P
(x
)
log
P
(x
))
e
+
O
(Îµ))
l
l
ij
ï£¾
(e âˆ’ 1) (eÎµ + k âˆ’ 1) ï£³
iâˆˆ[k] lâˆˆ[k],l6=i
ï£¶
ï£¶
ï£«ï£«
X

1
ï£­ï£­
P (xi ) log P (xi )ï£¸ e3Îµ + O e2Îµ Îµ ï£¸
= âˆ’ Îµ
(e âˆ’ 1) (eÎµ + k âˆ’ 1)
iâˆˆTj
ï£¶
ï£«
X
P (xi ) log P (xi )ï£¸ eÎµ + O (Îµ) .
(77)
= âˆ’ï£­
X

iâˆˆTj

Assume, to begin with, that j 6= {j1 , j2 , ..., jk }. Then
ï£«
ï£¶


X
T
P (xi ) log P (xi )ï£¸ eÎµ + O (Îµ) .
S (k) Î±âˆ— âˆ’ Âµj = ï£­P (Tj ) log P (Tj ) âˆ’
j

iâˆˆTj

P
Notice that for j 6= {j1 , j2 , ..., jk }, P (Tj ) log P (Tj ) > iâˆˆTj P (xi ) log P (xi ). Therefore,


T
there exists an Îµâˆ— > 0 such that S (k) Î±âˆ— âˆ’ Âµj â‰¥ 0 for all Îµ â‰¥ Îµâˆ— . If j âˆˆ {j1 , j2 , ..., jk }, it
j


T âˆ—
(k)
is not hard to check that S
Î±
âˆ’ Âµj = 0 for all Îµ. This establishes the satisfiability
j

of Î±âˆ— for all Îµ â‰¥ Îµâˆ— . It remains to show that the upper bound can be indeed achieved via
the randomized response mechanism. To this extent, recall that the randomized response
is given by
ï£±
eÎµ
ï£´
if y = x ,
ï£²
|X | âˆ’ 1 + eÎµ
Q(y|x) =
(78)
1
ï£´
ï£³
if
y
=
6
x
.
|X | âˆ’ 1 + eÎµ
Computing the I (X; Y ) under (78), we get that
X
1
eÎµ
I (X; Y ) = Îµ
P (xi ) eÎµ log
e +kâˆ’1
P (xi ) (eÎµ âˆ’ 1) + 1
iâˆˆ[k]

1
+ (1 âˆ’ P (xi )) log
.
P (xi ) (eÎµ âˆ’ 1) + 1
48

(79)

Extremal Mechanisms for Local Differential Privacy

Hence, the randomized response mechanism achieves the upper bound (75). This proves
the optimality of the randomized response for all Îµ â‰¥ Îµâˆ— .

10. Proof of Proposition 17
P
Let U (Q) be a utility mechanism of the form U (Q) = Y Âµ(Qy ), where Âµ is a sublinear
function. Consider a stochastic mapping W of dimensions ` Ã— m and let QW be the
stochastic mapping obtained by first applying Q to X âˆˆ X to obtain Y âˆˆ Y and then
applying W to Y to obtain Z âˆˆ Z.
X
U (QW ) =
Âµ ((QW )z )
Z

!
=

X

Âµ

X

Qy Wy,z

Z

Y

â‰¤

X

Wy,z Âµ (Qy )

=

X

Y,Z

Âµ(Qy )

Y

= U (Q) ,

(80)

where the inequality follows from sublinearity and the second to last equality follows from
the row stochastic property of W . Therefore, U (Q) obeys the data processing inequality.

Acknowledgments
This research is supported in part by NSF CISE award CCF-1422278, NSF SaTC award
CNS-1527754, NSF CMMI award MES-1450848 and NSF ENG award ECCS-1232257.

References
A. Acquisti. Privacy in electronic commerce and the economics of immediate gratification.
In Proceedings of the 5th ACM conference on Electronic commerce, pages 21â€“29. ACM,
2004.
A. Acquisti and J. Grossklags. What can behavioral economics teach us about privacy.
Digital Privacy, page 329, 2007.
R. F. Barber and J. C. Duchi. Privacy and statistical risk: Formalisms and minimax bounds.
arXiv preprint arXiv:1412.4451, 2014.
A. Beimel, K. Nissim, and E. Omri. Distributed private data analysis: Simultaneously solving how and what. In Advances in Cryptologyâ€“CRYPTO 2008, pages 451â€“468. Springer,
2008.
D. Blackwell. Equivalent comparisons of experiments. The Annals of Mathematical Statistics, 24(2):265â€“272, 1953.
49

Kairouz, Oh and Viswanath

J. Blocki, A. Blum, A. Datta, and O. Sheffet. The Johnson-Lindenstrauss transform itself
preserves differential privacy. In Foundations of Computer Science, 2012 IEEE 53rd
Annual Symposium on, pages 410â€“419. IEEE, 2012.
K. Chatzikokolakis, T. Chothia, and A. Guha. Statistical measurement of information
leakage. In Tools and Algorithms for the Construction and Analysis of Systems, pages
390â€“404. Springer, 2010.
K. Chaudhuri and D. Hsu. Convergence rates for differentially private statistical estimation.
arXiv preprint arXiv:1206.6395, 2012.
K. Chaudhuri and C. Monteleoni. Privacy-preserving logistic regression. In NIPS, volume 8,
pages 289â€“296, 2008.
K. Chaudhuri, A. D. Sarwate, and K. Sinha. Near-optimal differentially private principal
components. In NIPS, pages 998â€“1006, 2012.
T. M. Cover and J. A. Thomas. Elements of information theory. John Wiley & Sons, 2012.
A. De. Lower bounds in differential privacy. In Theory of Cryptography, pages 321â€“338.
Springer, 2012.
J. C Duchi, M. I. Jordan, and M. J. Wainwright. Local privacy and statistical minimax
rates. In Foundations of Computer Science, 2013 IEEE 54th Annual Symposium on,
pages 429â€“438. IEEE, 2013.
C. Dwork. Differential privacy. In Automata, languages and programming, pages 1â€“12.
Springer, 2006.
C. Dwork and J. Lei. Differential privacy and robust statistics. In Proceedings of the 41st
annual ACM symposium on Theory of computing, pages 371â€“380. ACM, 2009.
C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, and M. Naor. Our data, ourselves:
Privacy via distributed noise generation. In Advances in Cryptology-EUROCRYPT 2006,
pages 486â€“503. Springer, 2006a.
C. Dwork, F. McSherry, K. Nissim, and A. Smith. Calibrating noise to sensitivity in private
data analysis. In Theory of Cryptography, pages 265â€“284. Springer, 2006b.
Q. Geng and P. Viswanath. The optimal mechanism in differential privacy. arXiv preprint
arXiv:1212.1186, 2012.
Q. Geng and P. Viswanath. The optimal mechanism in (,Î´)-differential privacy. arXiv
preprint arXiv:1305.1330, 2013a.
Q. Geng and P. Viswanath. The optimal mechanism in differential privacy: Multidimensional setting. arXiv preprint arXiv:1312.0655, 2013b.
A. Ghosh, T. Roughgarden, and M. Sundararajan. Universally utility-maximizing privacy
mechanisms. SIAM Journal on Computing, 41(6):1673â€“1693, 2012.
50

Extremal Mechanisms for Local Differential Privacy

M. Hardt and A. Roth. Beating randomized response on incoherent matrices. In Proceedings
of the 44th symposium on Theory of Computing, pages 1255â€“1268. ACM, 2012.
M. Hardt and G. N. Rothblum. A multiplicative weights mechanism for privacy-preserving
data analysis. In Foundations of Computer Science, 2010 51st Annual IEEE Symposium
on, pages 61â€“70. IEEE, 2010.
M. Hardt and K. Talwar. On the geometry of differential privacy. In Proceedings of the
42nd ACM symposium on Theory of computing, pages 705â€“714. ACM, 2010.
M. Hardt, K. Ligett, and F. McSherry. A simple and practical algorithm for differentially
private data release. In NIPS, pages 2348â€“2356, 2012.
P. Kairouz, S. Oh, and P. Viswanath. The composition theorem for differential privacy.
arXiv preprint arXiv:1311.0776, 2013.
P. Kairouz, S. Oh, and P. Viswanath. Extremal mechanisms for local differential privacy.
arXiv preprint arXiv:1407.1338, 2014a.
P. Kairouz, S. Oh, and P. Viswanath. Differentially private multi-party computation: Optimality of non-interactive randomized response. arXiv preprint arXiv:1407.1546, 2014b.
M. Kapralov and K. Talwar. On differentially private low rank approximation. In SODA,
volume 5, page 1. SIAM, 2013.
J. Lei. Differentially private m-estimators. In NIPS, pages 361â€“369, 2011.
F. McSherry and K. Talwar. Mechanism design via differential privacy. In Foundations of
Computer Science, 2007. 48th Annual IEEE Symposium on, pages 94â€“103. IEEE, 2007.
L. Sankar, S. R. Rajagopalan, and H. V. Poor. Utility-privacy tradeoffs in databases: An
information-theoretic approach. Information Forensics and Security, IEEE Transactions
on, 8(6):838â€“852, 2013.
A. D. Sarwate and L. Sankar. A rate-disortion perspective on local differential privacy. In
Communication, Control, and Computing (Allerton), 2014 52nd Annual Allerton Conference on, pages 903â€“908. IEEE, 2014.
A. B. Tsybakov and V. Zaiats. Introduction to nonparametric estimation, volume 11.
Springer, 2009.
W. Wang, L. Ying, and J. Zhang. On the relation between identifiability, differential privacy
and mutual-information privacy. arXiv preprint arXiv:1402.3757, 2014a.
Y. Wang, Z. Huang, S. Mitra, and G.E. Dullerud. Entropy-minimizing mechanism for
differential privacy of discrete-time linear feedback systems. In Decision and Control
(CDC), 2014 IEEE 53rd Annual Conference on, pages 2130â€“2135, Dec 2014b. doi: 10.
1109/CDC.2014.7039713.
S. L. Warner. Randomized response: A survey technique for eliminating evasive answer
bias. Journal of the American Statistical Association, 60(309):63â€“69, 1965.
51

